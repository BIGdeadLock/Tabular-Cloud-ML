{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-02T12:49:50.561120Z",
     "start_time": "2024-11-02T12:49:27.033776Z"
    }
   },
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from keras.src import Sequential\n",
    "from keras.src.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.src.callbacks import EarlyStopping"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T11:15:08.281093Z",
     "start_time": "2024-11-01T11:15:08.277081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECT_PATH = os.getcwd()\n",
    "PROJECT_PATH = os.path.join(PROJECT_PATH, \"..\")\n",
    "MODELS_DIR = pathlib.Path(PROJECT_PATH) / \"store\" / \"models\"\n",
    "\n",
    "DATASET_DIR = pathlib.Path(PROJECT_PATH) / \"data\""
   ],
   "id": "982312657be336ff",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:07:51.728934Z",
     "start_time": "2024-11-01T14:07:51.686768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(DATASET_DIR / \"bank_marketing\"/ \"dataset.csv\")\n",
    "dataset"
   ],
   "id": "a240984fa1f517ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       age           job   marital  education default  balance housing loan  \\\n",
       "0       27    management    single  secondary      no       35      no   no   \n",
       "1       54   blue-collar   married    primary      no      466      no   no   \n",
       "2       43   blue-collar   married  secondary      no      105      no  yes   \n",
       "3       31    technician    single  secondary      no       19      no   no   \n",
       "4       27    technician    single  secondary      no      126     yes  yes   \n",
       "...    ...           ...       ...        ...     ...      ...     ...  ...   \n",
       "30902   51    technician   married   tertiary      no      825      no   no   \n",
       "30903   71       retired  divorced    primary      no     1729      no   no   \n",
       "30904   72       retired   married  secondary      no     5715      no   no   \n",
       "30905   57   blue-collar   married  secondary      no      668      no   no   \n",
       "30906   37  entrepreneur   married  secondary      no     2971      no   no   \n",
       "\n",
       "         contact  day_of_week month  duration  campaign  pdays  previous  \\\n",
       "0       cellular            4   jul       255         1     -1         0   \n",
       "1       cellular            4   jul       297         1     -1         0   \n",
       "2       cellular            4   jul       668         2     -1         0   \n",
       "3      telephone            4   jul        65         2     -1         0   \n",
       "4       cellular            4   jul       436         4     -1         0   \n",
       "...          ...          ...   ...       ...       ...    ...       ...   \n",
       "30902   cellular           17   nov       977         3     -1         0   \n",
       "30903   cellular           17   nov       456         2     -1         0   \n",
       "30904   cellular           17   nov      1127         5    184         3   \n",
       "30905  telephone           17   nov       508         4     -1         0   \n",
       "30906   cellular           17   nov       361         2    188        11   \n",
       "\n",
       "      poutcome    y  \n",
       "0          NaN   no  \n",
       "1          NaN   no  \n",
       "2          NaN   no  \n",
       "3          NaN   no  \n",
       "4          NaN   no  \n",
       "...        ...  ...  \n",
       "30902      NaN  yes  \n",
       "30903      NaN  yes  \n",
       "30904  success  yes  \n",
       "30905      NaN   no  \n",
       "30906    other   no  \n",
       "\n",
       "[30907 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>35</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>466</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>105</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>668</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>19</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>126</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>436</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30902</th>\n",
       "      <td>51</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>825</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30903</th>\n",
       "      <td>71</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1729</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30904</th>\n",
       "      <td>72</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>5715</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30905</th>\n",
       "      <td>57</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>668</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30906</th>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2971</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30907 rows × 17 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:09:16.630478Z",
     "start_time": "2024-11-01T14:09:16.603042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = dataset.iloc[:, :-1], dataset.iloc[:, -1]\n",
    "\n",
    "# Remove the bug in the dataset where the entire row has -9 values\n",
    "mask = ~(X == -9).all(axis=1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "y = y.replace({\"no\": 0, \"yes\": 1}).astype(int)"
   ],
   "id": "187e2a5342844a47",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r9/9n0wpy917zg1611cmsmqg0kr0000gn/T/ipykernel_54354/1292191429.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = y.replace({\"no\": 0, \"yes\": 1}).astype(int)\n"
     ]
    }
   ],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:09:24.816178Z",
     "start_time": "2024-11-01T14:09:24.780052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(X: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    The function will preprocess the data:\n",
    "    1. Categorical features will be label encoded (Boy->1, Girl ->2)\n",
    "    2. Numerical features will be scaled if the data is intended to be used for baseline. For cloud data set, no scaling will be preformed.\n",
    "\n",
    "    Return pd.Dataframe\n",
    "    \"\"\"\n",
    "    # Identify categorical and numeric columns\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "    # Initialize lists to store processed columns\n",
    "    processed_columns = []\n",
    "\n",
    "    # If there are categorical columns, apply one-hot encoding\n",
    "    if categorical_cols:\n",
    "        print(\"\\nEncoding categorical columns...\")\n",
    "        # onehot_encoder = OneHotEncoder(categories='auto', sparse=False)\n",
    "        # X_categorical = pd.DataFrame(onehot_encoder.fit_transform(X[categorical_cols]),\n",
    "        #                              columns=onehot_encoder.get_feature_names_out(categorical_cols))\n",
    "        label_encoder = LabelEncoder()\n",
    "        X_categorical = pd.DataFrame()\n",
    "        for col in categorical_cols:\n",
    "            X_categorical[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "        processed_columns.append(X_categorical)\n",
    "\n",
    "    # Apply standard scaling to the numeric columns\n",
    "    if numeric_cols:\n",
    "        print(\"\\nScaling numerical columns...\")\n",
    "        scaler = MinMaxScaler()\n",
    "        X_numeric = X[numeric_cols]\n",
    "        # X_numeric = pd.DataFrame(scaler.fit_transform(X[numeric_cols]), columns=numeric_cols, index=X.index)\n",
    "\n",
    "        processed_columns.append(X_numeric)\n",
    "\n",
    "    # Combine the processed columns\n",
    "    if processed_columns:\n",
    "        X_processed = pd.concat(processed_columns, axis=1)\n",
    "    else:\n",
    "        X_processed = X.copy()  # If there are no categorical or numeric columns, keep the original dataframe\n",
    "\n",
    "\n",
    "    return X_processed\n",
    "\n",
    "\n",
    "X = preprocess(X)"
   ],
   "id": "909539a4be92cf8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding categorical columns...\n",
      "\n",
      "Scaling numerical columns...\n"
     ]
    }
   ],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:10:31.022303Z",
     "start_time": "2024-11-01T14:10:31.016985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_sample, y_sample = X.iloc[100:200], y.iloc[100:200]\n",
    "y_sample.value_counts()"
   ],
   "id": "20fd537bed251cc5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    93\n",
       "1     7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 174
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:10:31.437970Z",
     "start_time": "2024-11-01T14:10:31.434122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test, y_test = X.iloc[:100], y.iloc[:100]\n",
    "y_test.value_counts()"
   ],
   "id": "d48d5a81179fad14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    89\n",
       "1    11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:14:17.434986Z",
     "start_time": "2024-11-01T14:14:16.896828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from keras.src.utils import to_categorical\n",
    "\n",
    "\n",
    "class DNNEmbedding(nn.Module):\n",
    "\n",
    "    name = \"dnn_embedding\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DNNEmbedding, self).__init__()\n",
    "\n",
    "        X, y = kwargs.get(\"X\"), kwargs.get(\"y\")\n",
    "        num_classes = len(set(y))\n",
    "        y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=X.shape[1]//2, activation='leaky_relu', name=\"embedding\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(units=num_classes, activation='softmax', name=\"output\"))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        early_stop = EarlyStopping(patience=2, monitor=\"loss\")\n",
    "\n",
    "        model.fit(X, y,validation_data=[X_test, to_categorical(y_test,2)], epochs=50, batch_size=8, callbacks=[early_stop])\n",
    "        self.model = model.layers[0]\n",
    "        self.output_shape = (1, X.shape[1]//2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if type(x) is pd.DataFrame:\n",
    "            x = x.to_numpy()\n",
    "\n",
    "        embedding = self.model(x)\n",
    "        return embedding\n",
    "\n",
    "\n",
    "embedding = DNNEmbedding(X=X_sample, y=y_sample)\n",
    "\n"
   ],
   "id": "d69d33283821949f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.3380 - loss: 1.4627 - val_accuracy: 0.7900 - val_loss: 1.5233\n",
      "Epoch 2/50\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5273 - loss: 1.1880 - val_accuracy: 0.7400 - val_loss: 1.1797\n",
      "Epoch 3/50\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5594 - loss: 1.1450 - val_accuracy: 0.7300 - val_loss: 0.9980\n",
      "Epoch 4/50\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5479 - loss: 1.0519 - val_accuracy: 0.7200 - val_loss: 0.9117\n",
      "Epoch 5/50\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.6318 - loss: 0.8408 - val_accuracy: 0.7300 - val_loss: 0.8696\n",
      "Epoch 6/50\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5805 - loss: 0.9940 - val_accuracy: 0.7500 - val_loss: 0.8073\n",
      "Epoch 7/50\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5916 - loss: 1.0276 - val_accuracy: 0.7500 - val_loss: 0.7545\n"
     ]
    }
   ],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:14:17.442422Z",
     "start_time": "2024-11-01T14:14:17.437906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from keras.src.layers import Input, Dense,  Flatten\n",
    "from keras.src.layers import BatchNormalization, Activation, Conv2DTranspose\n",
    "from keras.src.models import Model, Sequential\n",
    "from keras.src.layers import LeakyReLU, Reshape, Conv2D, UpSampling2D, ReLU\n",
    "\n",
    "class BaseEncryptor:\n",
    "\n",
    "    name: str\n",
    "\n",
    "    def __init__(self, input_shape=None, output_shape=None):\n",
    "        self.model = None\n",
    "        self.output_shape = output_shape\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build_generator(self, input_shape, output_shape):\n",
    "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
    "\n",
    "    def encode(self, inputs) -> np.array:\n",
    "        inputs = np.expand_dims(inputs, axis=0)\n",
    "        if self.model is None:\n",
    "            input_shape = inputs.shape[1:]\n",
    "            output_shape = self.output_shape or (1, inputs.shape[2])\n",
    "            self.model = self.build_generator(input_shape, output_shape)\n",
    "        return self.model(inputs).numpy()\n",
    "\n",
    "class DCEncryptor(BaseEncryptor):\n",
    "\n",
    "    name = \"dc\"\n",
    "\n",
    "    def build_generator(self, input_shape, output_shape):\n",
    "\n",
    "        input_layer = Input(shape=input_shape)\n",
    "        x = Flatten()(input_layer)\n",
    "\n",
    "        x = Dense(7*7*256, use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Reshape((7, 7, 256))(x)\n",
    "        x = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        x = Conv2DTranspose(16, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        output_image = Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='sigmoid')(x)\n",
    "\n",
    "        return Model(inputs=input_layer, outputs=output_image)\n",
    "    \n",
    "    \n",
    "encoder = DCEncryptor(output_shape=(1, 224, 224, 3))"
   ],
   "id": "821dca637b470fff",
   "outputs": [],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:16:30.884595Z",
     "start_time": "2024-11-01T14:16:29.620714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.api.applications import ResNet152V2, VGG16, EfficientNetB7\n",
    "# from keras.api.applications.vgg16 import preprocess_input\n",
    "from keras.api.applications.resnet_v2 import preprocess_input\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def pad(tensor, original, target=600):\n",
    "    pad_height = (target - original) // 2\n",
    "    pad_width = (target - original) // 2\n",
    "    padded_tensor = tf.pad(tensor, [[pad_height, pad_height], [pad_width, pad_width], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "    \n",
    "    # If the dimensions are odd, add an extra row/column to one side\n",
    "    if (600 - 224) % 2 != 0:\n",
    "        padded_tensor = tf.pad(padded_tensor, [[0, 1], [0, 1], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "        \n",
    "    return padded_tensor[np.newaxis, ...]\n",
    "\n",
    "\n",
    "class VGG16CloudModel:\n",
    "    name = \"vgg16\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = self.get_model()\n",
    "        self.input_shape = (224, 224, 3)\n",
    "        self.output_shape = (1,1000)\n",
    "\n",
    "    def fit(self, X_train, y_train, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def get_model(self):\n",
    "        # Load the pretrained VGG16 model with ImageNet weights\n",
    "        model = ResNet152V2(weights='imagenet')\n",
    "        return model\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.preprocess(X)\n",
    "        predictions = self.model.predict(X, verbose=None)\n",
    "        return predictions\n",
    "\n",
    "    def preprocess(self, X):\n",
    "        \n",
    "        X = X.copy()\n",
    "        # X = (X * 10000).astype(np.uint8)\n",
    "\n",
    "        if any(s < 224 for s in X.shape[1:3]):\n",
    "            # Pad the input to make its size equal to 224\n",
    "            padded_X = tf.image.resize_with_crop_or_pad(X, 224, 224)\n",
    "\n",
    "            # Ensure the input is properly preprocessed for VGG16\n",
    "            X = preprocess_input(padded_X.numpy())\n",
    "        else:\n",
    "            # If no padding is needed, directly preprocess the input\n",
    "            X = preprocess_input(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        return -1, -1\n",
    "    \n",
    "    \n",
    "cloud = VGG16CloudModel()\n"
   ],
   "id": "d010100e38c2c228",
   "outputs": [],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:18:20.880634Z",
     "start_time": "2024-11-01T14:18:19.542127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_encrypted, X_test_encrypted = [], []\n",
    "X_embed, X_test_embed = [], []\n",
    "for i, x in X_sample.iterrows():\n",
    "    \n",
    "    x_embed = embedding(x.values.reshape(1,-1))\n",
    "    X_embed.append(x_embed)\n",
    "    encrypted = encoder.encode(np.vstack(x_embed))\n",
    "\n",
    "    X_encrypted.append(encrypted)\n",
    "    \n",
    "for i,x in X_test.iterrows():\n",
    "    x_embed = embedding(x.values.reshape(1,-1))\n",
    "    X_test_embed.append(x_embed)\n",
    "    encrypted = encoder.encode(np.vstack(x_embed))\n",
    "    X_test_encrypted.append(encrypted)"
   ],
   "id": "a24845e75f0e88ae",
   "outputs": [],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:18:41.719123Z",
     "start_time": "2024-11-01T14:18:21.898624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = [\n",
    "    cloud.predict(x)\n",
    "    for x in X_encrypted\n",
    "]\n",
    "test_preds = [\n",
    "    cloud.predict(x)\n",
    "    for x in X_test_encrypted\n",
    "]"
   ],
   "id": "4fcdf191f61ce371",
   "outputs": [],
   "execution_count": 214
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T11:57:42.063197Z",
     "start_time": "2024-11-01T11:57:42.058288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# VGG no scalar\n",
    "# g = predictions[0]\n",
    "g.max()"
   ],
   "id": "c3fa1502e129309",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.075852744"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T11:50:17.268007Z",
     "start_time": "2024-11-01T11:50:17.263526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# VGG with scalar\n",
    "# v = predictions[0]\n",
    "v.max()"
   ],
   "id": "8b7f6edcd5df69e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07585279"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T11:56:45.158274Z",
     "start_time": "2024-11-01T11:56:45.154118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Resnet no scalar\n",
    "# p = predictions[0]\n",
    "p.max()"
   ],
   "id": "8d741a6deeed0544",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T11:52:12.693092Z",
     "start_time": "2024-11-01T11:52:12.691039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Resnet with scalar\n",
    "# h = predictions[0]\n",
    "h.max()"
   ],
   "id": "1ba14b38c7f34b1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63243544"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:23:48.002103Z",
     "start_time": "2024-11-01T14:23:47.978021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from keras.src.models import Model\n",
    "from keras.src.layers import Dense, Dropout, Input,  BatchNormalization\n",
    "from keras.src.metrics import F1Score\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetworkInternalModel(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.batch_size = 8\n",
    "        self.dropout_rate = 0.3\n",
    "        self.epochs = 100\n",
    "        self.model: Model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y_onehot = to_categorical(y , 2)\n",
    "        lr_scheduler = LearningRateScheduler(lambda epoch: 0.0001 * (0.9 ** epoch))\n",
    "        early_stopping = EarlyStopping(patience=3, monitor='loss')\n",
    "        self.model.fit(X, y_onehot, epochs=self.epochs, batch_size=self.batch_size, callbacks=[lr_scheduler, early_stopping])\n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = self.model.predict(X)\n",
    "        return np.argmax(prediction, axis=1)\n",
    "\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        if len(y.shape) == 2:\n",
    "            y = np.argmax(y, axis=1)\n",
    "\n",
    "        pred = self.predict(X)\n",
    "        return accuracy_score(y, pred), f1_score(y, pred, average='weighted')\n",
    "\n",
    "\n",
    "class DenseInternalModel(NeuralNetworkInternalModel):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = \"neural_network\"\n",
    "        num_classes = kwargs.get(\"num_classes\")\n",
    "        input_shape = kwargs.get(\"input_shape\")\n",
    "        self.model = self.get_model(num_classes=num_classes, input_shape=input_shape)\n",
    "\n",
    "    def get_model(self, num_classes, input_shape):\n",
    "        # Build the model\n",
    "        inputs = Input(shape=(input_shape,))  # Dynamic input shape\n",
    "\n",
    "        # Define the hidden layers\n",
    "        x = BatchNormalization()(inputs)\n",
    "        x = Dense(units=128, activation='leaky_relu')(x)\n",
    "        x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        # Define the output layer\n",
    "        outputs = Dense(units=num_classes, activation='softmax')(x)\n",
    "\n",
    "        # Create the model\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        # Compile the model with F1 Score\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy', F1Score()]\n",
    "                      )\n",
    "\n",
    "        return model\n",
    "    \n",
    "iim = DenseInternalModel(num_classes=2, input_shape=predictions[0].shape[1])"
   ],
   "id": "d539c7408c4e256",
   "outputs": [],
   "execution_count": 230
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:23:49.151556Z",
     "start_time": "2024-11-01T14:23:48.344983Z"
    }
   },
   "cell_type": "code",
   "source": "iim.fit(np.vstack(predictions), y_sample)",
   "id": "7e93e72b93130990",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8866 - f1_score: 0.4693 - loss: 0.6842 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 968us/step - accuracy: 0.9092 - f1_score: 0.4760 - loss: 0.6461 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 768us/step - accuracy: 0.9357 - f1_score: 0.4833 - loss: 0.5941 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 943us/step - accuracy: 0.9468 - f1_score: 0.4863 - loss: 0.5305 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 901us/step - accuracy: 0.8933 - f1_score: 0.4707 - loss: 0.5045 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 844us/step - accuracy: 0.9440 - f1_score: 0.4855 - loss: 0.4253 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 873us/step - accuracy: 0.9260 - f1_score: 0.4808 - loss: 0.3997 - learning_rate: 5.3144e-05\n",
      "Epoch 8/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 865us/step - accuracy: 0.9475 - f1_score: 0.4864 - loss: 0.3399 - learning_rate: 4.7830e-05\n",
      "Epoch 9/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 891us/step - accuracy: 0.9463 - f1_score: 0.4861 - loss: 0.3146 - learning_rate: 4.3047e-05\n",
      "Epoch 10/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 838us/step - accuracy: 0.9316 - f1_score: 0.4822 - loss: 0.3085 - learning_rate: 3.8742e-05\n",
      "Epoch 11/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 966us/step - accuracy: 0.9059 - f1_score: 0.4753 - loss: 0.3404 - learning_rate: 3.4868e-05\n",
      "Epoch 12/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 878us/step - accuracy: 0.9688 - f1_score: 0.4919 - loss: 0.2321 - learning_rate: 3.1381e-05\n",
      "Epoch 13/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 908us/step - accuracy: 0.9674 - f1_score: 0.4917 - loss: 0.2214 - learning_rate: 2.8243e-05\n",
      "Epoch 14/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 834us/step - accuracy: 0.9245 - f1_score: 0.4803 - loss: 0.2878 - learning_rate: 2.5419e-05\n",
      "Epoch 15/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 933us/step - accuracy: 0.9478 - f1_score: 0.4865 - loss: 0.2559 - learning_rate: 2.2877e-05\n",
      "Epoch 16/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 932us/step - accuracy: 0.9156 - f1_score: 0.4779 - loss: 0.3117 - learning_rate: 2.0589e-05\n",
      "Epoch 17/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 955us/step - accuracy: 0.8776 - f1_score: 0.4670 - loss: 0.3749 - learning_rate: 1.8530e-05\n",
      "Epoch 18/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 893us/step - accuracy: 0.9397 - f1_score: 0.4844 - loss: 0.2542 - learning_rate: 1.6677e-05\n",
      "Epoch 19/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 846us/step - accuracy: 0.9417 - f1_score: 0.4849 - loss: 0.2466 - learning_rate: 1.5009e-05\n",
      "Epoch 20/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 872us/step - accuracy: 0.9124 - f1_score: 0.4771 - loss: 0.3060 - learning_rate: 1.3509e-05\n",
      "Epoch 21/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 870us/step - accuracy: 0.9206 - f1_score: 0.4793 - loss: 0.2953 - learning_rate: 1.2158e-05\n",
      "Epoch 22/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 905us/step - accuracy: 0.9508 - f1_score: 0.4873 - loss: 0.2124 - learning_rate: 1.0942e-05\n",
      "Epoch 23/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 838us/step - accuracy: 0.9012 - f1_score: 0.4736 - loss: 0.3179 - learning_rate: 9.8477e-06\n",
      "Epoch 24/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 846us/step - accuracy: 0.9134 - f1_score: 0.4772 - loss: 0.2947 - learning_rate: 8.8629e-06\n",
      "Epoch 25/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 898us/step - accuracy: 0.9212 - f1_score: 0.4794 - loss: 0.2826 - learning_rate: 7.9766e-06\n"
     ]
    }
   ],
   "execution_count": 231
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:23:49.981292Z",
     "start_time": "2024-11-01T14:23:49.923191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "iim.evaluate(np.vstack(test_preds), y_test)\n",
    "# resnet"
   ],
   "id": "d7373d642a68e700",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.89, 0.8382010582010581)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 232
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:23:51.145058Z",
     "start_time": "2024-11-01T14:23:51.138911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_pred_embed, X_test_pred_embed = [], []\n",
    "for embed, pred in zip(X_embed, predictions):\n",
    "    X_pred_embed.append(np.hstack([embed, pred]))\n",
    "    \n",
    "for embed, pred in zip(X_test_embed, test_preds):\n",
    "    X_test_pred_embed.append(np.hstack([embed, pred]))"
   ],
   "id": "907d450011a19e50",
   "outputs": [],
   "execution_count": 233
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:23:52.622137Z",
     "start_time": "2024-11-01T14:23:51.713117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "iim = DenseInternalModel(num_classes=2, input_shape=X_pred_embed[0].shape[1])\n",
    "\n",
    "iim.fit(np.vstack(X_pred_embed), y_sample)\n"
   ],
   "id": "663d68d28de79ede",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.4541 - f1_score: 0.3110 - loss: 0.6815 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 964us/step - accuracy: 0.7223 - f1_score: 0.4191 - loss: 0.6371 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9319 - f1_score: 0.4823 - loss: 0.5800 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9587 - f1_score: 0.4894 - loss: 0.5414 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9308 - f1_score: 0.4820 - loss: 0.4981 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9269 - f1_score: 0.4810 - loss: 0.4703 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9139 - f1_score: 0.4774 - loss: 0.4219 - learning_rate: 5.3144e-05\n",
      "Epoch 8/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9211 - f1_score: 0.4794 - loss: 0.3939 - learning_rate: 4.7830e-05\n",
      "Epoch 9/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9214 - f1_score: 0.4795 - loss: 0.3539 - learning_rate: 4.3047e-05\n",
      "Epoch 10/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 963us/step - accuracy: 0.9455 - f1_score: 0.4859 - loss: 0.3134 - learning_rate: 3.8742e-05\n",
      "Epoch 11/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 964us/step - accuracy: 0.9326 - f1_score: 0.4825 - loss: 0.3068 - learning_rate: 3.4868e-05\n",
      "Epoch 12/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 815us/step - accuracy: 0.9088 - f1_score: 0.4760 - loss: 0.3303 - learning_rate: 3.1381e-05\n",
      "Epoch 13/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 826us/step - accuracy: 0.9628 - f1_score: 0.4904 - loss: 0.2441 - learning_rate: 2.8243e-05\n",
      "Epoch 14/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9348 - f1_score: 0.4831 - loss: 0.2654 - learning_rate: 2.5419e-05\n",
      "Epoch 15/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9326 - f1_score: 0.4825 - loss: 0.2768 - learning_rate: 2.2877e-05\n",
      "Epoch 16/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9375 - f1_score: 0.4838 - loss: 0.2612 - learning_rate: 2.0589e-05\n",
      "Epoch 17/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9326 - f1_score: 0.4825 - loss: 0.2733 - learning_rate: 1.8530e-05\n",
      "Epoch 18/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 926us/step - accuracy: 0.9182 - f1_score: 0.4786 - loss: 0.2929 - learning_rate: 1.6677e-05\n",
      "Epoch 19/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 966us/step - accuracy: 0.9236 - f1_score: 0.4800 - loss: 0.2849 - learning_rate: 1.5009e-05\n",
      "Epoch 20/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 930us/step - accuracy: 0.9345 - f1_score: 0.4830 - loss: 0.2590 - learning_rate: 1.3509e-05\n",
      "Epoch 21/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 918us/step - accuracy: 0.9562 - f1_score: 0.4887 - loss: 0.2091 - learning_rate: 1.2158e-05\n",
      "Epoch 22/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9097 - f1_score: 0.4763 - loss: 0.2868 - learning_rate: 1.0942e-05\n",
      "Epoch 23/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 918us/step - accuracy: 0.9172 - f1_score: 0.4782 - loss: 0.2802 - learning_rate: 9.8477e-06\n",
      "Epoch 24/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 911us/step - accuracy: 0.9252 - f1_score: 0.4805 - loss: 0.2709 - learning_rate: 8.8629e-06\n",
      "Epoch 25/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 948us/step - accuracy: 0.8566 - f1_score: 0.4602 - loss: 0.4102 - learning_rate: 7.9766e-06\n"
     ]
    }
   ],
   "execution_count": 234
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:23:53.251576Z",
     "start_time": "2024-11-01T14:23:53.201959Z"
    }
   },
   "cell_type": "code",
   "source": "iim.evaluate(np.vstack(X_test_pred_embed), y_test)",
   "id": "baff53803e2bbdd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.89, 0.8382010582010581)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 235
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:23:40.026026Z",
     "start_time": "2024-11-01T14:23:39.451306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline = DenseInternalModel(num_classes=2, input_shape=X_sample.shape[1])\n",
    "baseline.fit(X_sample, y_sample)\n",
    "baseline.evaluate(X_test, y_test)"
   ],
   "id": "71d0a5c5364bd012",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - accuracy: 0.3412 - f1_score: 0.2550 - loss: 0.8396 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - accuracy: 0.5414 - f1_score: 0.3965 - loss: 0.7104 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 574us/step - accuracy: 0.5402 - f1_score: 0.4024 - loss: 0.7022 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 544us/step - accuracy: 0.5467 - f1_score: 0.3630 - loss: 0.7312 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 536us/step - accuracy: 0.5459 - f1_score: 0.3521 - loss: 0.7285 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 501us/step - accuracy: 0.6283 - f1_score: 0.3904 - loss: 0.6255 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 576us/step - accuracy: 0.5773 - f1_score: 0.3658 - loss: 0.6511 - learning_rate: 5.3144e-05\n",
      "Epoch 8/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 453us/step - accuracy: 0.5375 - f1_score: 0.3817 - loss: 0.6977 - learning_rate: 4.7830e-05\n",
      "Epoch 9/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 511us/step - accuracy: 0.5977 - f1_score: 0.3735 - loss: 0.7363 - learning_rate: 4.3047e-05\n",
      "Epoch 10/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 485us/step - accuracy: 0.6732 - f1_score: 0.4444 - loss: 0.6370 - learning_rate: 3.8742e-05\n",
      "Epoch 11/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 517us/step - accuracy: 0.7043 - f1_score: 0.4396 - loss: 0.6192 - learning_rate: 3.4868e-05\n",
      "Epoch 12/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 473us/step - accuracy: 0.7223 - f1_score: 0.4401 - loss: 0.5862 - learning_rate: 3.1381e-05\n",
      "Epoch 13/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 471us/step - accuracy: 0.6069 - f1_score: 0.4271 - loss: 0.6506 - learning_rate: 2.8243e-05\n",
      "Epoch 14/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 436us/step - accuracy: 0.7207 - f1_score: 0.4184 - loss: 0.6219 - learning_rate: 2.5419e-05\n",
      "Epoch 15/100\n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 447us/step - accuracy: 0.6999 - f1_score: 0.4116 - loss: 0.6205 - learning_rate: 2.2877e-05\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.69, 0.7267455621301775)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 229
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6031e133a404e49e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
