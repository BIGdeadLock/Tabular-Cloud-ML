{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-22T13:02:49.644838Z",
     "start_time": "2024-12-22T13:02:48.154658Z"
    }
   },
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:03:30.249169Z",
     "start_time": "2024-12-22T13:03:30.245264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECT_PATH = os.getcwd()\n",
    "PROJECT_PATH = os.path.join(PROJECT_PATH, \"..\")\n",
    "MODELS_DIR = pathlib.Path(PROJECT_PATH) / \"store\" / \"models\"\n",
    "\n",
    "DATASET_DIR = pathlib.Path(PROJECT_PATH) / \"data\""
   ],
   "id": "982312657be336ff",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:03:31.108450Z",
     "start_time": "2024-12-22T13:03:30.452877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(DATASET_DIR / \"bank_marketing\"/ \"dataset.csv\")\n",
    "dataset"
   ],
   "id": "a240984fa1f517ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       age           job   marital  education default  balance housing loan  \\\n",
       "0       27    management    single  secondary      no       35      no   no   \n",
       "1       54   blue-collar   married    primary      no      466      no   no   \n",
       "2       43   blue-collar   married  secondary      no      105      no  yes   \n",
       "3       31    technician    single  secondary      no       19      no   no   \n",
       "4       27    technician    single  secondary      no      126     yes  yes   \n",
       "...    ...           ...       ...        ...     ...      ...     ...  ...   \n",
       "30902   51    technician   married   tertiary      no      825      no   no   \n",
       "30903   71       retired  divorced    primary      no     1729      no   no   \n",
       "30904   72       retired   married  secondary      no     5715      no   no   \n",
       "30905   57   blue-collar   married  secondary      no      668      no   no   \n",
       "30906   37  entrepreneur   married  secondary      no     2971      no   no   \n",
       "\n",
       "         contact  day_of_week month  duration  campaign  pdays  previous  \\\n",
       "0       cellular            4   jul       255         1     -1         0   \n",
       "1       cellular            4   jul       297         1     -1         0   \n",
       "2       cellular            4   jul       668         2     -1         0   \n",
       "3      telephone            4   jul        65         2     -1         0   \n",
       "4       cellular            4   jul       436         4     -1         0   \n",
       "...          ...          ...   ...       ...       ...    ...       ...   \n",
       "30902   cellular           17   nov       977         3     -1         0   \n",
       "30903   cellular           17   nov       456         2     -1         0   \n",
       "30904   cellular           17   nov      1127         5    184         3   \n",
       "30905  telephone           17   nov       508         4     -1         0   \n",
       "30906   cellular           17   nov       361         2    188        11   \n",
       "\n",
       "      poutcome    y  \n",
       "0          NaN   no  \n",
       "1          NaN   no  \n",
       "2          NaN   no  \n",
       "3          NaN   no  \n",
       "4          NaN   no  \n",
       "...        ...  ...  \n",
       "30902      NaN  yes  \n",
       "30903      NaN  yes  \n",
       "30904  success  yes  \n",
       "30905      NaN   no  \n",
       "30906    other   no  \n",
       "\n",
       "[30907 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>35</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>466</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>105</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>668</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>19</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>126</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>436</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30902</th>\n",
       "      <td>51</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>825</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30903</th>\n",
       "      <td>71</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1729</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30904</th>\n",
       "      <td>72</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>5715</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30905</th>\n",
       "      <td>57</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>668</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30906</th>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2971</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30907 rows × 17 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:03:31.151953Z",
     "start_time": "2024-12-22T13:03:31.134172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = dataset.iloc[:, :-1], dataset.iloc[:, -1]\n",
    "\n",
    "# Remove the bug in the dataset where the entire row has -9 values\n",
    "mask = ~(X == -9).all(axis=1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "y = y.replace({\"no\": 0, \"yes\": 1}).astype(int)"
   ],
   "id": "187e2a5342844a47",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r9/9n0wpy917zg1611cmsmqg0kr0000gn/T/ipykernel_42233/1292191429.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = y.replace({\"no\": 0, \"yes\": 1}).astype(int)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:03:31.194832Z",
     "start_time": "2024-12-22T13:03:31.169488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(X: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    The function will preprocess the data:\n",
    "    1. Categorical features will be label encoded (Boy->1, Girl ->2)\n",
    "    2. Numerical features will be scaled if the data is intended to be used for baseline. For cloud data set, no scaling will be preformed.\n",
    "\n",
    "    Return pd.Dataframe\n",
    "    \"\"\"\n",
    "    # Identify categorical and numeric columns\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "    # Initialize lists to store processed columns\n",
    "    processed_columns = []\n",
    "\n",
    "    # If there are categorical columns, apply one-hot encoding\n",
    "    if categorical_cols:\n",
    "        print(\"\\nEncoding categorical columns...\")\n",
    "        # onehot_encoder = OneHotEncoder(categories='auto', sparse=False)\n",
    "        # X_categorical = pd.DataFrame(onehot_encoder.fit_transform(X[categorical_cols]),\n",
    "        #                              columns=onehot_encoder.get_feature_names_out(categorical_cols))\n",
    "        label_encoder = LabelEncoder()\n",
    "        X_categorical = pd.DataFrame()\n",
    "        for col in categorical_cols:\n",
    "            X_categorical[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "        processed_columns.append(X_categorical)\n",
    "\n",
    "    # Apply standard scaling to the numeric columns\n",
    "    if numeric_cols:\n",
    "        print(\"\\nScaling numerical columns...\")\n",
    "        scaler = MinMaxScaler()\n",
    "        X_numeric = X[numeric_cols]\n",
    "        # X_numeric = pd.DataFrame(scaler.fit_transform(X[numeric_cols]), columns=numeric_cols, index=X.index)\n",
    "\n",
    "        processed_columns.append(X_numeric)\n",
    "\n",
    "    # Combine the processed columns\n",
    "    if processed_columns:\n",
    "        X_processed = pd.concat(processed_columns, axis=1)\n",
    "    else:\n",
    "        X_processed = X.copy()  # If there are no categorical or numeric columns, keep the original dataframe\n",
    "\n",
    "\n",
    "    return X_processed\n",
    "\n",
    "\n",
    "X = preprocess(X)"
   ],
   "id": "909539a4be92cf8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding categorical columns...\n",
      "\n",
      "Scaling numerical columns...\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:03:31.656045Z",
     "start_time": "2024-12-22T13:03:31.652970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_sample, y_sample = X.iloc[2000:22000], y.iloc[2000:22000]\n",
    "y_sample.value_counts()"
   ],
   "id": "20fd537bed251cc5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    18287\n",
       "1     1713\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:03:32.018089Z",
     "start_time": "2024-12-22T13:03:32.014070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test, y_test = X.iloc[:2000], y.iloc[:2000]\n",
    "y_test.value_counts()"
   ],
   "id": "d48d5a81179fad14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    1878\n",
       "1     122\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:08:53.901574Z",
     "start_time": "2024-12-22T13:08:47.071572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn, tensorflow as tf\n",
    "from keras.src.utils import to_categorical\n",
    "from keras.src.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.src.callbacks import EarlyStopping\n",
    "from keras.src import Sequential\n",
    "\n",
    "\n",
    "class DNNEmbedding(nn.Module):\n",
    "\n",
    "    name = \"dnn_embedding\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DNNEmbedding, self).__init__()\n",
    "\n",
    "        X, y = kwargs.get(\"X\"), kwargs.get(\"y\")\n",
    "        num_classes = len(set(y))\n",
    "        y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=X.shape[1]//2, activation='tanh', name=\"embedding\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(units=num_classes, activation='softmax', name=\"output\"))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        early_stop = EarlyStopping(patience=2, monitor=\"loss\")\n",
    "\n",
    "        model.fit(X, y,validation_data=[X_test, to_categorical(y_test,2)], epochs=50, batch_size=8, callbacks=[early_stop])\n",
    "        self.model = model.layers[0]\n",
    "        self.output_shape = (1, X.shape[1]//2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if type(x) is pd.DataFrame:\n",
    "            x = x.to_numpy()\n",
    "\n",
    "        embedding = self.model(x)\n",
    "        return embedding\n",
    "\n",
    "\n",
    "# Code to run on CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    \n",
    "    embedding = DNNEmbedding(X=X_sample, y=y_sample)\n",
    "\n"
   ],
   "id": "d69d33283821949f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 271us/step - accuracy: 0.8278 - loss: 0.4450 - val_accuracy: 0.9390 - val_loss: 0.2306\n",
      "Epoch 2/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 248us/step - accuracy: 0.9123 - loss: 0.2974 - val_accuracy: 0.9385 - val_loss: 0.2333\n",
      "Epoch 3/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 247us/step - accuracy: 0.9163 - loss: 0.2813 - val_accuracy: 0.9385 - val_loss: 0.2209\n",
      "Epoch 4/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 246us/step - accuracy: 0.9151 - loss: 0.2850 - val_accuracy: 0.9380 - val_loss: 0.2216\n",
      "Epoch 5/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 245us/step - accuracy: 0.9170 - loss: 0.2745 - val_accuracy: 0.9385 - val_loss: 0.2132\n",
      "Epoch 6/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 267us/step - accuracy: 0.9159 - loss: 0.2741 - val_accuracy: 0.9390 - val_loss: 0.1961\n",
      "Epoch 7/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 245us/step - accuracy: 0.9168 - loss: 0.2643 - val_accuracy: 0.9390 - val_loss: 0.1848\n",
      "Epoch 8/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 266us/step - accuracy: 0.9137 - loss: 0.2595 - val_accuracy: 0.9390 - val_loss: 0.1702\n",
      "Epoch 9/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 256us/step - accuracy: 0.9136 - loss: 0.2582 - val_accuracy: 0.9385 - val_loss: 0.1819\n",
      "Epoch 10/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 255us/step - accuracy: 0.9131 - loss: 0.2653 - val_accuracy: 0.9480 - val_loss: 0.1954\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:15:37.732422Z",
     "start_time": "2024-12-22T13:15:37.716671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from keras.src.layers import Input, Dense,  Flatten\n",
    "from keras.src.layers import BatchNormalization, Activation, Conv2DTranspose\n",
    "from keras.src.models import Model, Sequential\n",
    "from keras.src.layers import LeakyReLU, Reshape, Conv2D, UpSampling2D, ReLU\n",
    "\n",
    "class BaseEncryptor:\n",
    "\n",
    "    name: str\n",
    "\n",
    "    def __init__(self, input_shape=None, output_shape=None):\n",
    "        self.model = None\n",
    "        self.output_shape = output_shape\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build_generator(self, input_shape, output_shape):\n",
    "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
    "\n",
    "    def encode(self, inputs) -> np.array:\n",
    "        inputs = np.expand_dims(inputs, axis=0)\n",
    "        if self.model is None:\n",
    "            input_shape = inputs.shape[1:]\n",
    "            output_shape = self.output_shape or (1, inputs.shape[2])\n",
    "            self.model = self.build_generator(input_shape, output_shape)\n",
    "        return self.model(inputs).numpy()\n",
    "\n",
    "class DCEncryptor(BaseEncryptor):\n",
    "\n",
    "    name = \"dc\"\n",
    "    \n",
    "    def build_generator1(self, input_shape, output_shape):\n",
    "        G = Sequential()\n",
    "        G.add(Reshape(target_shape=[1, 1, self.input_shape], input_shape=[self.input_shape]))\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 1x1x4096\n",
    "        G.add(Conv2DTranspose(filters=64, kernel_size=4))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 0, Activations index: 1\n",
    "\n",
    "        # 4x4x64\n",
    "        G.add(Conv2D(filters=64, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 2, Activations index: 5\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 8x8x64\n",
    "        G.add(Conv2D(filters=32, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 8, Activations index: 9\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 16x16x32\n",
    "        G.add(Conv2D(filters=16, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 14, Activations index: 13\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 32x32x16\n",
    "        G.add(Conv2D(filters=8, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 20, Activations index: 17\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 64x64x8\n",
    "        G.add(Conv2D(filters=4, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 26, Activations index: 21\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 128x128x4\n",
    "        G.add(Conv2D(filters=3, kernel_size=4, padding='same'))\n",
    "        G.add(Activation('sigmoid'))\n",
    "        \n",
    "        return G\n",
    "        \n",
    "    def build_generator(self, input_shape, output_shape):\n",
    "\n",
    "        input_layer = Input(shape=input_shape)\n",
    "        x = Flatten()(input_layer)\n",
    "    \n",
    "        x = Dense(4*4*256, use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "    \n",
    "        x = Reshape((4, 4, 256))(x)\n",
    "    \n",
    "        x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "    \n",
    "        x = Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "    \n",
    "        x = Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "    \n",
    "        output_image = Conv2DTranspose(3, (4, 4), strides=(1, 1), padding='same', use_bias=False, activation='sigmoid')(x)\n",
    "    \n",
    "        return Model(inputs=input_layer, outputs=output_image)\n",
    "        \n",
    "    def build_generator_vgg224(self, input_shape, output_shape):\n",
    "\n",
    "        input_layer = Input(shape=input_shape)\n",
    "        x = Flatten()(input_layer)\n",
    "\n",
    "        x = Dense(7*7*256, use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Reshape((7, 7, 256))(x)\n",
    "        x = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        x = Conv2DTranspose(16, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        output_image = Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n",
    "\n",
    "        return Model(inputs=input_layer, outputs=output_image)\n",
    "    \n",
    "    \n",
    "encoder = DCEncryptor(output_shape=(1, 32, 32, 4))"
   ],
   "id": "821dca637b470fff",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:16:00.171164Z",
     "start_time": "2024-12-22T13:15:59.772319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.api.applications import ResNet152V2, VGG16, EfficientNetB7\n",
    "# from keras.api.applications.vgg16 import preprocess_input\n",
    "from keras.api.applications.resnet_v2 import preprocess_input\n",
    "import tensorflow as tf\n",
    "from keras.api.models import load_model\n",
    "\n",
    "\n",
    "def pad(tensor, original, target=600):\n",
    "    pad_height = (target - original) // 2\n",
    "    pad_width = (target - original) // 2\n",
    "    padded_tensor = tf.pad(tensor, [[pad_height, pad_height], [pad_width, pad_width], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "    # If the dimensions are odd, add an extra row/column to one side\n",
    "    if (600 - 224) % 2 != 0:\n",
    "        padded_tensor = tf.pad(padded_tensor, [[0, 1], [0, 1], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "    return padded_tensor[np.newaxis, ...]\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Assuming 'image' is your input tensor\n",
    "    resized_image = tf.image.resize(image, (32, 32))\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "class VGG16CloudModel:\n",
    "    name = \"vgg16\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = self.get_model()\n",
    "        self.input_shape = (32,32,3)#(224, 224, 3)\n",
    "        self.output_shape = (1,1000)\n",
    "\n",
    "    def fit(self, X_train, y_train, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def get_model(self):\n",
    "        # Load the pretrained VGG16 model with ImageNet weights\n",
    "        model = load_model(\"/Users/eden.yavin/Projects/Tabular-Cloud-ML/store/models/cifar100_vgg.keras\") #VGG16(weights='imagenet')\n",
    "        return model\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.preprocess(X)\n",
    "        predictions = self.model.predict(X, verbose=None)\n",
    "        return predictions\n",
    "\n",
    "    def preprocess(self, X):\n",
    "        \n",
    "        X = X.copy()\n",
    "        # X = (X * 10000).astype(np.uint8)\n",
    "\n",
    "        if any(s < 32 for s in X.shape[1:3]):\n",
    "            # Pad the input to make its size equal to 224\n",
    "            padded_X = tf.image.resize_with_crop_or_pad(X, 32, 32)\n",
    "\n",
    "            # Ensure the input is properly preprocessed for VGG16\n",
    "            X = preprocess_input(padded_X.numpy())\n",
    "        else:\n",
    "            # If no padding is needed, directly preprocess the input\n",
    "            X = preprocess_input(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    \n",
    "    \n",
    "cloud = VGG16CloudModel()\n"
   ],
   "id": "d010100e38c2c228",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:18:24.971957Z",
     "start_time": "2024-12-22T13:16:19.666057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "X_encrypted, X_test_encrypted = [], []\n",
    "X_embed, X_test_embed = [], []\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "        \n",
    "    for i, x in tqdm(X_sample.iterrows(), total=len(X_sample)):\n",
    "        \n",
    "        x_embed = embedding(x.values.reshape(1,-1))\n",
    "        X_embed.append(x_embed)\n",
    "        encrypted = encoder.encode(np.vstack(x_embed))\n",
    "    \n",
    "        X_encrypted.append(encrypted)\n",
    "        \n",
    "    for i,x in tqdm(X_test.iterrows(), total=len(X_test)):\n",
    "        x_embed = embedding(x.values.reshape(1,-1))\n",
    "        X_test_embed.append(x_embed)\n",
    "        encrypted = encoder.encode(np.vstack(x_embed))\n",
    "        X_test_encrypted.append(encrypted)"
   ],
   "id": "a24845e75f0e88ae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:54<00:00, 175.22it/s]\n",
      "100%|██████████| 2000/2000 [00:11<00:00, 180.10it/s]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:25:39.053214Z",
     "start_time": "2024-12-22T13:18:25.018334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.device('/GPU:0'):\n",
    "\n",
    "    predictions = [\n",
    "        cloud.predict(x)\n",
    "        for x in tqdm(X_encrypted, total=len(X_encrypted))\n",
    "    ]\n",
    "    test_preds = [\n",
    "        cloud.predict(x)\n",
    "        for x in tqdm(X_test_encrypted, total=len(X_test_encrypted))\n",
    "]"
   ],
   "id": "4fcdf191f61ce371",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]2024-12-22 15:18:25.075042: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "100%|██████████| 20000/20000 [06:34<00:00, 50.72it/s]\n",
      "100%|██████████| 2000/2000 [00:39<00:00, 50.39it/s]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:29:53.103787Z",
     "start_time": "2024-12-22T13:29:52.382295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from keras.src.models import Model\n",
    "from keras.src.layers import Dense, Dropout, Input,  BatchNormalization\n",
    "from keras.src.metrics import F1Score\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetworkInternalModel(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.batch_size = 8\n",
    "        self.dropout_rate = 0.3\n",
    "        self.epochs = 100\n",
    "        self.model: Model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y_onehot = to_categorical(y , 2)\n",
    "        lr_scheduler = LearningRateScheduler(lambda epoch: 0.0001 * (0.9 ** epoch))\n",
    "        early_stopping = EarlyStopping(patience=3, monitor='loss')\n",
    "        self.model.fit(X, y_onehot, epochs=self.epochs, batch_size=self.batch_size, callbacks=[lr_scheduler, early_stopping])\n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = self.model.predict(X)\n",
    "        return np.argmax(prediction, axis=1)\n",
    "\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        if len(y.shape) == 2:\n",
    "            y = np.argmax(y, axis=1)\n",
    "\n",
    "        pred = self.predict(X)\n",
    "        return accuracy_score(y, pred), f1_score(y, pred, average='weighted')\n",
    "\n"
   ],
   "id": "d539c7408c4e256",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using one vector",
   "id": "8ab8b36d3ad9275"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:31:03.717587Z",
     "start_time": "2024-12-22T13:31:03.687770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class DenseInternalModel(NeuralNetworkInternalModel):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = \"neural_network\"\n",
    "        num_classes = kwargs.get(\"num_classes\")\n",
    "        input_shape = kwargs.get(\"input_shape\")\n",
    "        self.model = self.get_model(num_classes=num_classes, input_shape=input_shape)\n",
    "\n",
    "    def get_model(self, num_classes, input_shape):\n",
    "        # Build the model\n",
    "        inputs = Input(shape=(input_shape,))  # Dynamic input shape\n",
    "\n",
    "        # Define the hidden layers\n",
    "        x = BatchNormalization()(inputs)\n",
    "        x = Dense(units=128, activation='leaky_relu')(x)\n",
    "        x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        # Define the output layer\n",
    "        outputs = Dense(units=num_classes, activation='softmax')(x)\n",
    "\n",
    "        # Create the model\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        # Compile the model with F1 Score\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy', F1Score()]\n",
    "                      )\n",
    "\n",
    "        return model\n",
    "    "
   ],
   "id": "2f2288e0568e144c",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using Pred Vector",
   "id": "53b159c52929e7f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:31:50.241146Z",
     "start_time": "2024-12-22T13:31:44.576358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Code to run on CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    iim = DenseInternalModel(num_classes=2, input_shape=predictions[0].shape[1])\n",
    "    iim.fit(np.vstack(predictions), y_sample)\n",
    "    print(\"--------PERFORMANCE-------\")\n",
    "    print(iim.evaluate(np.vstack(test_preds), y_test))"
   ],
   "id": "7e93e72b93130990",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 300us/step - accuracy: 0.9143 - f1_score: 0.4809 - loss: 0.3684 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 298us/step - accuracy: 0.9160 - f1_score: 0.4781 - loss: 0.2904 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 299us/step - accuracy: 0.9141 - f1_score: 0.4775 - loss: 0.2949 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 300us/step - accuracy: 0.9172 - f1_score: 0.4784 - loss: 0.2866 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 299us/step - accuracy: 0.9119 - f1_score: 0.4769 - loss: 0.2997 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 301us/step - accuracy: 0.9170 - f1_score: 0.4784 - loss: 0.2871 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 297us/step - accuracy: 0.9164 - f1_score: 0.4782 - loss: 0.2892 - learning_rate: 5.3144e-05\n",
      "--------PERFORMANCE-------\n",
      "\u001B[1m63/63\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 396us/step\n",
      "(0.939, 0.9094595152140278)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using Both Prediction and Embedding as One Vector",
   "id": "840752add63aeb4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:32:15.595428Z",
     "start_time": "2024-12-22T13:32:11.602546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_pred_embed, X_test_pred_embed = [], []\n",
    "for embed, pred in zip(X_embed, predictions):\n",
    "    X_pred_embed.append(np.hstack([embed, pred]))\n",
    "    \n",
    "for embed, pred in zip(X_test_embed, test_preds):\n",
    "    X_test_pred_embed.append(np.hstack([embed, pred]))"
   ],
   "id": "907d450011a19e50",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:33:52.581765Z",
     "start_time": "2024-12-22T13:33:38.010247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    \n",
    "    iim = DenseInternalModel(num_classes=2, input_shape=X_pred_embed[0].shape[1])\n",
    "    iim.fit(np.vstack(X_pred_embed), y_sample)\n",
    "    print(\"--------PERFORMANCE-------\")\n",
    "    print(iim.evaluate(np.vstack(X_test_pred_embed), y_test))\n"
   ],
   "id": "663d68d28de79ede",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 316us/step - accuracy: 0.8703 - f1_score: 0.4862 - loss: 0.3651 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 343us/step - accuracy: 0.9161 - f1_score: 0.5385 - loss: 0.2570 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 310us/step - accuracy: 0.9177 - f1_score: 0.5694 - loss: 0.2505 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 313us/step - accuracy: 0.9192 - f1_score: 0.5730 - loss: 0.2511 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 327us/step - accuracy: 0.9140 - f1_score: 0.5575 - loss: 0.2612 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 335us/step - accuracy: 0.9168 - f1_score: 0.5688 - loss: 0.2555 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 324us/step - accuracy: 0.9172 - f1_score: 0.5801 - loss: 0.2551 - learning_rate: 5.3144e-05\n",
      "Epoch 8/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 317us/step - accuracy: 0.9188 - f1_score: 0.5646 - loss: 0.2522 - learning_rate: 4.7830e-05\n",
      "Epoch 9/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 326us/step - accuracy: 0.9201 - f1_score: 0.5818 - loss: 0.2499 - learning_rate: 4.3047e-05\n",
      "Epoch 10/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 330us/step - accuracy: 0.9218 - f1_score: 0.5705 - loss: 0.2427 - learning_rate: 3.8742e-05\n",
      "Epoch 11/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 342us/step - accuracy: 0.9172 - f1_score: 0.5736 - loss: 0.2555 - learning_rate: 3.4868e-05\n",
      "Epoch 12/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 327us/step - accuracy: 0.9207 - f1_score: 0.5652 - loss: 0.2441 - learning_rate: 3.1381e-05\n",
      "Epoch 13/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 326us/step - accuracy: 0.9172 - f1_score: 0.5730 - loss: 0.2573 - learning_rate: 2.8243e-05\n",
      "Epoch 14/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 326us/step - accuracy: 0.9214 - f1_score: 0.5879 - loss: 0.2446 - learning_rate: 2.5419e-05\n",
      "Epoch 15/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 322us/step - accuracy: 0.9166 - f1_score: 0.5608 - loss: 0.2547 - learning_rate: 2.2877e-05\n",
      "Epoch 16/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 327us/step - accuracy: 0.9163 - f1_score: 0.5744 - loss: 0.2621 - learning_rate: 2.0589e-05\n",
      "Epoch 17/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 329us/step - accuracy: 0.9167 - f1_score: 0.5593 - loss: 0.2557 - learning_rate: 1.8530e-05\n",
      "--------PERFORMANCE-------\n",
      "\u001B[1m63/63\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 416us/step\n",
      "(0.948, 0.9380159225144353)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Baseline",
   "id": "f7b551f8ab973726"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:34:07.774228Z",
     "start_time": "2024-12-22T13:33:52.587995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    baseline = DenseInternalModel(num_classes=2, input_shape=X_sample.shape[1])\n",
    "    baseline.fit(X_sample, y_sample)\n",
    "    print(\"--------PERFORMANCE-------\")\n",
    "    print(baseline.evaluate(X_test, y_test))"
   ],
   "id": "71d0a5c5364bd012",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 291us/step - accuracy: 0.8383 - f1_score: 0.4963 - loss: 0.4083 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 285us/step - accuracy: 0.9148 - f1_score: 0.5537 - loss: 0.2423 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 286us/step - accuracy: 0.9130 - f1_score: 0.5730 - loss: 0.2423 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 284us/step - accuracy: 0.9116 - f1_score: 0.5555 - loss: 0.2364 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 288us/step - accuracy: 0.9077 - f1_score: 0.5506 - loss: 0.2454 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 286us/step - accuracy: 0.9192 - f1_score: 0.5600 - loss: 0.2258 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 288us/step - accuracy: 0.9154 - f1_score: 0.5740 - loss: 0.2347 - learning_rate: 5.3144e-05\n",
      "Epoch 8/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344us/step - accuracy: 0.9135 - f1_score: 0.5395 - loss: 0.2335 - learning_rate: 4.7830e-05\n",
      "Epoch 9/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 293us/step - accuracy: 0.9101 - f1_score: 0.5428 - loss: 0.2389 - learning_rate: 4.3047e-05\n",
      "Epoch 10/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 294us/step - accuracy: 0.9123 - f1_score: 0.5637 - loss: 0.2381 - learning_rate: 3.8742e-05\n",
      "Epoch 11/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 291us/step - accuracy: 0.9152 - f1_score: 0.5423 - loss: 0.2305 - learning_rate: 3.4868e-05\n",
      "Epoch 12/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 291us/step - accuracy: 0.9142 - f1_score: 0.5509 - loss: 0.2314 - learning_rate: 3.1381e-05\n",
      "Epoch 13/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 287us/step - accuracy: 0.9152 - f1_score: 0.5447 - loss: 0.2328 - learning_rate: 2.8243e-05\n",
      "Epoch 14/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 287us/step - accuracy: 0.9148 - f1_score: 0.5376 - loss: 0.2296 - learning_rate: 2.5419e-05\n",
      "Epoch 15/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 288us/step - accuracy: 0.9076 - f1_score: 0.5414 - loss: 0.2432 - learning_rate: 2.2877e-05\n",
      "Epoch 16/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 296us/step - accuracy: 0.9129 - f1_score: 0.5426 - loss: 0.2321 - learning_rate: 2.0589e-05\n",
      "Epoch 17/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 298us/step - accuracy: 0.9118 - f1_score: 0.5497 - loss: 0.2346 - learning_rate: 1.8530e-05\n",
      "Epoch 18/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 297us/step - accuracy: 0.9125 - f1_score: 0.5400 - loss: 0.2357 - learning_rate: 1.6677e-05\n",
      "Epoch 19/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 297us/step - accuracy: 0.9159 - f1_score: 0.5347 - loss: 0.2246 - learning_rate: 1.5009e-05\n",
      "Epoch 20/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 298us/step - accuracy: 0.9147 - f1_score: 0.5476 - loss: 0.2371 - learning_rate: 1.3509e-05\n",
      "--------PERFORMANCE-------\n",
      "\u001B[1m63/63\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 406us/step\n",
      "(0.949, 0.9424419642857143)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using Two vectors",
   "id": "fb4dd9071a5c4464"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:34:16.508599Z",
     "start_time": "2024-12-22T13:34:16.501088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from keras.src.models import Model\n",
    "from keras.src.layers import Dense, Dropout, Input,  BatchNormalization, concatenate\n",
    "from keras.src.metrics import F1Score\n",
    "from keras.src import regularizers\n",
    "\n",
    "class DoubleDenseInternalModel(NeuralNetworkInternalModel):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = \"neural_network\"\n",
    "        num_classes = kwargs.get(\"num_classes\")\n",
    "        input_shape = kwargs.get(\"input_shape\")\n",
    "        self.model = self.get_model(num_classes=num_classes, input_shape=input_shape)\n",
    "\n",
    "    def get_model(self, num_classes, input_shape):\n",
    "        inputs_sub_networks = []\n",
    "\n",
    "        input_shape_a, input_shape_b = input_shape\n",
    "        input_a = Input(shape=(input_shape_a,))\n",
    "\n",
    "        x = Dense(input_shape_a // 2, activation=\"relu\", kernel_regularizer=regularizers.L2(0.1), bias_regularizer=regularizers.L2(0.01))(\n",
    "            input_a)\n",
    "        x = BatchNormalization(momentum=0.7)(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        # x = Dense(input_shape_a / 2, activation=\"relu\")(x)\n",
    "        x = Model(inputs=input_a, outputs=x)\n",
    "\n",
    "        inputs_sub_networks.append(x)\n",
    "\n",
    "        input_b = Input(shape=(input_shape_b,))\n",
    "        # the second branch operates on the second input\n",
    "        y = Dense(input_shape_b // 4, activation=\"relu\", kernel_regularizer=regularizers.L2(0.1),  bias_regularizer=regularizers.L2(0.01))(\n",
    "            input_b)\n",
    "        y = BatchNormalization(momentum=0.7)(y)\n",
    "        y = Dropout(0.3)(y)\n",
    "        y = Model(inputs=input_b, outputs=y)\n",
    "\n",
    "        inputs_sub_networks.append(y)\n",
    "\n",
    "        combined = concatenate([k.output for k in inputs_sub_networks])\n",
    "\n",
    "        m = Dense(num_classes, activation=\"softmax\", kernel_regularizer=regularizers.L2(0.1),\n",
    "                  bias_regularizer=regularizers.L2(0.1))(combined)\n",
    "\n",
    "        model = Model(inputs=[k.input for k in inputs_sub_networks], outputs=m)\n",
    "        # Compile the model with F1 Score\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy', F1Score()]\n",
    "                      )\n",
    "\n",
    "        return model"
   ],
   "id": "6ebe9cdab8a6d67e",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:34:58.758460Z",
     "start_time": "2024-12-22T13:34:58.702743Z"
    }
   },
   "cell_type": "code",
   "source": "X_double_pred_embed, X_double_test_pred_embed = [np.vstack(X_embed), np.vstack(predictions)], [np.vstack(X_test_embed), np.vstack(test_preds)]\n",
   "id": "9a551e38213cf3a6",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:35:21.678466Z",
     "start_time": "2024-12-22T13:34:59.394366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    double_iim = DoubleDenseInternalModel(num_classes=2, input_shape=(X_double_pred_embed[0].shape[1],X_double_pred_embed[1].shape[1]))\n",
    "    double_iim.fit(X_double_pred_embed, y_sample)\n",
    "    print(\"--------PERFORMANCE-------\")\n",
    "    print(double_iim.evaluate(X_double_test_pred_embed, y_test))\n",
    "\n"
   ],
   "id": "b6a74bcbb9bb2988",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 339us/step - accuracy: 0.6645 - f1_score: 0.4346 - loss: 3.3812 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 333us/step - accuracy: 0.9152 - f1_score: 0.4779 - loss: 0.6652 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 331us/step - accuracy: 0.9122 - f1_score: 0.4771 - loss: 0.4519 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 335us/step - accuracy: 0.9177 - f1_score: 0.4785 - loss: 0.3603 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 336us/step - accuracy: 0.9181 - f1_score: 0.4786 - loss: 0.3259 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 334us/step - accuracy: 0.9163 - f1_score: 0.4782 - loss: 0.3151 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 331us/step - accuracy: 0.9117 - f1_score: 0.4769 - loss: 0.3145 - learning_rate: 5.3144e-05\n",
      "Epoch 8/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 337us/step - accuracy: 0.9103 - f1_score: 0.4791 - loss: 0.3120 - learning_rate: 4.7830e-05\n",
      "Epoch 9/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 363us/step - accuracy: 0.9129 - f1_score: 0.4790 - loss: 0.3056 - learning_rate: 4.3047e-05\n",
      "Epoch 10/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 355us/step - accuracy: 0.9142 - f1_score: 0.4814 - loss: 0.2988 - learning_rate: 3.8742e-05\n",
      "Epoch 11/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 382us/step - accuracy: 0.9159 - f1_score: 0.4890 - loss: 0.2959 - learning_rate: 3.4868e-05\n",
      "Epoch 12/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 380us/step - accuracy: 0.9139 - f1_score: 0.4881 - loss: 0.2981 - learning_rate: 3.1381e-05\n",
      "Epoch 13/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344us/step - accuracy: 0.9170 - f1_score: 0.4837 - loss: 0.2899 - learning_rate: 2.8243e-05\n",
      "Epoch 14/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 344us/step - accuracy: 0.9156 - f1_score: 0.4898 - loss: 0.2916 - learning_rate: 2.5419e-05\n",
      "Epoch 15/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 345us/step - accuracy: 0.9131 - f1_score: 0.4924 - loss: 0.2961 - learning_rate: 2.2877e-05\n",
      "Epoch 16/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 390us/step - accuracy: 0.9131 - f1_score: 0.4895 - loss: 0.2953 - learning_rate: 2.0589e-05\n",
      "Epoch 17/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 427us/step - accuracy: 0.9148 - f1_score: 0.4895 - loss: 0.2939 - learning_rate: 1.8530e-05\n",
      "Epoch 18/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 358us/step - accuracy: 0.9161 - f1_score: 0.4897 - loss: 0.2898 - learning_rate: 1.6677e-05\n",
      "Epoch 19/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 352us/step - accuracy: 0.9129 - f1_score: 0.4863 - loss: 0.2954 - learning_rate: 1.5009e-05\n",
      "Epoch 20/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 362us/step - accuracy: 0.9141 - f1_score: 0.4889 - loss: 0.2933 - learning_rate: 1.3509e-05\n",
      "Epoch 21/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 360us/step - accuracy: 0.9160 - f1_score: 0.4993 - loss: 0.2862 - learning_rate: 1.2158e-05\n",
      "Epoch 22/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 360us/step - accuracy: 0.9111 - f1_score: 0.4864 - loss: 0.2980 - learning_rate: 1.0942e-05\n",
      "Epoch 23/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 406us/step - accuracy: 0.9149 - f1_score: 0.4931 - loss: 0.2880 - learning_rate: 9.8477e-06\n",
      "Epoch 24/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 370us/step - accuracy: 0.9109 - f1_score: 0.4861 - loss: 0.2977 - learning_rate: 8.8629e-06\n",
      "--------PERFORMANCE-------\n",
      "\u001B[1m63/63\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step\n",
      "(0.9485, 0.9384098049907035)\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Correlation",
   "id": "72bb92bb99514ed7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:37:23.254379Z",
     "start_time": "2024-12-22T13:37:23.138838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows = []\n",
    "for embed, pred, label in zip(X_embed, predictions, y_sample):\n",
    "    rows.append(np.hstack([embed, pred, np.vstack([label])]))\n",
    "df = pd.DataFrame(np.vstack(rows))\n",
    "df.head()"
   ],
   "id": "96894e2f55346cf3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   0    1    2    3    4    5    6    7             8             9    ...  \\\n",
       "0 -1.0 -1.0 -1.0 -1.0  1.0 -1.0 -1.0  1.0  2.766979e-07  5.367829e-09  ...   \n",
       "1 -1.0 -1.0 -1.0 -1.0  1.0 -1.0 -1.0  1.0  2.766979e-07  5.367829e-09  ...   \n",
       "2 -1.0 -1.0 -1.0 -1.0  1.0 -1.0 -1.0 -1.0  2.766727e-07  5.367589e-09  ...   \n",
       "3 -1.0 -1.0 -1.0 -1.0 -1.0  1.0 -1.0  1.0  2.766951e-07  5.367594e-09  ...   \n",
       "4 -1.0 -1.0 -1.0 -1.0  1.0 -1.0 -1.0 -1.0  2.766727e-07  5.367589e-09  ...   \n",
       "\n",
       "        99        100           101           102           103       104  \\\n",
       "0  0.000001  0.000005  5.753773e-07  1.384776e-09  2.619639e-07  0.000001   \n",
       "1  0.000001  0.000005  5.753773e-07  1.384776e-09  2.619639e-07  0.000001   \n",
       "2  0.000001  0.000005  5.753566e-07  1.384754e-09  2.619567e-07  0.000001   \n",
       "3  0.000001  0.000005  5.753533e-07  1.384647e-09  2.619532e-07  0.000001   \n",
       "4  0.000001  0.000005  5.753566e-07  1.384754e-09  2.619567e-07  0.000001   \n",
       "\n",
       "            105           106       107  108  \n",
       "0  1.063482e-09  1.579175e-07  0.000266  0.0  \n",
       "1  1.063482e-09  1.579175e-07  0.000266  0.0  \n",
       "2  1.063456e-09  1.579101e-07  0.000266  0.0  \n",
       "3  1.063356e-09  1.579191e-07  0.000266  0.0  \n",
       "4  1.063456e-09  1.579101e-07  0.000266  0.0  \n",
       "\n",
       "[5 rows x 109 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.766979e-07</td>\n",
       "      <td>5.367829e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753773e-07</td>\n",
       "      <td>1.384776e-09</td>\n",
       "      <td>2.619639e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063482e-09</td>\n",
       "      <td>1.579175e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.766979e-07</td>\n",
       "      <td>5.367829e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753773e-07</td>\n",
       "      <td>1.384776e-09</td>\n",
       "      <td>2.619639e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063482e-09</td>\n",
       "      <td>1.579175e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.766727e-07</td>\n",
       "      <td>5.367589e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753566e-07</td>\n",
       "      <td>1.384754e-09</td>\n",
       "      <td>2.619567e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063456e-09</td>\n",
       "      <td>1.579101e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.766951e-07</td>\n",
       "      <td>5.367594e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753533e-07</td>\n",
       "      <td>1.384647e-09</td>\n",
       "      <td>2.619532e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063356e-09</td>\n",
       "      <td>1.579191e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.766727e-07</td>\n",
       "      <td>5.367589e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753566e-07</td>\n",
       "      <td>1.384754e-09</td>\n",
       "      <td>2.619567e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063456e-09</td>\n",
       "      <td>1.579101e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:49:08.144554Z",
     "start_time": "2024-12-22T13:49:08.122745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows = []\n",
    "for embed, pred, label in zip(X_test_embed, test_preds, y_test):\n",
    "    rows.append(np.hstack([embed, pred, np.vstack([label])]))\n",
    "\n",
    "test_df = pd.DataFrame(np.vstack(rows))\n",
    "test_df.head()"
   ],
   "id": "4524f5d7864e9dc6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        0    1    2         3         4    5    6    7             8    \\\n",
       "0 -0.996705 -1.0 -1.0 -0.999537 -1.000000 -1.0 -1.0  1.0  2.766912e-07   \n",
       "1 -1.000000 -1.0 -1.0 -1.000000  1.000000 -1.0 -1.0  1.0  2.766979e-07   \n",
       "2 -0.999570 -1.0 -1.0 -1.000000 -1.000000 -1.0 -1.0  1.0  2.766907e-07   \n",
       "3 -1.000000 -1.0 -1.0  1.000000 -0.998985 -1.0 -1.0 -1.0  2.766720e-07   \n",
       "4 -1.000000 -1.0 -1.0 -1.000000 -0.999996 -1.0 -1.0  1.0  2.766909e-07   \n",
       "\n",
       "            9    ...       99        100           101           102  \\\n",
       "0  5.367964e-09  ...  0.000001  0.000005  5.753951e-07  1.384787e-09   \n",
       "1  5.367829e-09  ...  0.000001  0.000005  5.753773e-07  1.384776e-09   \n",
       "2  5.367943e-09  ...  0.000001  0.000005  5.753918e-07  1.384787e-09   \n",
       "3  5.367792e-09  ...  0.000001  0.000005  5.753728e-07  1.384619e-09   \n",
       "4  5.367933e-09  ...  0.000001  0.000005  5.753923e-07  1.384779e-09   \n",
       "\n",
       "            103       104           105           106       107  108  \n",
       "0  2.619570e-07  0.000001  1.063490e-09  1.579187e-07  0.000266  0.0  \n",
       "1  2.619639e-07  0.000001  1.063482e-09  1.579175e-07  0.000266  0.0  \n",
       "2  2.619565e-07  0.000001  1.063482e-09  1.579196e-07  0.000266  0.0  \n",
       "3  2.619551e-07  0.000001  1.063365e-09  1.579138e-07  0.000266  0.0  \n",
       "4  2.619559e-07  0.000001  1.063486e-09  1.579189e-07  0.000266  0.0  \n",
       "\n",
       "[5 rows x 109 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.996705</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.999537</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.766912e-07</td>\n",
       "      <td>5.367964e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753951e-07</td>\n",
       "      <td>1.384787e-09</td>\n",
       "      <td>2.619570e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063490e-09</td>\n",
       "      <td>1.579187e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.766979e-07</td>\n",
       "      <td>5.367829e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753773e-07</td>\n",
       "      <td>1.384776e-09</td>\n",
       "      <td>2.619639e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063482e-09</td>\n",
       "      <td>1.579175e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.999570</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.766907e-07</td>\n",
       "      <td>5.367943e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753918e-07</td>\n",
       "      <td>1.384787e-09</td>\n",
       "      <td>2.619565e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063482e-09</td>\n",
       "      <td>1.579196e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.998985</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.766720e-07</td>\n",
       "      <td>5.367792e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753728e-07</td>\n",
       "      <td>1.384619e-09</td>\n",
       "      <td>2.619551e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063365e-09</td>\n",
       "      <td>1.579138e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.766909e-07</td>\n",
       "      <td>5.367933e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753923e-07</td>\n",
       "      <td>1.384779e-09</td>\n",
       "      <td>2.619559e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063486e-09</td>\n",
       "      <td>1.579189e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:42:34.280119Z",
     "start_time": "2024-12-22T13:42:34.014870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "correlation_matrix = df.corr()\n",
    "\n",
    "TOP = 10\n",
    "target_correlation = correlation_matrix.iloc[-1].abs().sort_values(ascending=False)\n",
    "top_target_corr = target_correlation[1:TOP]  # Exclude the target's correlation with itself\n",
    "\n",
    "print(f\"Top {TOP} feature correlations with the target:\")\n",
    "print(top_target_corr)"
   ],
   "id": "bda743c258e61be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 feature correlations with the target:\n",
      "6      0.003050\n",
      "2      0.007783\n",
      "4      0.013605\n",
      "67     0.015070\n",
      "11     0.016073\n",
      "60     0.024851\n",
      "102    0.026671\n",
      "1      0.029054\n",
      "0      0.035994\n",
      "Name: 108, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:41:46.435550Z",
     "start_time": "2024-12-22T13:41:46.418440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TOP = 20\n",
    "\n",
    "# Get the top 10 feature-feature correlations\n",
    "feature_correlation = correlation_matrix.abs().unstack()\n",
    "feature_correlation = feature_correlation[feature_correlation < 1.0]  # Remove self-correlations\n",
    "top_feature_corr = feature_correlation.sort_values(ascending=False)[:TOP]\n",
    "\n",
    "print(f\"\\nTop {TOP} feature-feature correlations:\")\n",
    "print(top_feature_corr)"
   ],
   "id": "4559fc7b94dd5875",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 feature-feature correlations:\n",
      "91   8      0.991189\n",
      "8    91     0.991189\n",
      "101  9      0.986578\n",
      "9    101    0.986578\n",
      "44   43     0.986427\n",
      "43   44     0.986427\n",
      "59   100    0.985324\n",
      "100  59     0.985324\n",
      "20   23     0.984703\n",
      "23   20     0.984703\n",
      "107  52     0.982269\n",
      "52   107    0.982269\n",
      "19   106    0.980771\n",
      "106  19     0.980771\n",
      "25   66     0.979824\n",
      "66   25     0.979824\n",
      "44   58     0.979658\n",
      "58   44     0.979658\n",
      "107  99     0.978215\n",
      "99   107    0.978215\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dim Reduction",
   "id": "7a801bba75bced80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:47:11.751482Z",
     "start_time": "2024-12-22T13:47:11.718386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming your data is in a numpy array called 'X' with shape (n_samples, 1009)\n",
    "# If not, you need to load and prepare your data first\n",
    "X,y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=10)\n",
    "X_reduced = pca.fit_transform(X_scaled)\n",
    "\n",
    "# X_reduced now has shape (n_samples, 10)\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Total explained variance:\", sum(pca.explained_variance_ratio_))"
   ],
   "id": "9bd8b1556282ba21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.53415906 0.25490196 0.06251872 0.03584684 0.02870274 0.01985813\n",
      " 0.01562191 0.01151777 0.01084    0.00854644]\n",
      "Total explained variance: 0.9825135639825718\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:51:53.272813Z",
     "start_time": "2024-12-22T13:51:53.263337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test,_ = test_df.iloc[:, :-1], test_df.iloc[:, -1]\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=10)\n",
    "X_test_reduced = pca.fit_transform(X_test_scaled)\n",
    "\n",
    "# X_reduced now has shape (n_samples, 10)\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Total explained variance:\", sum(pca.explained_variance_ratio_))"
   ],
   "id": "c5fd811993ad48b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.53593826 0.2474006  0.05817848 0.04273527 0.02496998 0.01911342\n",
      " 0.01823509 0.0139761  0.01179614 0.01007248]\n",
      "Total explained variance: 0.9824158305038713\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:52:06.907251Z",
     "start_time": "2024-12-22T13:51:55.547816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    \n",
    "    iim = DenseInternalModel(num_classes=2, input_shape=X_reduced.shape[1])\n",
    "    iim.fit(X_reduced, y_sample)\n",
    "    print(\"--------PERFORMANCE-------\")\n",
    "    print(iim.evaluate(X_test_reduced, y_test))"
   ],
   "id": "1c05cb01289cf563",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 285us/step - accuracy: 0.8543 - f1_score: 0.5073 - loss: 0.4010 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 277us/step - accuracy: 0.9151 - f1_score: 0.5256 - loss: 0.2679 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 276us/step - accuracy: 0.9144 - f1_score: 0.5435 - loss: 0.2659 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 276us/step - accuracy: 0.9178 - f1_score: 0.5436 - loss: 0.2547 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 275us/step - accuracy: 0.9171 - f1_score: 0.5415 - loss: 0.2559 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 274us/step - accuracy: 0.9220 - f1_score: 0.5675 - loss: 0.2468 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 275us/step - accuracy: 0.9136 - f1_score: 0.5582 - loss: 0.2631 - learning_rate: 5.3144e-05\n",
      "Epoch 8/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 280us/step - accuracy: 0.9159 - f1_score: 0.5524 - loss: 0.2653 - learning_rate: 4.7830e-05\n",
      "Epoch 9/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 284us/step - accuracy: 0.9171 - f1_score: 0.5453 - loss: 0.2568 - learning_rate: 4.3047e-05\n",
      "Epoch 10/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 291us/step - accuracy: 0.9115 - f1_score: 0.5438 - loss: 0.2695 - learning_rate: 3.8742e-05\n",
      "Epoch 11/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 307us/step - accuracy: 0.9194 - f1_score: 0.5701 - loss: 0.2528 - learning_rate: 3.4868e-05\n",
      "Epoch 12/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 348us/step - accuracy: 0.9188 - f1_score: 0.5634 - loss: 0.2504 - learning_rate: 3.1381e-05\n",
      "Epoch 13/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 303us/step - accuracy: 0.9164 - f1_score: 0.5447 - loss: 0.2573 - learning_rate: 2.8243e-05\n",
      "Epoch 14/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 320us/step - accuracy: 0.9163 - f1_score: 0.5487 - loss: 0.2579 - learning_rate: 2.5419e-05\n",
      "Epoch 15/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 282us/step - accuracy: 0.9187 - f1_score: 0.5683 - loss: 0.2521 - learning_rate: 2.2877e-05\n",
      "--------PERFORMANCE-------\n",
      "\u001B[1m63/63\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 390us/step\n",
      "(0.945, 0.927847520417614)\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:51:33.579106Z",
     "start_time": "2024-12-22T13:51:33.577082Z"
    }
   },
   "cell_type": "code",
   "source": "X_test_reduced.shape, y_test.shape",
   "id": "35dee69d2918f0bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 10), (2000,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3687494b5c101b28"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
