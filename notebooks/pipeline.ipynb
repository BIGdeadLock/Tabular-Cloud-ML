{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-25T19:41:51.851587Z",
     "start_time": "2024-11-25T19:41:49.702730Z"
    }
   },
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from keras.src import Sequential\n",
    "from keras.src.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.src.callbacks import EarlyStopping"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:41:51.857372Z",
     "start_time": "2024-11-25T19:41:51.855201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECT_PATH = os.getcwd()\n",
    "PROJECT_PATH = os.path.join(PROJECT_PATH, \"..\")\n",
    "MODELS_DIR = pathlib.Path(PROJECT_PATH) / \"store\" / \"models\"\n",
    "\n",
    "DATASET_DIR = pathlib.Path(PROJECT_PATH) / \"data\""
   ],
   "id": "982312657be336ff",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:41:51.920688Z",
     "start_time": "2024-11-25T19:41:51.867308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(DATASET_DIR / \"bank_marketing\"/ \"dataset.csv\")\n",
    "dataset"
   ],
   "id": "a240984fa1f517ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       age           job   marital  education default  balance housing loan  \\\n",
       "0       27    management    single  secondary      no       35      no   no   \n",
       "1       54   blue-collar   married    primary      no      466      no   no   \n",
       "2       43   blue-collar   married  secondary      no      105      no  yes   \n",
       "3       31    technician    single  secondary      no       19      no   no   \n",
       "4       27    technician    single  secondary      no      126     yes  yes   \n",
       "...    ...           ...       ...        ...     ...      ...     ...  ...   \n",
       "30902   51    technician   married   tertiary      no      825      no   no   \n",
       "30903   71       retired  divorced    primary      no     1729      no   no   \n",
       "30904   72       retired   married  secondary      no     5715      no   no   \n",
       "30905   57   blue-collar   married  secondary      no      668      no   no   \n",
       "30906   37  entrepreneur   married  secondary      no     2971      no   no   \n",
       "\n",
       "         contact  day_of_week month  duration  campaign  pdays  previous  \\\n",
       "0       cellular            4   jul       255         1     -1         0   \n",
       "1       cellular            4   jul       297         1     -1         0   \n",
       "2       cellular            4   jul       668         2     -1         0   \n",
       "3      telephone            4   jul        65         2     -1         0   \n",
       "4       cellular            4   jul       436         4     -1         0   \n",
       "...          ...          ...   ...       ...       ...    ...       ...   \n",
       "30902   cellular           17   nov       977         3     -1         0   \n",
       "30903   cellular           17   nov       456         2     -1         0   \n",
       "30904   cellular           17   nov      1127         5    184         3   \n",
       "30905  telephone           17   nov       508         4     -1         0   \n",
       "30906   cellular           17   nov       361         2    188        11   \n",
       "\n",
       "      poutcome    y  \n",
       "0          NaN   no  \n",
       "1          NaN   no  \n",
       "2          NaN   no  \n",
       "3          NaN   no  \n",
       "4          NaN   no  \n",
       "...        ...  ...  \n",
       "30902      NaN  yes  \n",
       "30903      NaN  yes  \n",
       "30904  success  yes  \n",
       "30905      NaN   no  \n",
       "30906    other   no  \n",
       "\n",
       "[30907 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>35</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>466</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>105</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>668</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>19</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>126</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>436</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30902</th>\n",
       "      <td>51</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>825</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30903</th>\n",
       "      <td>71</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1729</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30904</th>\n",
       "      <td>72</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>5715</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30905</th>\n",
       "      <td>57</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>668</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30906</th>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2971</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30907 rows × 17 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:41:52.573893Z",
     "start_time": "2024-11-25T19:41:52.556490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = dataset.iloc[:, :-1], dataset.iloc[:, -1]\n",
    "\n",
    "# Remove the bug in the dataset where the entire row has -9 values\n",
    "mask = ~(X == -9).all(axis=1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "y = y.replace({\"no\": 0, \"yes\": 1}).astype(int)"
   ],
   "id": "187e2a5342844a47",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r9/9n0wpy917zg1611cmsmqg0kr0000gn/T/ipykernel_74803/1292191429.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = y.replace({\"no\": 0, \"yes\": 1}).astype(int)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:41:53.277798Z",
     "start_time": "2024-11-25T19:41:53.246071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(X: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    The function will preprocess the data:\n",
    "    1. Categorical features will be label encoded (Boy->1, Girl ->2)\n",
    "    2. Numerical features will be scaled if the data is intended to be used for baseline. For cloud data set, no scaling will be preformed.\n",
    "\n",
    "    Return pd.Dataframe\n",
    "    \"\"\"\n",
    "    # Identify categorical and numeric columns\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "    # Initialize lists to store processed columns\n",
    "    processed_columns = []\n",
    "\n",
    "    # If there are categorical columns, apply one-hot encoding\n",
    "    if categorical_cols:\n",
    "        print(\"\\nEncoding categorical columns...\")\n",
    "        # onehot_encoder = OneHotEncoder(categories='auto', sparse=False)\n",
    "        # X_categorical = pd.DataFrame(onehot_encoder.fit_transform(X[categorical_cols]),\n",
    "        #                              columns=onehot_encoder.get_feature_names_out(categorical_cols))\n",
    "        label_encoder = LabelEncoder()\n",
    "        X_categorical = pd.DataFrame()\n",
    "        for col in categorical_cols:\n",
    "            X_categorical[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "        processed_columns.append(X_categorical)\n",
    "\n",
    "    # Apply standard scaling to the numeric columns\n",
    "    if numeric_cols:\n",
    "        print(\"\\nScaling numerical columns...\")\n",
    "        scaler = MinMaxScaler()\n",
    "        X_numeric = X[numeric_cols]\n",
    "        # X_numeric = pd.DataFrame(scaler.fit_transform(X[numeric_cols]), columns=numeric_cols, index=X.index)\n",
    "\n",
    "        processed_columns.append(X_numeric)\n",
    "\n",
    "    # Combine the processed columns\n",
    "    if processed_columns:\n",
    "        X_processed = pd.concat(processed_columns, axis=1)\n",
    "    else:\n",
    "        X_processed = X.copy()  # If there are no categorical or numeric columns, keep the original dataframe\n",
    "\n",
    "\n",
    "    return X_processed\n",
    "\n",
    "\n",
    "X = preprocess(X)"
   ],
   "id": "909539a4be92cf8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding categorical columns...\n",
      "\n",
      "Scaling numerical columns...\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:41:53.721343Z",
     "start_time": "2024-11-25T19:41:53.717931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_sample, y_sample = X.iloc[2000:3000], y.iloc[2000:3000]\n",
    "y_sample.value_counts()"
   ],
   "id": "20fd537bed251cc5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    919\n",
       "1     81\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:41:53.956589Z",
     "start_time": "2024-11-25T19:41:53.953070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test, y_test = X.iloc[:1000], y.iloc[:1000]\n",
    "y_test.value_counts()"
   ],
   "id": "d48d5a81179fad14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    940\n",
       "1     60\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:42:17.830400Z",
     "start_time": "2024-11-25T19:41:54.161182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from keras.src.utils import to_categorical\n",
    "\n",
    "\n",
    "class DNNEmbedding(nn.Module):\n",
    "\n",
    "    name = \"dnn_embedding\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DNNEmbedding, self).__init__()\n",
    "\n",
    "        X, y = kwargs.get(\"X\"), kwargs.get(\"y\")\n",
    "        num_classes = len(set(y))\n",
    "        y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=X.shape[1]//2, activation='tanh', name=\"embedding\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(units=num_classes, activation='softmax', name=\"output\"))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        early_stop = EarlyStopping(patience=2, monitor=\"loss\")\n",
    "\n",
    "        model.fit(X, y,validation_data=[X_test, to_categorical(y_test,2)], epochs=50, batch_size=8, callbacks=[early_stop])\n",
    "        self.model = model.layers[0]\n",
    "        self.output_shape = (1, X.shape[1]//2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if type(x) is pd.DataFrame:\n",
    "            x = x.to_numpy()\n",
    "\n",
    "        embedding = self.model(x)\n",
    "        return embedding\n",
    "\n",
    "\n",
    "embedding = DNNEmbedding(X=X_sample, y=y_sample)\n",
    "\n"
   ],
   "id": "d69d33283821949f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eden.yavin/Projects/Tabular-Cloud-ML/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 21:41:55.878657: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 15ms/step - accuracy: 0.5990 - loss: 0.8058 - val_accuracy: 0.8780 - val_loss: 0.4320\n",
      "Epoch 2/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 14ms/step - accuracy: 0.7562 - loss: 0.5783 - val_accuracy: 0.9120 - val_loss: 0.3815\n",
      "Epoch 3/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.8541 - loss: 0.4363 - val_accuracy: 0.9240 - val_loss: 0.3399\n",
      "Epoch 4/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.8823 - loss: 0.3715 - val_accuracy: 0.9240 - val_loss: 0.3020\n",
      "Epoch 5/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 14ms/step - accuracy: 0.9001 - loss: 0.3373 - val_accuracy: 0.9250 - val_loss: 0.2708\n",
      "Epoch 6/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.9055 - loss: 0.3081 - val_accuracy: 0.9250 - val_loss: 0.2570\n",
      "Epoch 7/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 14ms/step - accuracy: 0.9149 - loss: 0.2916 - val_accuracy: 0.9250 - val_loss: 0.2427\n",
      "Epoch 8/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.8987 - loss: 0.3347 - val_accuracy: 0.9250 - val_loss: 0.2287\n",
      "Epoch 9/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.9233 - loss: 0.2507 - val_accuracy: 0.9250 - val_loss: 0.2197\n",
      "Epoch 10/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.9197 - loss: 0.2715 - val_accuracy: 0.9250 - val_loss: 0.2151\n",
      "Epoch 11/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.9057 - loss: 0.3234 - val_accuracy: 0.9250 - val_loss: 0.2105\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:49:54.900737Z",
     "start_time": "2024-11-25T19:49:54.884201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from keras.src.layers import Input, Dense,  Flatten\n",
    "from keras.src.layers import BatchNormalization, Activation, Conv2DTranspose\n",
    "from keras.src.models import Model, Sequential\n",
    "from keras.src.layers import LeakyReLU, Reshape, Conv2D, UpSampling2D, ReLU\n",
    "\n",
    "class BaseEncryptor:\n",
    "\n",
    "    name: str\n",
    "\n",
    "    def __init__(self, input_shape=None, output_shape=None):\n",
    "        self.model = None\n",
    "        self.output_shape = output_shape\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build_generator(self, input_shape, output_shape):\n",
    "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
    "\n",
    "    def encode(self, inputs) -> np.array:\n",
    "        inputs = np.expand_dims(inputs, axis=0)\n",
    "        if self.model is None:\n",
    "            input_shape = inputs.shape[1:]\n",
    "            output_shape = self.output_shape or (1, inputs.shape[2])\n",
    "            self.model = self.build_generator(input_shape, output_shape)\n",
    "        return self.model(inputs).numpy()\n",
    "\n",
    "class DCEncryptor(BaseEncryptor):\n",
    "\n",
    "    name = \"dc\"\n",
    "    \n",
    "    def build_generator1(self, input_shape, output_shape):\n",
    "        G = Sequential()\n",
    "        G.add(Reshape(target_shape=[1, 1, self.input_shape], input_shape=[self.input_shape]))\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 1x1x4096\n",
    "        G.add(Conv2DTranspose(filters=64, kernel_size=4))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 0, Activations index: 1\n",
    "\n",
    "        # 4x4x64\n",
    "        G.add(Conv2D(filters=64, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 2, Activations index: 5\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 8x8x64\n",
    "        G.add(Conv2D(filters=32, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 8, Activations index: 9\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 16x16x32\n",
    "        G.add(Conv2D(filters=16, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 14, Activations index: 13\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 32x32x16\n",
    "        G.add(Conv2D(filters=8, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 20, Activations index: 17\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 64x64x8\n",
    "        G.add(Conv2D(filters=4, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 26, Activations index: 21\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 128x128x4\n",
    "        G.add(Conv2D(filters=3, kernel_size=4, padding='same'))\n",
    "        G.add(Activation('sigmoid'))\n",
    "        \n",
    "        return G\n",
    "        \n",
    "    def build_generator(self, input_shape, output_shape):\n",
    "\n",
    "        input_layer = Input(shape=input_shape)\n",
    "        x = Flatten()(input_layer)\n",
    "    \n",
    "        x = Dense(4*4*256, use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "    \n",
    "        x = Reshape((4, 4, 256))(x)\n",
    "    \n",
    "        x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "    \n",
    "        x = Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "    \n",
    "        x = Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "    \n",
    "        output_image = Conv2DTranspose(3, (4, 4), strides=(1, 1), padding='same', use_bias=False, activation='sigmoid')(x)\n",
    "    \n",
    "        return Model(inputs=input_layer, outputs=output_image)\n",
    "        \n",
    "    def build_generator_vgg224(self, input_shape, output_shape):\n",
    "\n",
    "        input_layer = Input(shape=input_shape)\n",
    "        x = Flatten()(input_layer)\n",
    "\n",
    "        x = Dense(7*7*256, use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Reshape((7, 7, 256))(x)\n",
    "        x = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        x = Conv2DTranspose(16, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        output_image = Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n",
    "\n",
    "        return Model(inputs=input_layer, outputs=output_image)\n",
    "    \n",
    "    \n",
    "encoder = DCEncryptor(output_shape=(1, 32, 32, 4))"
   ],
   "id": "821dca637b470fff",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:42:17.972829Z",
     "start_time": "2024-11-25T19:42:17.851424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.api.applications import ResNet152V2, VGG16, EfficientNetB7\n",
    "# from keras.api.applications.vgg16 import preprocess_input\n",
    "from keras.api.applications.resnet_v2 import preprocess_input\n",
    "import tensorflow as tf\n",
    "from keras.api.models import load_model\n",
    "\n",
    "\n",
    "def pad(tensor, original, target=600):\n",
    "    pad_height = (target - original) // 2\n",
    "    pad_width = (target - original) // 2\n",
    "    padded_tensor = tf.pad(tensor, [[pad_height, pad_height], [pad_width, pad_width], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "    # If the dimensions are odd, add an extra row/column to one side\n",
    "    if (600 - 224) % 2 != 0:\n",
    "        padded_tensor = tf.pad(padded_tensor, [[0, 1], [0, 1], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "    return padded_tensor[np.newaxis, ...]\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Assuming 'image' is your input tensor\n",
    "    resized_image = tf.image.resize(image, (32, 32))\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "class VGG16CloudModel:\n",
    "    name = \"vgg16\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = self.get_model()\n",
    "        self.input_shape = (32,32,3)#(224, 224, 3)\n",
    "        self.output_shape = (1,1000)\n",
    "\n",
    "    def fit(self, X_train, y_train, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def get_model(self):\n",
    "        # Load the pretrained VGG16 model with ImageNet weights\n",
    "        model = load_model(\"/Users/eden.yavin/Projects/Tabular-Cloud-ML/store/models/cifar100_vgg.keras\") #VGG16(weights='imagenet')\n",
    "        return model\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.preprocess(X)\n",
    "        predictions = self.model.predict(X, verbose=None)\n",
    "        return predictions\n",
    "\n",
    "    def preprocess(self, X):\n",
    "        \n",
    "        X = X.copy()\n",
    "        # X = (X * 10000).astype(np.uint8)\n",
    "\n",
    "        if any(s < 32 for s in X.shape[1:3]):\n",
    "            # Pad the input to make its size equal to 224\n",
    "            padded_X = tf.image.resize_with_crop_or_pad(X, 32, 32)\n",
    "\n",
    "            # Ensure the input is properly preprocessed for VGG16\n",
    "            X = preprocess_input(padded_X.numpy())\n",
    "        else:\n",
    "            # If no padding is needed, directly preprocess the input\n",
    "            X = preprocess_input(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    \n",
    "    \n",
    "cloud = VGG16CloudModel()\n"
   ],
   "id": "d010100e38c2c228",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:50:08.430565Z",
     "start_time": "2024-11-25T19:49:57.734360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_encrypted, X_test_encrypted = [], []\n",
    "X_embed, X_test_embed = [], []\n",
    "for i, x in X_sample.iterrows():\n",
    "    \n",
    "    x_embed = embedding(x.values.reshape(1,-1))\n",
    "    X_embed.append(x_embed)\n",
    "    encrypted = encoder.encode(np.vstack(x_embed))\n",
    "\n",
    "    X_encrypted.append(encrypted)\n",
    "    \n",
    "for i,x in X_test.iterrows():\n",
    "    x_embed = embedding(x.values.reshape(1,-1))\n",
    "    X_test_embed.append(x_embed)\n",
    "    encrypted = encoder.encode(np.vstack(x_embed))\n",
    "    X_test_encrypted.append(encrypted)"
   ],
   "id": "a24845e75f0e88ae",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:50:49.902655Z",
     "start_time": "2024-11-25T19:50:08.434564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = [\n",
    "    cloud.predict(x)\n",
    "    for x in X_encrypted\n",
    "]\n",
    "test_preds = [\n",
    "    cloud.predict(x)\n",
    "    for x in X_test_encrypted\n",
    "]"
   ],
   "id": "4fcdf191f61ce371",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:47:34.814943Z",
     "start_time": "2024-11-25T19:47:34.811297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# VGG Cifar100 | Encoder - Sigmoid \n",
    "g = predictions[0]\n",
    "g.max()"
   ],
   "id": "c3fa1502e129309",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96965593"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:50:49.925124Z",
     "start_time": "2024-11-25T19:50:49.922894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# VGG Cifar100 | Encoder - tanh \n",
    "v = predictions[0]\n",
    "v.max()"
   ],
   "id": "8b7f6edcd5df69e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9696511"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T11:56:45.158274Z",
     "start_time": "2024-11-01T11:56:45.154118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Resnet no scalar\n",
    "# p = predictions[0]\n",
    "p.max()"
   ],
   "id": "8d741a6deeed0544",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T11:52:12.693092Z",
     "start_time": "2024-11-01T11:52:12.691039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Resnet with scalar\n",
    "# h = predictions[0]\n",
    "h.max()"
   ],
   "id": "1ba14b38c7f34b1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63243544"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:50:58.410811Z",
     "start_time": "2024-11-25T19:50:58.374992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from keras.src.models import Model\n",
    "from keras.src.layers import Dense, Dropout, Input,  BatchNormalization\n",
    "from keras.src.metrics import F1Score\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetworkInternalModel(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.batch_size = 8\n",
    "        self.dropout_rate = 0.3\n",
    "        self.epochs = 100\n",
    "        self.model: Model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y_onehot = to_categorical(y , 2)\n",
    "        lr_scheduler = LearningRateScheduler(lambda epoch: 0.0001 * (0.9 ** epoch))\n",
    "        early_stopping = EarlyStopping(patience=3, monitor='loss')\n",
    "        self.model.fit(X, y_onehot, epochs=self.epochs, batch_size=self.batch_size, callbacks=[lr_scheduler, early_stopping])\n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = self.model.predict(X)\n",
    "        return np.argmax(prediction, axis=1)\n",
    "\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        if len(y.shape) == 2:\n",
    "            y = np.argmax(y, axis=1)\n",
    "\n",
    "        pred = self.predict(X)\n",
    "        return accuracy_score(y, pred), f1_score(y, pred, average='weighted')\n",
    "\n",
    "\n",
    "class DenseInternalModel(NeuralNetworkInternalModel):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = \"neural_network\"\n",
    "        num_classes = kwargs.get(\"num_classes\")\n",
    "        input_shape = kwargs.get(\"input_shape\")\n",
    "        self.model = self.get_model(num_classes=num_classes, input_shape=input_shape)\n",
    "\n",
    "    def get_model(self, num_classes, input_shape):\n",
    "        # Build the model\n",
    "        inputs = Input(shape=(input_shape,))  # Dynamic input shape\n",
    "\n",
    "        # Define the hidden layers\n",
    "        x = BatchNormalization()(inputs)\n",
    "        x = Dense(units=128, activation='leaky_relu')(x)\n",
    "        x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        # Define the output layer\n",
    "        outputs = Dense(units=num_classes, activation='softmax')(x)\n",
    "\n",
    "        # Create the model\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        # Compile the model with F1 Score\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy', F1Score()]\n",
    "                      )\n",
    "\n",
    "        return model\n",
    "    \n",
    "iim = DenseInternalModel(num_classes=2, input_shape=predictions[0].shape[1])"
   ],
   "id": "d539c7408c4e256",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:51:07.948181Z",
     "start_time": "2024-11-25T19:50:59.897286Z"
    }
   },
   "cell_type": "code",
   "source": "iim.fit(np.vstack(predictions), y_sample)",
   "id": "7e93e72b93130990",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.9018 - f1_score: 0.5085 - loss: 0.6594 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9118 - f1_score: 0.4769 - loss: 0.4453 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9049 - f1_score: 0.4750 - loss: 0.3254 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9234 - f1_score: 0.4801 - loss: 0.2734 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9140 - f1_score: 0.4775 - loss: 0.2922 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9236 - f1_score: 0.4801 - loss: 0.2696 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8975 - f1_score: 0.4729 - loss: 0.3340 - learning_rate: 5.3144e-05\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:51:13.911434Z",
     "start_time": "2024-11-25T19:51:13.763268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "iim.evaluate(np.vstack(test_preds), y_test)\n",
    "# resnet"
   ],
   "id": "d7373d642a68e700",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.94, 0.9109278350515464)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:51:18.557261Z",
     "start_time": "2024-11-25T19:51:18.104686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_pred_embed, X_test_pred_embed = [], []\n",
    "for embed, pred in zip(X_embed, predictions):\n",
    "    X_pred_embed.append(np.hstack([embed, pred]))\n",
    "    \n",
    "for embed, pred in zip(X_test_embed, test_preds):\n",
    "    X_test_pred_embed.append(np.hstack([embed, pred]))"
   ],
   "id": "907d450011a19e50",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:51:38.067707Z",
     "start_time": "2024-11-25T19:51:19.046875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "iim = DenseInternalModel(num_classes=2, input_shape=X_pred_embed[0].shape[1])\n",
    "\n",
    "iim.fit(np.vstack(X_pred_embed), y_sample)\n"
   ],
   "id": "663d68d28de79ede",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.6921 - f1_score: 0.4720 - loss: 0.6348 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9302 - f1_score: 0.4819 - loss: 0.3988 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9244 - f1_score: 0.4803 - loss: 0.2926 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9262 - f1_score: 0.4808 - loss: 0.2575 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9133 - f1_score: 0.4772 - loss: 0.2732 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9235 - f1_score: 0.4801 - loss: 0.2485 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9046 - f1_score: 0.4749 - loss: 0.2747 - learning_rate: 5.3144e-05\n",
      "Epoch 8/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9038 - f1_score: 0.4744 - loss: 0.2790 - learning_rate: 4.7830e-05\n",
      "Epoch 9/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9134 - f1_score: 0.4773 - loss: 0.2676 - learning_rate: 4.3047e-05\n",
      "Epoch 10/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9274 - f1_score: 0.4812 - loss: 0.2308 - learning_rate: 3.8742e-05\n",
      "Epoch 11/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9259 - f1_score: 0.4807 - loss: 0.2364 - learning_rate: 3.4868e-05\n",
      "Epoch 12/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9199 - f1_score: 0.4791 - loss: 0.2323 - learning_rate: 3.1381e-05\n",
      "Epoch 13/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9095 - f1_score: 0.4763 - loss: 0.2601 - learning_rate: 2.8243e-05\n",
      "Epoch 14/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9213 - f1_score: 0.4795 - loss: 0.2325 - learning_rate: 2.5419e-05\n",
      "Epoch 15/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9227 - f1_score: 0.4799 - loss: 0.2338 - learning_rate: 2.2877e-05\n",
      "Epoch 16/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9224 - f1_score: 0.4798 - loss: 0.2381 - learning_rate: 2.0589e-05\n",
      "Epoch 17/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9136 - f1_score: 0.4774 - loss: 0.2520 - learning_rate: 1.8530e-05\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:48:21.666198Z",
     "start_time": "2024-11-25T19:48:21.549422Z"
    }
   },
   "cell_type": "code",
   "source": "iim.evaluate(np.vstack(X_test_pred_embed), y_test)",
   "id": "baff53803e2bbdd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.94, 0.9109278350515464)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T19:52:06.360813Z",
     "start_time": "2024-11-25T19:51:38.254969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline = DenseInternalModel(num_classes=2, input_shape=X_sample.shape[1])\n",
    "baseline.fit(X_sample, y_sample)\n",
    "baseline.evaluate(X_test, y_test)"
   ],
   "id": "71d0a5c5364bd012",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 8ms/step - accuracy: 0.5807 - f1_score: 0.4430 - loss: 0.6987 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.7671 - f1_score: 0.4760 - loss: 0.5389 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8928 - f1_score: 0.5261 - loss: 0.4287 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9114 - f1_score: 0.5282 - loss: 0.3774 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9261 - f1_score: 0.5431 - loss: 0.3235 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9184 - f1_score: 0.4939 - loss: 0.3105 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9160 - f1_score: 0.4876 - loss: 0.2886 - learning_rate: 5.3144e-05\n",
      "Epoch 8/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9241 - f1_score: 0.4909 - loss: 0.2700 - learning_rate: 4.7830e-05\n",
      "Epoch 9/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9201 - f1_score: 0.5403 - loss: 0.2565 - learning_rate: 4.3047e-05\n",
      "Epoch 10/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9279 - f1_score: 0.4829 - loss: 0.2495 - learning_rate: 3.8742e-05\n",
      "Epoch 11/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9295 - f1_score: 0.5208 - loss: 0.2407 - learning_rate: 3.4868e-05\n",
      "Epoch 12/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9326 - f1_score: 0.4943 - loss: 0.2257 - learning_rate: 3.1381e-05\n",
      "Epoch 13/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9116 - f1_score: 0.5226 - loss: 0.2560 - learning_rate: 2.8243e-05\n",
      "Epoch 14/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9247 - f1_score: 0.5161 - loss: 0.2261 - learning_rate: 2.5419e-05\n",
      "Epoch 15/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9000 - f1_score: 0.5079 - loss: 0.2679 - learning_rate: 2.2877e-05\n",
      "Epoch 16/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9265 - f1_score: 0.5050 - loss: 0.2222 - learning_rate: 2.0589e-05\n",
      "Epoch 17/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9149 - f1_score: 0.5034 - loss: 0.2511 - learning_rate: 1.8530e-05\n",
      "Epoch 18/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9174 - f1_score: 0.4884 - loss: 0.2311 - learning_rate: 1.6677e-05\n",
      "Epoch 19/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9278 - f1_score: 0.5047 - loss: 0.2091 - learning_rate: 1.5009e-05\n",
      "Epoch 20/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9276 - f1_score: 0.5344 - loss: 0.2213 - learning_rate: 1.3509e-05\n",
      "Epoch 21/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9153 - f1_score: 0.4851 - loss: 0.2437 - learning_rate: 1.2158e-05\n",
      "Epoch 22/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9109 - f1_score: 0.5083 - loss: 0.2312 - learning_rate: 1.0942e-05\n",
      "Epoch 23/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8943 - f1_score: 0.5417 - loss: 0.2850 - learning_rate: 9.8477e-06\n",
      "Epoch 24/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9255 - f1_score: 0.5556 - loss: 0.2255 - learning_rate: 8.8629e-06\n",
      "Epoch 25/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.9207 - f1_score: 0.5202 - loss: 0.2120 - learning_rate: 7.9766e-06\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.939, 0.9104280556988138)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
