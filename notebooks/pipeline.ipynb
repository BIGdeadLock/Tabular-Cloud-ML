{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-29T16:46:40.732090Z",
     "start_time": "2024-12-29T16:46:39.524222Z"
    }
   },
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:46:40.737940Z",
     "start_time": "2024-12-29T16:46:40.735903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECT_PATH = os.getcwd()\n",
    "PROJECT_PATH = os.path.join(PROJECT_PATH, \"..\")\n",
    "MODELS_DIR = pathlib.Path(PROJECT_PATH) / \"store\" / \"models\"\n",
    "\n",
    "DATASET_DIR = pathlib.Path(PROJECT_PATH) / \"data\""
   ],
   "id": "982312657be336ff",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:46:41.514376Z",
     "start_time": "2024-12-29T16:46:40.907677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(DATASET_DIR / \"heloc\"/ \"dataset.csv\")\n",
    "dataset"
   ],
   "id": "a240984fa1f517ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      RiskPerformance  ExternalRiskEstimate  MSinceOldestTradeOpen  \\\n",
       "0                 Bad                    55                    144   \n",
       "1                 Bad                    61                     58   \n",
       "2                 Bad                    67                     66   \n",
       "3                 Bad                    66                    169   \n",
       "4                 Bad                    81                    333   \n",
       "...               ...                   ...                    ...   \n",
       "10454            Good                    73                    131   \n",
       "10455             Bad                    65                    147   \n",
       "10456             Bad                    74                    129   \n",
       "10457             Bad                    72                    234   \n",
       "10458             Bad                    66                     28   \n",
       "\n",
       "       MSinceMostRecentTradeOpen  AverageMInFile  NumSatisfactoryTrades  \\\n",
       "0                              4              84                     20   \n",
       "1                             15              41                      2   \n",
       "2                              5              24                      9   \n",
       "3                              1              73                     28   \n",
       "4                             27             132                     12   \n",
       "...                          ...             ...                    ...   \n",
       "10454                          5              57                     21   \n",
       "10455                         39              68                     11   \n",
       "10456                          6              64                     18   \n",
       "10457                         12             113                     42   \n",
       "10458                          1              17                      4   \n",
       "\n",
       "       NumTrades60Ever2DerogPubRec  NumTrades90Ever2DerogPubRec  \\\n",
       "0                                3                            0   \n",
       "1                                4                            4   \n",
       "2                                0                            0   \n",
       "3                                1                            1   \n",
       "4                                0                            0   \n",
       "...                            ...                          ...   \n",
       "10454                            0                            0   \n",
       "10455                            0                            0   \n",
       "10456                            1                            1   \n",
       "10457                            2                            2   \n",
       "10458                            0                            0   \n",
       "\n",
       "       PercentTradesNeverDelq  MSinceMostRecentDelq  ...  \\\n",
       "0                          83                     2  ...   \n",
       "1                         100                    -7  ...   \n",
       "2                         100                    -7  ...   \n",
       "3                          93                    76  ...   \n",
       "4                         100                    -7  ...   \n",
       "...                       ...                   ...  ...   \n",
       "10454                      95                    80  ...   \n",
       "10455                      92                    28  ...   \n",
       "10456                     100                    -7  ...   \n",
       "10457                      96                    35  ...   \n",
       "10458                     100                    -7  ...   \n",
       "\n",
       "       PercentInstallTrades  MSinceMostRecentInqexcl7days  NumInqLast6M  \\\n",
       "0                        43                             0             0   \n",
       "1                        67                             0             0   \n",
       "2                        44                             0             4   \n",
       "3                        57                             0             5   \n",
       "4                        25                             0             1   \n",
       "...                     ...                           ...           ...   \n",
       "10454                    19                             7             0   \n",
       "10455                    42                             1             1   \n",
       "10456                    33                             3             4   \n",
       "10457                    20                             6             0   \n",
       "10458                    60                             3             3   \n",
       "\n",
       "       NumInqLast6Mexcl7days  NetFractionRevolvingBurden  \\\n",
       "0                          0                          33   \n",
       "1                          0                           0   \n",
       "2                          4                          53   \n",
       "3                          4                          72   \n",
       "4                          1                          51   \n",
       "...                      ...                         ...   \n",
       "10454                      0                          26   \n",
       "10455                      1                          86   \n",
       "10456                      4                           6   \n",
       "10457                      0                          19   \n",
       "10458                      2                          67   \n",
       "\n",
       "       NetFractionInstallBurden  NumRevolvingTradesWBalance  \\\n",
       "0                            -8                           8   \n",
       "1                            -8                           0   \n",
       "2                            66                           4   \n",
       "3                            83                           6   \n",
       "4                            89                           3   \n",
       "...                         ...                         ...   \n",
       "10454                        -8                           5   \n",
       "10455                        53                           2   \n",
       "10456                        -8                           5   \n",
       "10457                        -8                           4   \n",
       "10458                        -8                           2   \n",
       "\n",
       "       NumInstallTradesWBalance  NumBank2NatlTradesWHighUtilization  \\\n",
       "0                             1                                   1   \n",
       "1                            -8                                  -8   \n",
       "2                             2                                   1   \n",
       "3                             4                                   3   \n",
       "4                             1                                   0   \n",
       "...                         ...                                 ...   \n",
       "10454                         2                                   0   \n",
       "10455                         2                                   1   \n",
       "10456                        -8                                   0   \n",
       "10457                         1                                   0   \n",
       "10458                         1                                   0   \n",
       "\n",
       "       PercentTradesWBalance  \n",
       "0                         69  \n",
       "1                          0  \n",
       "2                         86  \n",
       "3                         91  \n",
       "4                         80  \n",
       "...                      ...  \n",
       "10454                    100  \n",
       "10455                     80  \n",
       "10456                     56  \n",
       "10457                     38  \n",
       "10458                    100  \n",
       "\n",
       "[10459 rows x 24 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RiskPerformance</th>\n",
       "      <th>ExternalRiskEstimate</th>\n",
       "      <th>MSinceOldestTradeOpen</th>\n",
       "      <th>MSinceMostRecentTradeOpen</th>\n",
       "      <th>AverageMInFile</th>\n",
       "      <th>NumSatisfactoryTrades</th>\n",
       "      <th>NumTrades60Ever2DerogPubRec</th>\n",
       "      <th>NumTrades90Ever2DerogPubRec</th>\n",
       "      <th>PercentTradesNeverDelq</th>\n",
       "      <th>MSinceMostRecentDelq</th>\n",
       "      <th>...</th>\n",
       "      <th>PercentInstallTrades</th>\n",
       "      <th>MSinceMostRecentInqexcl7days</th>\n",
       "      <th>NumInqLast6M</th>\n",
       "      <th>NumInqLast6Mexcl7days</th>\n",
       "      <th>NetFractionRevolvingBurden</th>\n",
       "      <th>NetFractionInstallBurden</th>\n",
       "      <th>NumRevolvingTradesWBalance</th>\n",
       "      <th>NumInstallTradesWBalance</th>\n",
       "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
       "      <th>PercentTradesWBalance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad</td>\n",
       "      <td>55</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>-8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad</td>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>-7</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-7</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad</td>\n",
       "      <td>66</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad</td>\n",
       "      <td>81</td>\n",
       "      <td>333</td>\n",
       "      <td>27</td>\n",
       "      <td>132</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-7</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10454</th>\n",
       "      <td>Good</td>\n",
       "      <td>73</td>\n",
       "      <td>131</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>-8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10455</th>\n",
       "      <td>Bad</td>\n",
       "      <td>65</td>\n",
       "      <td>147</td>\n",
       "      <td>39</td>\n",
       "      <td>68</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10456</th>\n",
       "      <td>Bad</td>\n",
       "      <td>74</td>\n",
       "      <td>129</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>-7</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-8</td>\n",
       "      <td>5</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10457</th>\n",
       "      <td>Bad</td>\n",
       "      <td>72</td>\n",
       "      <td>234</td>\n",
       "      <td>12</td>\n",
       "      <td>113</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>-8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10458</th>\n",
       "      <td>Bad</td>\n",
       "      <td>66</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-7</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>-8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10459 rows × 24 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:46:58.276949Z",
     "start_time": "2024-12-29T16:46:58.268940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(X: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    The function will preprocess the data:\n",
    "    1. Categorical features will be label encoded (Boy->1, Girl ->2)\n",
    "    2. Numerical features will be scaled if the data is intended to be used for baseline. For cloud data set, no scaling will be preformed.\n",
    "\n",
    "    Return pd.Dataframe\n",
    "    \"\"\"\n",
    "    # Identify categorical and numeric columns\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "    # Initialize lists to store processed columns\n",
    "    processed_columns = []\n",
    "\n",
    "    # If there are categorical columns, apply one-hot encoding\n",
    "    if categorical_cols:\n",
    "        print(\"\\nEncoding categorical columns...\")\n",
    "        # onehot_encoder = OneHotEncoder(categories='auto', sparse=False)\n",
    "        # X_categorical = pd.DataFrame(onehot_encoder.fit_transform(X[categorical_cols]),\n",
    "        #                              columns=onehot_encoder.get_feature_names_out(categorical_cols))\n",
    "        label_encoder = LabelEncoder()\n",
    "        X_categorical = pd.DataFrame()\n",
    "        for col in categorical_cols:\n",
    "            X_categorical[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "        processed_columns.append(X_categorical)\n",
    "\n",
    "    # Apply standard scaling to the numeric columns\n",
    "    if numeric_cols:\n",
    "        print(\"\\nScaling numerical columns...\")\n",
    "        scaler = MinMaxScaler()\n",
    "        X_numeric = X[numeric_cols]\n",
    "        # X_numeric = pd.DataFrame(scaler.fit_transform(X[numeric_cols]), columns=numeric_cols, index=X.index)\n",
    "\n",
    "        processed_columns.append(X_numeric)\n",
    "\n",
    "    # Combine the processed columns\n",
    "    if processed_columns:\n",
    "        X_processed = pd.concat(processed_columns, axis=1)\n",
    "    else:\n",
    "        X_processed = X.copy()  # If there are no categorical or numeric columns, keep the original dataframe\n",
    "\n",
    "\n",
    "    return X_processed\n",
    "\n",
    "\n",
    "dataset = preprocess(dataset)"
   ],
   "id": "909539a4be92cf8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding categorical columns...\n",
      "\n",
      "Scaling numerical columns...\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:46:58.512057Z",
     "start_time": "2024-12-29T16:46:58.504848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X,y = dataset.iloc[:, 1:], dataset.iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, stratify=y)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "id": "20fd537bed251cc5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7844, 23), (2615, 23), (7844,), (2615,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:47:02.433692Z",
     "start_time": "2024-12-29T16:46:58.895549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn, tensorflow as tf\n",
    "from keras.src.utils import to_categorical\n",
    "from keras.src.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.src.callbacks import EarlyStopping\n",
    "from keras.src import Sequential\n",
    "\n",
    "\n",
    "class DNNEmbedding(nn.Module):\n",
    "\n",
    "    name = \"dnn_embedding\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DNNEmbedding, self).__init__()\n",
    "\n",
    "        X, y = kwargs.get(\"X\"), kwargs.get(\"y\")\n",
    "        num_classes = len(set(y))\n",
    "        y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=X.shape[1]//2, activation='tanh', name=\"embedding\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(units=num_classes, activation='softmax', name=\"output\"))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        early_stop = EarlyStopping(patience=2, monitor=\"loss\")\n",
    "\n",
    "        model.fit(X, y,validation_data=[X_test, to_categorical(y_test,2)], epochs=50, batch_size=8, callbacks=[early_stop])\n",
    "        self.model = model.layers[0]\n",
    "        self.classifier = model\n",
    "        self.output_shape = (1, X.shape[1]//2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if type(x) is pd.DataFrame:\n",
    "            x = x.to_numpy()\n",
    "\n",
    "        embedding = self.model(x)\n",
    "        return embedding\n",
    "\n",
    "\n",
    "# Code to run on CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    \n",
    "    embedding = DNNEmbedding(X=X_train, y=y_train)\n",
    "\n"
   ],
   "id": "d69d33283821949f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 366us/step - accuracy: 0.5725 - loss: 0.8027 - val_accuracy: 0.6482 - val_loss: 0.6423\n",
      "Epoch 2/50\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - accuracy: 0.6063 - loss: 0.6738 - val_accuracy: 0.6459 - val_loss: 0.6395\n",
      "Epoch 3/50\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 302us/step - accuracy: 0.6203 - loss: 0.6535 - val_accuracy: 0.6505 - val_loss: 0.6324\n",
      "Epoch 4/50\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - accuracy: 0.6324 - loss: 0.6461 - val_accuracy: 0.6505 - val_loss: 0.6250\n",
      "Epoch 5/50\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299us/step - accuracy: 0.6320 - loss: 0.6512 - val_accuracy: 0.6493 - val_loss: 0.6183\n",
      "Epoch 6/50\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299us/step - accuracy: 0.6483 - loss: 0.6351 - val_accuracy: 0.6474 - val_loss: 0.6246\n",
      "Epoch 7/50\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - accuracy: 0.6360 - loss: 0.6388 - val_accuracy: 0.6696 - val_loss: 0.6190\n",
      "Epoch 8/50\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 302us/step - accuracy: 0.6423 - loss: 0.6365 - val_accuracy: 0.6792 - val_loss: 0.6076\n",
      "Epoch 9/50\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 305us/step - accuracy: 0.6558 - loss: 0.6361 - val_accuracy: 0.6799 - val_loss: 0.6072\n",
      "Epoch 10/50\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 308us/step - accuracy: 0.6547 - loss: 0.6396 - val_accuracy: 0.6757 - val_loss: 0.6084\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:49:35.926741Z",
     "start_time": "2024-12-29T16:49:35.921124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from keras.src.layers import Input, Dense,  Flatten\n",
    "from keras.src.layers import BatchNormalization, Activation, Conv2DTranspose\n",
    "from keras.src.models import Model, Sequential\n",
    "from keras.src.layers import LeakyReLU, Reshape, Conv2D, UpSampling2D, ReLU\n",
    "\n",
    "class BaseEncryptor:\n",
    "\n",
    "    name: str\n",
    "\n",
    "    def __init__(self, input_shape=None, output_shape=None):\n",
    "        self.model = None\n",
    "        self.output_shape = output_shape\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build_generator(self, input_shape, output_shape):\n",
    "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
    "\n",
    "    def encode(self, inputs) -> np.array:\n",
    "        inputs = np.expand_dims(inputs, axis=0)\n",
    "        if self.model is None:\n",
    "            input_shape = inputs.shape[1:]\n",
    "            output_shape = self.output_shape or (1, inputs.shape[2])\n",
    "            self.model = self.build_generator(input_shape, output_shape)\n",
    "        return self.model(inputs).numpy()\n",
    "\n",
    "class DCEncryptor(BaseEncryptor):\n",
    "\n",
    "    name = \"dc\"\n",
    "    \n",
    "    def build_generator(self, input_shape, output_shape):\n",
    "        # Ziv's Model\n",
    "        G = Sequential()\n",
    "\n",
    "        G.add(Reshape(target_shape=[1, *input_shape[1:]], input_shape=input_shape))\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 1x1x4096\n",
    "        G.add(Conv2DTranspose(filters=64, kernel_size=4))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 0, Activations index: 1\n",
    "\n",
    "        # 4x4x64\n",
    "        G.add(Conv2D(filters=64, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 2, Activations index: 5\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 8x8x64\n",
    "        G.add(Conv2D(filters=32, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 8, Activations index: 9\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 16x16x32\n",
    "        G.add(Conv2D(filters=16, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 14, Activations index: 13\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 32x32x16\n",
    "        G.add(Conv2D(filters=8, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 20, Activations index: 17\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 64x64x8\n",
    "        G.add(Conv2D(filters=4, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 26, Activations index: 21\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 128x128x4\n",
    "        G.add(Conv2D(filters=3, kernel_size=4, padding='same'))\n",
    "        G.add(Activation('sigmoid'))\n",
    "        # Weights index: 32, Activations index: 25\n",
    "\n",
    "        return G\n",
    "    \n",
    "    \n",
    "encoder = DCEncryptor(output_shape=(1, 224, 224, 4))"
   ],
   "id": "821dca637b470fff",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:49:50.418346Z",
     "start_time": "2024-12-29T16:49:49.286544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.api.applications import ResNet152V2, VGG16, EfficientNetB7\n",
    "# from keras.api.applications.vgg16 import preprocess_input\n",
    "from keras.api.applications.resnet_v2 import preprocess_input\n",
    "import tensorflow as tf\n",
    "from keras.api.models import load_model\n",
    "\n",
    "\n",
    "def pad(tensor, original, target=600):\n",
    "    pad_height = (target - original) // 2\n",
    "    pad_width = (target - original) // 2\n",
    "    padded_tensor = tf.pad(tensor, [[pad_height, pad_height], [pad_width, pad_width], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "    # If the dimensions are odd, add an extra row/column to one side\n",
    "    if (600 - 224) % 2 != 0:\n",
    "        padded_tensor = tf.pad(padded_tensor, [[0, 1], [0, 1], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "    return padded_tensor[np.newaxis, ...]\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Assuming 'image' is your input tensor\n",
    "    resized_image = tf.image.resize(image, (224, 224))\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "class VGG16CloudModel:\n",
    "    name = \"vgg16\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = self.get_model()\n",
    "        self.input_shape = (224, 224, 3) \n",
    "        self.output_shape = (1,1000)\n",
    "\n",
    "    def fit(self, X_train, y_train, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def get_model(self):\n",
    "        # Load the pretrained VGG16 model with ImageNet weights\n",
    "        # model = load_model(\"/Users/eden.yavin/Projects/Tabular-Cloud-ML/store/models/cifar100_vgg.keras\") #\n",
    "        model = VGG16(weights='imagenet')\n",
    "        return model\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.preprocess(X)\n",
    "        predictions = self.model.predict(X, verbose=None)\n",
    "        return predictions\n",
    "\n",
    "    def preprocess(self, X):\n",
    "        \n",
    "        X = X.copy()\n",
    "        # X = (X * 10000).astype(np.uint8)\n",
    "\n",
    "        if any(s < 224 for s in X.shape[1:3]):\n",
    "            # Pad the input to make its size equal to 224\n",
    "            padded_X = tf.image.resize_with_crop_or_pad(X, 224, 224)\n",
    "\n",
    "            # Ensure the input is properly preprocessed for VGG16\n",
    "            X = preprocess_input(padded_X.numpy())\n",
    "        else:\n",
    "            # If no padding is needed, directly preprocess the input\n",
    "            X = preprocess_input(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    \n",
    "    \n",
    "cloud = VGG16CloudModel()\n"
   ],
   "id": "d010100e38c2c228",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:48:12.592672Z",
     "start_time": "2024-12-29T16:47:11.698154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "X_encrypted, X_test_encrypted = [], []\n",
    "X_embed, X_test_embed = [], []\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "        \n",
    "    for i, x in tqdm(X_train.iterrows(), total=len(X_train)):\n",
    "        \n",
    "        x_embed = embedding(x.values.reshape(1,-1))\n",
    "        X_embed.append(x_embed)\n",
    "        encrypted = encoder.encode(np.vstack(x_embed))\n",
    "    \n",
    "        X_encrypted.append(encrypted)\n",
    "        \n",
    "    for i,x in tqdm(X_test.iterrows(), total=len(X_test)):\n",
    "        x_embed = embedding(x.values.reshape(1,-1))\n",
    "        X_test_embed.append(x_embed)\n",
    "        encrypted = encoder.encode(np.vstack(x_embed))\n",
    "        X_test_encrypted.append(encrypted)"
   ],
   "id": "a24845e75f0e88ae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7844/7844 [00:45<00:00, 172.44it/s]\n",
      "100%|██████████| 2615/2615 [00:15<00:00, 170.08it/s]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:55:37.674078Z",
     "start_time": "2024-12-29T16:50:18.438017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.device('/GPU:0'):\n",
    "\n",
    "    predictions = [\n",
    "        cloud.predict(x)\n",
    "        for x in tqdm(X_encrypted, total=len(X_encrypted), leave=True, position=0)\n",
    "    ]\n",
    "    test_preds = [\n",
    "        cloud.predict(x)\n",
    "        for x in tqdm(X_test_encrypted, total=len(X_test_encrypted), leave=True, position=0)\n",
    "]"
   ],
   "id": "4fcdf191f61ce371",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7844/7844 [03:59<00:00, 32.79it/s]\n",
      "100%|██████████| 2615/2615 [01:20<00:00, 32.67it/s]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:57:20.670200Z",
     "start_time": "2024-12-29T16:57:20.665399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from keras.src.models import Model\n",
    "from keras.src.layers import Dense, Dropout, Input,  BatchNormalization\n",
    "from keras.src.metrics import F1Score\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetworkInternalModel(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.batch_size = 8\n",
    "        self.dropout_rate = 0.3\n",
    "        self.epochs = 100\n",
    "        self.model: Model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y_onehot = to_categorical(y , 2)\n",
    "        lr_scheduler = LearningRateScheduler(lambda epoch: 0.0001 * (0.9 ** epoch))\n",
    "        early_stopping = EarlyStopping(patience=3, monitor='loss')\n",
    "        self.model.fit(X, y_onehot, epochs=self.epochs, batch_size=self.batch_size, callbacks=[lr_scheduler, early_stopping])\n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = self.model.predict(X)\n",
    "        return np.argmax(prediction, axis=1)\n",
    "\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        if len(y.shape) == 2:\n",
    "            y = np.argmax(y, axis=1)\n",
    "\n",
    "        pred = self.predict(X)\n",
    "        return accuracy_score(y, pred), f1_score(y, pred, average='weighted')\n",
    "\n"
   ],
   "id": "d539c7408c4e256",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using one vector",
   "id": "8ab8b36d3ad9275"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:57:22.533058Z",
     "start_time": "2024-12-29T16:57:22.528244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class DenseInternalModel(NeuralNetworkInternalModel):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = \"neural_network\"\n",
    "        num_classes = kwargs.get(\"num_classes\")\n",
    "        input_shape = kwargs.get(\"input_shape\")\n",
    "        self.model = self.get_model(num_classes=num_classes, input_shape=input_shape)\n",
    "\n",
    "    def get_model(self, num_classes, input_shape):\n",
    "        # Build the model\n",
    "        inputs = Input(shape=(input_shape,))  # Dynamic input shape\n",
    "\n",
    "        # Define the hidden layers\n",
    "        x = BatchNormalization()(inputs)\n",
    "        x = Dense(units=128, activation='leaky_relu')(x)\n",
    "        x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        # Define the output layer\n",
    "        outputs = Dense(units=num_classes, activation='softmax')(x)\n",
    "\n",
    "        # Create the model\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        # Compile the model with F1 Score\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy', F1Score()]\n",
    "                      )\n",
    "\n",
    "        return model\n",
    "    "
   ],
   "id": "2f2288e0568e144c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using Embedding Vector",
   "id": "e019306d9334a125"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:57:29.621220Z",
     "start_time": "2024-12-29T16:57:24.057313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    iim = DenseInternalModel(num_classes=2, input_shape=X_embed[0].shape[1])\n",
    "    iim.fit(np.vstack(X_embed), y_train)\n",
    "    print(\"--------PERFORMANCE-------\")\n",
    "    print(iim.evaluate(np.vstack(X_test_embed), y_test))"
   ],
   "id": "77352623274e12a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 310us/step - accuracy: 0.5528 - f1_score: 0.5463 - loss: 0.6973 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 296us/step - accuracy: 0.6458 - f1_score: 0.6452 - loss: 0.6351 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - accuracy: 0.6468 - f1_score: 0.6456 - loss: 0.6374 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - accuracy: 0.6491 - f1_score: 0.6485 - loss: 0.6325 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 297us/step - accuracy: 0.6500 - f1_score: 0.6495 - loss: 0.6303 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 297us/step - accuracy: 0.6611 - f1_score: 0.6609 - loss: 0.6288 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 296us/step - accuracy: 0.6630 - f1_score: 0.6622 - loss: 0.6140 - learning_rate: 5.3144e-05\n",
      "Epoch 8/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - accuracy: 0.6662 - f1_score: 0.6653 - loss: 0.6197 - learning_rate: 4.7830e-05\n",
      "Epoch 9/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - accuracy: 0.6621 - f1_score: 0.6617 - loss: 0.6253 - learning_rate: 4.3047e-05\n",
      "Epoch 10/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 303us/step - accuracy: 0.6633 - f1_score: 0.6628 - loss: 0.6228 - learning_rate: 3.8742e-05\n",
      "Epoch 11/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 305us/step - accuracy: 0.6565 - f1_score: 0.6560 - loss: 0.6261 - learning_rate: 3.4868e-05\n",
      "--------PERFORMANCE-------\n",
      "\u001B[1m82/82\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 362us/step\n",
      "(0.6856596558317399, 0.685804498300382)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:02:34.067435Z",
     "start_time": "2024-12-29T17:02:33.912569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "iim = XGBClassifier()\n",
    "iim.fit(np.vstack(X_embed), y_train)\n",
    "print(\"--------PERFORMANCE-------\")\n",
    "pred = iim.predict(np.vstack(X_test_embed))\n",
    "accuracy_score(y_test, pred), f1_score(y_test, pred, average='weighted')"
   ],
   "id": "21196e3a13c802b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------PERFORMANCE-------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.665774378585086, 0.6659135091315428)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using Pred Vector",
   "id": "53b159c52929e7f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:57:38.214544Z",
     "start_time": "2024-12-29T16:57:32.392094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Code to run on CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    iim = DenseInternalModel(num_classes=2, input_shape=predictions[0].shape[1])\n",
    "    iim.fit(np.vstack(predictions), y_train)\n",
    "    print(\"--------PERFORMANCE-------\")\n",
    "    print(iim.evaluate(np.vstack(test_preds), y_test))"
   ],
   "id": "7e93e72b93130990",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 674us/step - accuracy: 0.5238 - f1_score: 0.3600 - loss: 0.6927 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 677us/step - accuracy: 0.5198 - f1_score: 0.3420 - loss: 0.6927 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 676us/step - accuracy: 0.5254 - f1_score: 0.3444 - loss: 0.6923 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 683us/step - accuracy: 0.5270 - f1_score: 0.3462 - loss: 0.6919 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 747us/step - accuracy: 0.5237 - f1_score: 0.3437 - loss: 0.6920 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 667us/step - accuracy: 0.5252 - f1_score: 0.3443 - loss: 0.6925 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 650us/step - accuracy: 0.5118 - f1_score: 0.3385 - loss: 0.6931 - learning_rate: 5.3144e-05\n",
      "Epoch 8/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 686us/step - accuracy: 0.5182 - f1_score: 0.3413 - loss: 0.6927 - learning_rate: 4.7830e-05\n",
      "--------PERFORMANCE-------\n",
      "\u001B[1m82/82\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 427us/step\n",
      "(0.5219885277246654, 0.3580474072081248)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:02:50.657918Z",
     "start_time": "2024-12-29T17:02:49.965916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "iim = XGBClassifier()\n",
    "iim.fit(np.vstack(predictions), y_train)\n",
    "print(\"--------PERFORMANCE-------\")\n",
    "pred = iim.predict(np.vstack(test_preds))\n",
    "accuracy_score(y_test, pred), f1_score(y_test, pred, average='weighted')"
   ],
   "id": "75835315039309d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------PERFORMANCE-------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6481835564053537, 0.6482276701825916)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using Both Prediction and Embedding as One Vector",
   "id": "840752add63aeb4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:57:43.542026Z",
     "start_time": "2024-12-29T16:57:43.491757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_pred_embed, X_test_pred_embed = [], []\n",
    "for embed, pred in zip(X_embed, predictions):\n",
    "    X_pred_embed.append(np.hstack([embed, pred]))\n",
    "    \n",
    "for embed, pred in zip(X_test_embed, test_preds):\n",
    "    X_test_pred_embed.append(np.hstack([embed, pred]))"
   ],
   "id": "907d450011a19e50",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:57:56.258973Z",
     "start_time": "2024-12-29T16:57:51.998673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    \n",
    "    iim = DenseInternalModel(num_classes=2, input_shape=X_pred_embed[0].shape[1])\n",
    "    iim.fit(np.vstack(X_pred_embed), y_train)\n",
    "    print(\"--------PERFORMANCE-------\")\n",
    "    print(iim.evaluate(np.vstack(X_test_pred_embed), y_test))\n"
   ],
   "id": "663d68d28de79ede",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 924us/step - accuracy: 0.6020 - f1_score: 0.6019 - loss: 0.6549 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 739us/step - accuracy: 0.6658 - f1_score: 0.6657 - loss: 0.6221 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 731us/step - accuracy: 0.6486 - f1_score: 0.6484 - loss: 0.6294 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 722us/step - accuracy: 0.6541 - f1_score: 0.6540 - loss: 0.6251 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 715us/step - accuracy: 0.6551 - f1_score: 0.6548 - loss: 0.6256 - learning_rate: 6.5610e-05\n",
      "--------PERFORMANCE-------\n",
      "\u001B[1m82/82\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 467us/step\n",
      "(0.6783938814531548, 0.6781022232248638)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:04:32.418942Z",
     "start_time": "2024-12-29T17:04:31.651759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "iim = XGBClassifier(random_state=42)\n",
    "iim.fit(np.vstack(X_pred_embed), y_train)\n",
    "print(\"--------PERFORMANCE-------\")\n",
    "pred = iim.predict(np.vstack(X_test_pred_embed))\n",
    "accuracy_score(y_test, pred), f1_score(y_test, pred, average='weighted')"
   ],
   "id": "45643fd0045d231b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------PERFORMANCE-------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6596558317399618, 0.6597263128416567)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:05:31.429326Z",
     "start_time": "2024-12-29T17:05:30.460730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Create and train the first XGBoost model on X1\n",
    "model1 = XGBClassifier(random_state=42)\n",
    "model1.fit(np.vstack(X_embed), y_train)\n",
    "\n",
    "# Create and train the second XGBoost model on X2\n",
    "model2 = XGBClassifier(random_state=42)\n",
    "model2.fit(np.vstack(predictions), y_train)\n",
    "\n",
    "# Make predictions using both models (probability of class 1)\n",
    "pred1_train = model1.predict_proba(np.vstack(X_embed))[:, 1].reshape(-1, 1)\n",
    "pred2_train = model2.predict_proba(np.vstack(predictions))[:, 1].reshape(-1, 1)\n",
    "pred1_test = model1.predict_proba(np.vstack(X_test_embed))[:, 1].reshape(-1, 1)\n",
    "pred2_test = model2.predict_proba(np.vstack(test_preds))[:, 1].reshape(-1, 1)\n",
    "\n",
    "# Combine predictions for meta-model training\n",
    "X_meta_train = np.hstack((pred1_train, pred2_train))\n",
    "X_meta_test = np.hstack((pred1_test, pred2_test))\n",
    "\n",
    "# Create and train the meta-model (stacking)\n",
    "meta_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "meta_model.fit(X_meta_train, y_train)\n",
    "\n",
    "# Make final predictions using the meta-model\n",
    "final_predictions = meta_model.predict(X_meta_test)\n",
    "\n",
    "# Evaluate the stacked model\n",
    "accuracy_score(y_test, final_predictions), f1_score(y_test, final_predictions, average='weighted')\n"
   ],
   "id": "5535a9a8b9f9042",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6588910133843212, 0.6586733545079823)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Baseline",
   "id": "f7b551f8ab973726"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:58:57.409923Z",
     "start_time": "2024-12-29T16:58:52.055548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    baseline = DenseInternalModel(num_classes=2, input_shape=X_train.shape[1])\n",
    "    baseline.fit(X_train, y_train)\n",
    "    print(\"--------PERFORMANCE-------\")\n",
    "    print(baseline.evaluate(X_test, y_test))"
   ],
   "id": "71d0a5c5364bd012",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 334us/step - accuracy: 0.5915 - f1_score: 0.5883 - loss: 0.6839 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 299us/step - accuracy: 0.6683 - f1_score: 0.6671 - loss: 0.6165 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 301us/step - accuracy: 0.6831 - f1_score: 0.6818 - loss: 0.6129 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 294us/step - accuracy: 0.6647 - f1_score: 0.6638 - loss: 0.6109 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 300us/step - accuracy: 0.6837 - f1_score: 0.6818 - loss: 0.5982 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298us/step - accuracy: 0.6827 - f1_score: 0.6811 - loss: 0.6012 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 295us/step - accuracy: 0.6734 - f1_score: 0.6723 - loss: 0.6079 - learning_rate: 5.3144e-05\n",
      "Epoch 8/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 316us/step - accuracy: 0.6831 - f1_score: 0.6816 - loss: 0.6012 - learning_rate: 4.7830e-05\n",
      "Epoch 9/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 419us/step - accuracy: 0.6966 - f1_score: 0.6955 - loss: 0.5924 - learning_rate: 4.3047e-05\n",
      "Epoch 10/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 487us/step - accuracy: 0.6893 - f1_score: 0.6873 - loss: 0.5920 - learning_rate: 3.8742e-05\n",
      "Epoch 11/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 577us/step - accuracy: 0.6928 - f1_score: 0.6916 - loss: 0.5897 - learning_rate: 3.4868e-05\n",
      "Epoch 12/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 499us/step - accuracy: 0.7009 - f1_score: 0.6998 - loss: 0.5898 - learning_rate: 3.1381e-05\n",
      "Epoch 13/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 474us/step - accuracy: 0.6902 - f1_score: 0.6890 - loss: 0.5912 - learning_rate: 2.8243e-05\n",
      "--------PERFORMANCE-------\n",
      "\u001B[1m82/82\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 486us/step\n",
      "(0.722753346080306, 0.7218627693959032)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using Two vectors",
   "id": "fb4dd9071a5c4464"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:59:08.288082Z",
     "start_time": "2024-12-29T16:59:08.282241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from keras.src.models import Model\n",
    "from keras.src.layers import Dense, Dropout, Input,  BatchNormalization, concatenate\n",
    "from keras.src.metrics import F1Score\n",
    "from keras.src import regularizers\n",
    "\n",
    "class DoubleDenseInternalModel(NeuralNetworkInternalModel):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = \"neural_network\"\n",
    "        num_classes = kwargs.get(\"num_classes\")\n",
    "        input_shape = kwargs.get(\"input_shape\")\n",
    "        self.model = self.get_model(num_classes=num_classes, input_shape=input_shape)\n",
    "\n",
    "    def get_model(self, num_classes, input_shape):\n",
    "        inputs_sub_networks = []\n",
    "\n",
    "        input_shape_a, input_shape_b = input_shape\n",
    "        input_a = Input(shape=(input_shape_a,))\n",
    "\n",
    "        x = Dense(input_shape_a // 2, activation=\"relu\", kernel_regularizer=regularizers.L2(0.1), bias_regularizer=regularizers.L2(0.01))(\n",
    "            input_a)\n",
    "        x = BatchNormalization(momentum=0.7)(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        # x = Dense(input_shape_a / 2, activation=\"relu\")(x)\n",
    "        x = Model(inputs=input_a, outputs=x)\n",
    "\n",
    "        inputs_sub_networks.append(x)\n",
    "\n",
    "        input_b = Input(shape=(input_shape_b,))\n",
    "        # the second branch operates on the second input\n",
    "        y = Dense(input_shape_b // 4, activation=\"relu\", kernel_regularizer=regularizers.L2(0.1),  bias_regularizer=regularizers.L2(0.01))(\n",
    "            input_b)\n",
    "        y = BatchNormalization(momentum=0.7)(y)\n",
    "        y = Dropout(0.3)(y)\n",
    "        y = Model(inputs=input_b, outputs=y)\n",
    "\n",
    "        inputs_sub_networks.append(y)\n",
    "\n",
    "        combined = concatenate([k.output for k in inputs_sub_networks])\n",
    "\n",
    "        m = Dense(num_classes, activation=\"softmax\", kernel_regularizer=regularizers.L2(0.1),\n",
    "                  bias_regularizer=regularizers.L2(0.1))(combined)\n",
    "\n",
    "        model = Model(inputs=[k.input for k in inputs_sub_networks], outputs=m)\n",
    "        # Compile the model with F1 Score\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy', F1Score()]\n",
    "                      )\n",
    "\n",
    "        return model"
   ],
   "id": "6ebe9cdab8a6d67e",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:59:09.070525Z",
     "start_time": "2024-12-29T16:59:09.037126Z"
    }
   },
   "cell_type": "code",
   "source": "X_double_pred_embed, X_double_test_pred_embed = [np.vstack(X_embed), np.vstack(predictions)], [np.vstack(X_test_embed), np.vstack(test_preds)]\n",
   "id": "9a551e38213cf3a6",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:00:46.654622Z",
     "start_time": "2024-12-29T16:59:13.513129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    double_iim = DoubleDenseInternalModel(num_classes=2, input_shape=(X_double_pred_embed[0].shape[1],X_double_pred_embed[1].shape[1]))\n",
    "    double_iim.fit(X_double_pred_embed, y_train)\n",
    "    print(\"--------PERFORMANCE-------\")\n",
    "    print(double_iim.evaluate(X_double_test_pred_embed, y_test))\n",
    "\n"
   ],
   "id": "b6a74bcbb9bb2988",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step - accuracy: 0.5084 - f1_score: 0.5058 - loss: 20.2064 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5368 - f1_score: 0.5353 - loss: 1.2766 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step - accuracy: 0.5454 - f1_score: 0.5451 - loss: 1.0276 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5770 - f1_score: 0.5764 - loss: 0.9072 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.5984 - f1_score: 0.5979 - loss: 0.8228 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.6338 - f1_score: 0.6337 - loss: 0.7675 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.6487 - f1_score: 0.6484 - loss: 0.7254 - learning_rate: 5.3144e-05\n",
      "Epoch 8/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.6466 - f1_score: 0.6462 - loss: 0.7020 - learning_rate: 4.7830e-05\n",
      "Epoch 9/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.6601 - f1_score: 0.6598 - loss: 0.6854 - learning_rate: 4.3047e-05\n",
      "Epoch 10/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.6521 - f1_score: 0.6517 - loss: 0.6805 - learning_rate: 3.8742e-05\n",
      "Epoch 11/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.6553 - f1_score: 0.6549 - loss: 0.6726 - learning_rate: 3.4868e-05\n",
      "Epoch 12/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.6544 - f1_score: 0.6543 - loss: 0.6636 - learning_rate: 3.1381e-05\n",
      "Epoch 13/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - accuracy: 0.6579 - f1_score: 0.6576 - loss: 0.6653 - learning_rate: 2.8243e-05\n",
      "Epoch 14/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.6632 - f1_score: 0.6631 - loss: 0.6599 - learning_rate: 2.5419e-05\n",
      "Epoch 15/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 4ms/step - accuracy: 0.6498 - f1_score: 0.6497 - loss: 0.6554 - learning_rate: 2.2877e-05\n",
      "Epoch 16/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.6527 - f1_score: 0.6524 - loss: 0.6575 - learning_rate: 2.0589e-05\n",
      "Epoch 17/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.6686 - f1_score: 0.6686 - loss: 0.6495 - learning_rate: 1.8530e-05\n",
      "Epoch 18/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.6617 - f1_score: 0.6616 - loss: 0.6579 - learning_rate: 1.6677e-05\n",
      "Epoch 19/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.6581 - f1_score: 0.6579 - loss: 0.6531 - learning_rate: 1.5009e-05\n",
      "Epoch 20/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 6ms/step - accuracy: 0.6583 - f1_score: 0.6582 - loss: 0.6524 - learning_rate: 1.3509e-05\n",
      "Epoch 21/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.6646 - f1_score: 0.6645 - loss: 0.6486 - learning_rate: 1.2158e-05\n",
      "Epoch 22/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.6609 - f1_score: 0.6608 - loss: 0.6489 - learning_rate: 1.0942e-05\n",
      "Epoch 23/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.6673 - f1_score: 0.6671 - loss: 0.6465 - learning_rate: 9.8477e-06\n",
      "Epoch 24/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6571 - f1_score: 0.6571 - loss: 0.6480 - learning_rate: 8.8629e-06\n",
      "Epoch 25/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.6609 - f1_score: 0.6608 - loss: 0.6485 - learning_rate: 7.9766e-06\n",
      "Epoch 26/100\n",
      "\u001B[1m981/981\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.6553 - f1_score: 0.6551 - loss: 0.6531 - learning_rate: 7.1790e-06\n",
      "--------PERFORMANCE-------\n",
      "\u001B[1m82/82\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "(0.6749521988527725, 0.6728319434895682)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Correlation",
   "id": "72bb92bb99514ed7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:37:23.254379Z",
     "start_time": "2024-12-22T13:37:23.138838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows = []\n",
    "for embed, pred, label in zip(X_embed, predictions, y_sample):\n",
    "    rows.append(np.hstack([embed, pred, np.vstack([label])]))\n",
    "df = pd.DataFrame(np.vstack(rows))\n",
    "df.head()"
   ],
   "id": "96894e2f55346cf3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   0    1    2    3    4    5    6    7             8             9    ...  \\\n",
       "0 -1.0 -1.0 -1.0 -1.0  1.0 -1.0 -1.0  1.0  2.766979e-07  5.367829e-09  ...   \n",
       "1 -1.0 -1.0 -1.0 -1.0  1.0 -1.0 -1.0  1.0  2.766979e-07  5.367829e-09  ...   \n",
       "2 -1.0 -1.0 -1.0 -1.0  1.0 -1.0 -1.0 -1.0  2.766727e-07  5.367589e-09  ...   \n",
       "3 -1.0 -1.0 -1.0 -1.0 -1.0  1.0 -1.0  1.0  2.766951e-07  5.367594e-09  ...   \n",
       "4 -1.0 -1.0 -1.0 -1.0  1.0 -1.0 -1.0 -1.0  2.766727e-07  5.367589e-09  ...   \n",
       "\n",
       "        99        100           101           102           103       104  \\\n",
       "0  0.000001  0.000005  5.753773e-07  1.384776e-09  2.619639e-07  0.000001   \n",
       "1  0.000001  0.000005  5.753773e-07  1.384776e-09  2.619639e-07  0.000001   \n",
       "2  0.000001  0.000005  5.753566e-07  1.384754e-09  2.619567e-07  0.000001   \n",
       "3  0.000001  0.000005  5.753533e-07  1.384647e-09  2.619532e-07  0.000001   \n",
       "4  0.000001  0.000005  5.753566e-07  1.384754e-09  2.619567e-07  0.000001   \n",
       "\n",
       "            105           106       107  108  \n",
       "0  1.063482e-09  1.579175e-07  0.000266  0.0  \n",
       "1  1.063482e-09  1.579175e-07  0.000266  0.0  \n",
       "2  1.063456e-09  1.579101e-07  0.000266  0.0  \n",
       "3  1.063356e-09  1.579191e-07  0.000266  0.0  \n",
       "4  1.063456e-09  1.579101e-07  0.000266  0.0  \n",
       "\n",
       "[5 rows x 109 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.766979e-07</td>\n",
       "      <td>5.367829e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753773e-07</td>\n",
       "      <td>1.384776e-09</td>\n",
       "      <td>2.619639e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063482e-09</td>\n",
       "      <td>1.579175e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.766979e-07</td>\n",
       "      <td>5.367829e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753773e-07</td>\n",
       "      <td>1.384776e-09</td>\n",
       "      <td>2.619639e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063482e-09</td>\n",
       "      <td>1.579175e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.766727e-07</td>\n",
       "      <td>5.367589e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753566e-07</td>\n",
       "      <td>1.384754e-09</td>\n",
       "      <td>2.619567e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063456e-09</td>\n",
       "      <td>1.579101e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.766951e-07</td>\n",
       "      <td>5.367594e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753533e-07</td>\n",
       "      <td>1.384647e-09</td>\n",
       "      <td>2.619532e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063356e-09</td>\n",
       "      <td>1.579191e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.766727e-07</td>\n",
       "      <td>5.367589e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753566e-07</td>\n",
       "      <td>1.384754e-09</td>\n",
       "      <td>2.619567e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063456e-09</td>\n",
       "      <td>1.579101e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:49:08.144554Z",
     "start_time": "2024-12-22T13:49:08.122745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows = []\n",
    "for embed, pred, label in zip(X_test_embed, test_preds, y_test):\n",
    "    rows.append(np.hstack([embed, pred, np.vstack([label])]))\n",
    "\n",
    "test_df = pd.DataFrame(np.vstack(rows))\n",
    "test_df.head()"
   ],
   "id": "4524f5d7864e9dc6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        0    1    2         3         4    5    6    7             8    \\\n",
       "0 -0.996705 -1.0 -1.0 -0.999537 -1.000000 -1.0 -1.0  1.0  2.766912e-07   \n",
       "1 -1.000000 -1.0 -1.0 -1.000000  1.000000 -1.0 -1.0  1.0  2.766979e-07   \n",
       "2 -0.999570 -1.0 -1.0 -1.000000 -1.000000 -1.0 -1.0  1.0  2.766907e-07   \n",
       "3 -1.000000 -1.0 -1.0  1.000000 -0.998985 -1.0 -1.0 -1.0  2.766720e-07   \n",
       "4 -1.000000 -1.0 -1.0 -1.000000 -0.999996 -1.0 -1.0  1.0  2.766909e-07   \n",
       "\n",
       "            9    ...       99        100           101           102  \\\n",
       "0  5.367964e-09  ...  0.000001  0.000005  5.753951e-07  1.384787e-09   \n",
       "1  5.367829e-09  ...  0.000001  0.000005  5.753773e-07  1.384776e-09   \n",
       "2  5.367943e-09  ...  0.000001  0.000005  5.753918e-07  1.384787e-09   \n",
       "3  5.367792e-09  ...  0.000001  0.000005  5.753728e-07  1.384619e-09   \n",
       "4  5.367933e-09  ...  0.000001  0.000005  5.753923e-07  1.384779e-09   \n",
       "\n",
       "            103       104           105           106       107  108  \n",
       "0  2.619570e-07  0.000001  1.063490e-09  1.579187e-07  0.000266  0.0  \n",
       "1  2.619639e-07  0.000001  1.063482e-09  1.579175e-07  0.000266  0.0  \n",
       "2  2.619565e-07  0.000001  1.063482e-09  1.579196e-07  0.000266  0.0  \n",
       "3  2.619551e-07  0.000001  1.063365e-09  1.579138e-07  0.000266  0.0  \n",
       "4  2.619559e-07  0.000001  1.063486e-09  1.579189e-07  0.000266  0.0  \n",
       "\n",
       "[5 rows x 109 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.996705</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.999537</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.766912e-07</td>\n",
       "      <td>5.367964e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753951e-07</td>\n",
       "      <td>1.384787e-09</td>\n",
       "      <td>2.619570e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063490e-09</td>\n",
       "      <td>1.579187e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.766979e-07</td>\n",
       "      <td>5.367829e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753773e-07</td>\n",
       "      <td>1.384776e-09</td>\n",
       "      <td>2.619639e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063482e-09</td>\n",
       "      <td>1.579175e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.999570</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.766907e-07</td>\n",
       "      <td>5.367943e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753918e-07</td>\n",
       "      <td>1.384787e-09</td>\n",
       "      <td>2.619565e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063482e-09</td>\n",
       "      <td>1.579196e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.998985</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.766720e-07</td>\n",
       "      <td>5.367792e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753728e-07</td>\n",
       "      <td>1.384619e-09</td>\n",
       "      <td>2.619551e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063365e-09</td>\n",
       "      <td>1.579138e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.766909e-07</td>\n",
       "      <td>5.367933e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.753923e-07</td>\n",
       "      <td>1.384779e-09</td>\n",
       "      <td>2.619559e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.063486e-09</td>\n",
       "      <td>1.579189e-07</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:42:34.280119Z",
     "start_time": "2024-12-22T13:42:34.014870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "correlation_matrix = df.corr()\n",
    "\n",
    "TOP = 10\n",
    "target_correlation = correlation_matrix.iloc[-1].abs().sort_values(ascending=False)\n",
    "top_target_corr = target_correlation[1:TOP]  # Exclude the target's correlation with itself\n",
    "\n",
    "print(f\"Top {TOP} feature correlations with the target:\")\n",
    "print(top_target_corr)"
   ],
   "id": "bda743c258e61be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 feature correlations with the target:\n",
      "6      0.003050\n",
      "2      0.007783\n",
      "4      0.013605\n",
      "67     0.015070\n",
      "11     0.016073\n",
      "60     0.024851\n",
      "102    0.026671\n",
      "1      0.029054\n",
      "0      0.035994\n",
      "Name: 108, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:41:46.435550Z",
     "start_time": "2024-12-22T13:41:46.418440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TOP = 20\n",
    "\n",
    "# Get the top 10 feature-feature correlations\n",
    "feature_correlation = correlation_matrix.abs().unstack()\n",
    "feature_correlation = feature_correlation[feature_correlation < 1.0]  # Remove self-correlations\n",
    "top_feature_corr = feature_correlation.sort_values(ascending=False)[:TOP]\n",
    "\n",
    "print(f\"\\nTop {TOP} feature-feature correlations:\")\n",
    "print(top_feature_corr)"
   ],
   "id": "4559fc7b94dd5875",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 feature-feature correlations:\n",
      "91   8      0.991189\n",
      "8    91     0.991189\n",
      "101  9      0.986578\n",
      "9    101    0.986578\n",
      "44   43     0.986427\n",
      "43   44     0.986427\n",
      "59   100    0.985324\n",
      "100  59     0.985324\n",
      "20   23     0.984703\n",
      "23   20     0.984703\n",
      "107  52     0.982269\n",
      "52   107    0.982269\n",
      "19   106    0.980771\n",
      "106  19     0.980771\n",
      "25   66     0.979824\n",
      "66   25     0.979824\n",
      "44   58     0.979658\n",
      "58   44     0.979658\n",
      "107  99     0.978215\n",
      "99   107    0.978215\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dim Reduction",
   "id": "7a801bba75bced80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:47:11.751482Z",
     "start_time": "2024-12-22T13:47:11.718386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming your data is in a numpy array called 'X' with shape (n_samples, 1009)\n",
    "# If not, you need to load and prepare your data first\n",
    "X,y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=10)\n",
    "X_reduced = pca.fit_transform(X_scaled)\n",
    "\n",
    "# X_reduced now has shape (n_samples, 10)\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Total explained variance:\", sum(pca.explained_variance_ratio_))"
   ],
   "id": "9bd8b1556282ba21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.53415906 0.25490196 0.06251872 0.03584684 0.02870274 0.01985813\n",
      " 0.01562191 0.01151777 0.01084    0.00854644]\n",
      "Total explained variance: 0.9825135639825718\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:51:53.272813Z",
     "start_time": "2024-12-22T13:51:53.263337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test,_ = test_df.iloc[:, :-1], test_df.iloc[:, -1]\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=10)\n",
    "X_test_reduced = pca.fit_transform(X_test_scaled)\n",
    "\n",
    "# X_reduced now has shape (n_samples, 10)\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Total explained variance:\", sum(pca.explained_variance_ratio_))"
   ],
   "id": "c5fd811993ad48b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.53593826 0.2474006  0.05817848 0.04273527 0.02496998 0.01911342\n",
      " 0.01823509 0.0139761  0.01179614 0.01007248]\n",
      "Total explained variance: 0.9824158305038713\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:52:06.907251Z",
     "start_time": "2024-12-22T13:51:55.547816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    \n",
    "    iim = DenseInternalModel(num_classes=2, input_shape=X_reduced.shape[1])\n",
    "    iim.fit(X_reduced, y_sample)\n",
    "    print(\"--------PERFORMANCE-------\")\n",
    "    print(iim.evaluate(X_test_reduced, y_test))"
   ],
   "id": "1c05cb01289cf563",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 285us/step - accuracy: 0.8543 - f1_score: 0.5073 - loss: 0.4010 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 277us/step - accuracy: 0.9151 - f1_score: 0.5256 - loss: 0.2679 - learning_rate: 9.0000e-05\n",
      "Epoch 3/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 276us/step - accuracy: 0.9144 - f1_score: 0.5435 - loss: 0.2659 - learning_rate: 8.1000e-05\n",
      "Epoch 4/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 276us/step - accuracy: 0.9178 - f1_score: 0.5436 - loss: 0.2547 - learning_rate: 7.2900e-05\n",
      "Epoch 5/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 275us/step - accuracy: 0.9171 - f1_score: 0.5415 - loss: 0.2559 - learning_rate: 6.5610e-05\n",
      "Epoch 6/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 274us/step - accuracy: 0.9220 - f1_score: 0.5675 - loss: 0.2468 - learning_rate: 5.9049e-05\n",
      "Epoch 7/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 275us/step - accuracy: 0.9136 - f1_score: 0.5582 - loss: 0.2631 - learning_rate: 5.3144e-05\n",
      "Epoch 8/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 280us/step - accuracy: 0.9159 - f1_score: 0.5524 - loss: 0.2653 - learning_rate: 4.7830e-05\n",
      "Epoch 9/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 284us/step - accuracy: 0.9171 - f1_score: 0.5453 - loss: 0.2568 - learning_rate: 4.3047e-05\n",
      "Epoch 10/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 291us/step - accuracy: 0.9115 - f1_score: 0.5438 - loss: 0.2695 - learning_rate: 3.8742e-05\n",
      "Epoch 11/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 307us/step - accuracy: 0.9194 - f1_score: 0.5701 - loss: 0.2528 - learning_rate: 3.4868e-05\n",
      "Epoch 12/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 348us/step - accuracy: 0.9188 - f1_score: 0.5634 - loss: 0.2504 - learning_rate: 3.1381e-05\n",
      "Epoch 13/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 303us/step - accuracy: 0.9164 - f1_score: 0.5447 - loss: 0.2573 - learning_rate: 2.8243e-05\n",
      "Epoch 14/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 320us/step - accuracy: 0.9163 - f1_score: 0.5487 - loss: 0.2579 - learning_rate: 2.5419e-05\n",
      "Epoch 15/100\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 282us/step - accuracy: 0.9187 - f1_score: 0.5683 - loss: 0.2521 - learning_rate: 2.2877e-05\n",
      "--------PERFORMANCE-------\n",
      "\u001B[1m63/63\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 390us/step\n",
      "(0.945, 0.927847520417614)\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:51:33.579106Z",
     "start_time": "2024-12-22T13:51:33.577082Z"
    }
   },
   "cell_type": "code",
   "source": "X_test_reduced.shape, y_test.shape",
   "id": "35dee69d2918f0bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 10), (2000,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3687494b5c101b28"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
