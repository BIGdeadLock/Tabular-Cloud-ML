{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-22T18:55:08.941403Z",
     "start_time": "2024-12-22T18:55:05.270825Z"
    }
   },
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T18:55:08.950885Z",
     "start_time": "2024-12-22T18:55:08.948544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECT_PATH = os.getcwd()\n",
    "PROJECT_PATH = os.path.join(PROJECT_PATH, \"..\")\n",
    "MODELS_DIR = pathlib.Path(PROJECT_PATH) / \"store\" / \"models\"\n",
    "\n",
    "DATASET_DIR = pathlib.Path(PROJECT_PATH) / \"data\""
   ],
   "id": "3b76c2a988c82238",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T18:55:11.093308Z",
     "start_time": "2024-12-22T18:55:08.961531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(DATASET_DIR / \"bank_marketing\"/ \"dataset.csv\")\n",
    "dataset"
   ],
   "id": "77e11cec3986aac5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       age           job   marital  education default  balance housing loan  \\\n",
       "0       27    management    single  secondary      no       35      no   no   \n",
       "1       54   blue-collar   married    primary      no      466      no   no   \n",
       "2       43   blue-collar   married  secondary      no      105      no  yes   \n",
       "3       31    technician    single  secondary      no       19      no   no   \n",
       "4       27    technician    single  secondary      no      126     yes  yes   \n",
       "...    ...           ...       ...        ...     ...      ...     ...  ...   \n",
       "30902   51    technician   married   tertiary      no      825      no   no   \n",
       "30903   71       retired  divorced    primary      no     1729      no   no   \n",
       "30904   72       retired   married  secondary      no     5715      no   no   \n",
       "30905   57   blue-collar   married  secondary      no      668      no   no   \n",
       "30906   37  entrepreneur   married  secondary      no     2971      no   no   \n",
       "\n",
       "         contact  day_of_week month  duration  campaign  pdays  previous  \\\n",
       "0       cellular            4   jul       255         1     -1         0   \n",
       "1       cellular            4   jul       297         1     -1         0   \n",
       "2       cellular            4   jul       668         2     -1         0   \n",
       "3      telephone            4   jul        65         2     -1         0   \n",
       "4       cellular            4   jul       436         4     -1         0   \n",
       "...          ...          ...   ...       ...       ...    ...       ...   \n",
       "30902   cellular           17   nov       977         3     -1         0   \n",
       "30903   cellular           17   nov       456         2     -1         0   \n",
       "30904   cellular           17   nov      1127         5    184         3   \n",
       "30905  telephone           17   nov       508         4     -1         0   \n",
       "30906   cellular           17   nov       361         2    188        11   \n",
       "\n",
       "      poutcome    y  \n",
       "0          NaN   no  \n",
       "1          NaN   no  \n",
       "2          NaN   no  \n",
       "3          NaN   no  \n",
       "4          NaN   no  \n",
       "...        ...  ...  \n",
       "30902      NaN  yes  \n",
       "30903      NaN  yes  \n",
       "30904  success  yes  \n",
       "30905      NaN   no  \n",
       "30906    other   no  \n",
       "\n",
       "[30907 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>35</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>466</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>105</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>668</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>19</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>126</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>436</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30902</th>\n",
       "      <td>51</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>825</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30903</th>\n",
       "      <td>71</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1729</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30904</th>\n",
       "      <td>72</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>5715</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30905</th>\n",
       "      <td>57</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>668</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30906</th>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2971</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30907 rows × 17 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T18:55:11.341100Z",
     "start_time": "2024-12-22T18:55:11.321750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = dataset.iloc[:, :-1], dataset.iloc[:, -1]\n",
    "\n",
    "# Remove the bug in the dataset where the entire row has -9 values\n",
    "mask = ~(X == -9).all(axis=1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "y = y.replace({\"no\": 0, \"yes\": 1}).astype(int)"
   ],
   "id": "f5fb62e726fd2001",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r9/9n0wpy917zg1611cmsmqg0kr0000gn/T/ipykernel_70605/1292191429.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = y.replace({\"no\": 0, \"yes\": 1}).astype(int)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T18:55:11.621295Z",
     "start_time": "2024-12-22T18:55:11.593098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(X: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    The function will preprocess the data:\n",
    "    1. Categorical features will be label encoded (Boy->1, Girl ->2)\n",
    "    2. Numerical features will be scaled if the data is intended to be used for baseline. For cloud data set, no scaling will be preformed.\n",
    "\n",
    "    Return pd.Dataframe\n",
    "    \"\"\"\n",
    "    # Identify categorical and numeric columns\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "    # Initialize lists to store processed columns\n",
    "    processed_columns = []\n",
    "\n",
    "    # If there are categorical columns, apply one-hot encoding\n",
    "    if categorical_cols:\n",
    "        print(\"\\nEncoding categorical columns...\")\n",
    "        # onehot_encoder = OneHotEncoder(categories='auto', sparse=False)\n",
    "        # X_categorical = pd.DataFrame(onehot_encoder.fit_transform(X[categorical_cols]),\n",
    "        #                              columns=onehot_encoder.get_feature_names_out(categorical_cols))\n",
    "        label_encoder = LabelEncoder()\n",
    "        X_categorical = pd.DataFrame()\n",
    "        for col in categorical_cols:\n",
    "            X_categorical[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "        processed_columns.append(X_categorical)\n",
    "\n",
    "    # Apply standard scaling to the numeric columns\n",
    "    if numeric_cols:\n",
    "        print(\"\\nScaling numerical columns...\")\n",
    "        scaler = MinMaxScaler()\n",
    "        # X_numeric = X[numeric_cols]\n",
    "        X_numeric = pd.DataFrame(scaler.fit_transform(X[numeric_cols]), columns=numeric_cols, index=X.index)\n",
    "\n",
    "        processed_columns.append(X_numeric)\n",
    "\n",
    "    # Combine the processed columns\n",
    "    if processed_columns:\n",
    "        X_processed = pd.concat(processed_columns, axis=1)\n",
    "    else:\n",
    "        X_processed = X.copy()  # If there are no categorical or numeric columns, keep the original dataframe\n",
    "\n",
    "\n",
    "    return X_processed\n",
    "\n",
    "\n",
    "X = preprocess(X)"
   ],
   "id": "f52103b993942b4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding categorical columns...\n",
      "\n",
      "Scaling numerical columns...\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T18:55:12.805569Z",
     "start_time": "2024-12-22T18:55:12.795836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = preprocess(X)\n",
    "X_sample, y_sample = X.iloc[2000:22000], y.iloc[2000:22000]\n",
    "y_sample.value_counts()"
   ],
   "id": "10c5f286c50b0715",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling numerical columns...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    18287\n",
       "1     1713\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T18:55:13.419598Z",
     "start_time": "2024-12-22T18:55:13.411404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test, y_test = X.iloc[:2000], y.iloc[:2000]\n",
    "y_test.value_counts()"
   ],
   "id": "3631cb9185f2bd7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    1878\n",
       "1     122\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T18:55:34.550128Z",
     "start_time": "2024-12-22T18:55:13.930637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn, tensorflow as tf\n",
    "from keras.src.utils import to_categorical\n",
    "from keras.src.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.src.callbacks import EarlyStopping\n",
    "from keras.src import Sequential\n",
    "\n",
    "\n",
    "class DNNEmbedding(nn.Module):\n",
    "\n",
    "    name = \"dnn_embedding\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DNNEmbedding, self).__init__()\n",
    "\n",
    "        X, y = kwargs.get(\"X\"), kwargs.get(\"y\")\n",
    "        num_classes = len(set(y))\n",
    "        y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=X.shape[1]//2, activation='tanh', name=\"embedding\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(units=num_classes, activation='softmax', name=\"output\"))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        early_stop = EarlyStopping(patience=2, monitor=\"loss\")\n",
    "\n",
    "        model.fit(X, y,validation_data=[X_test, to_categorical(y_test,2)], epochs=50, batch_size=8, callbacks=[early_stop])\n",
    "        self.model = model.layers[0]\n",
    "        self.output_shape = (1, X.shape[1]//2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if type(x) is pd.DataFrame:\n",
    "            x = x.to_numpy()\n",
    "\n",
    "        embedding = self.model(x)\n",
    "        return embedding\n",
    "\n",
    "\n",
    "# Code to run on CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    \n",
    "    embedding = DNNEmbedding(X=X_sample, y=y_sample)\n",
    "\n"
   ],
   "id": "582a23893cfe77ed",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eden.yavin/Projects/Tabular-Cloud-ML/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-22 20:55:26.347344: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-12-22 20:55:26.347361: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2024-12-22 20:55:26.347365: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "2024-12-22 20:55:26.347586: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-22 20:55:26.347599: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 308us/step - accuracy: 0.7992 - loss: 0.4826 - val_accuracy: 0.9410 - val_loss: 0.1740\n",
      "Epoch 2/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 278us/step - accuracy: 0.9155 - loss: 0.2582 - val_accuracy: 0.9470 - val_loss: 0.1401\n",
      "Epoch 3/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 271us/step - accuracy: 0.9222 - loss: 0.2243 - val_accuracy: 0.9485 - val_loss: 0.1459\n",
      "Epoch 4/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 272us/step - accuracy: 0.9128 - loss: 0.2371 - val_accuracy: 0.9485 - val_loss: 0.1496\n",
      "Epoch 5/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 271us/step - accuracy: 0.9167 - loss: 0.2336 - val_accuracy: 0.9480 - val_loss: 0.1528\n",
      "Epoch 6/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 275us/step - accuracy: 0.9171 - loss: 0.2308 - val_accuracy: 0.9465 - val_loss: 0.1386\n",
      "Epoch 7/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 275us/step - accuracy: 0.9194 - loss: 0.2216 - val_accuracy: 0.9460 - val_loss: 0.1437\n",
      "Epoch 8/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 277us/step - accuracy: 0.9159 - loss: 0.2307 - val_accuracy: 0.9480 - val_loss: 0.1421\n",
      "Epoch 9/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 283us/step - accuracy: 0.9173 - loss: 0.2266 - val_accuracy: 0.9465 - val_loss: 0.1379\n",
      "Epoch 10/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 283us/step - accuracy: 0.9173 - loss: 0.2281 - val_accuracy: 0.9470 - val_loss: 0.1393\n",
      "Epoch 11/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 286us/step - accuracy: 0.9155 - loss: 0.2324 - val_accuracy: 0.9460 - val_loss: 0.1405\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T18:55:34.564377Z",
     "start_time": "2024-12-22T18:55:34.555039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from keras.src.layers import Input, Dense,  Flatten\n",
    "from keras.src.layers import BatchNormalization, Activation, Conv2DTranspose\n",
    "from keras.src.models import Model, Sequential\n",
    "from keras.src.layers import LeakyReLU, Reshape, Conv2D, UpSampling2D, ReLU\n",
    "\n",
    "class BaseEncryptor:\n",
    "\n",
    "    name: str\n",
    "\n",
    "    def __init__(self, input_shape=None, output_shape=None):\n",
    "        self.model = None\n",
    "        self.output_shape = output_shape\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build_generator(self, input_shape, output_shape):\n",
    "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
    "\n",
    "    def encode(self, inputs) -> np.array:\n",
    "        inputs = np.expand_dims(inputs, axis=0)\n",
    "        if self.model is None:\n",
    "            input_shape = inputs.shape[1:]\n",
    "            output_shape = self.output_shape or (1, inputs.shape[2])\n",
    "            self.model = self.build_generator(input_shape, output_shape)\n",
    "        return self.model(inputs).numpy()\n",
    "\n",
    "class DCEncryptor(BaseEncryptor):\n",
    "\n",
    "    name = \"dc\"\n",
    "    \n",
    "    def build_generator1(self, input_shape, output_shape):\n",
    "        G = Sequential()\n",
    "        G.add(Reshape(target_shape=[1, 1, self.input_shape], input_shape=[self.input_shape]))\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 1x1x4096\n",
    "        G.add(Conv2DTranspose(filters=64, kernel_size=4))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 0, Activations index: 1\n",
    "\n",
    "        # 4x4x64\n",
    "        G.add(Conv2D(filters=64, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 2, Activations index: 5\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 8x8x64\n",
    "        G.add(Conv2D(filters=32, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 8, Activations index: 9\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 16x16x32\n",
    "        G.add(Conv2D(filters=16, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 14, Activations index: 13\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 32x32x16\n",
    "        G.add(Conv2D(filters=8, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 20, Activations index: 17\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 64x64x8\n",
    "        G.add(Conv2D(filters=4, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 26, Activations index: 21\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 128x128x4\n",
    "        G.add(Conv2D(filters=3, kernel_size=4, padding='same'))\n",
    "        G.add(Activation('sigmoid'))\n",
    "        \n",
    "        return G\n",
    "        \n",
    "    def build_generator(self, input_shape, output_shape):\n",
    "\n",
    "        input_layer = Input(shape=input_shape)\n",
    "        x = Flatten()(input_layer)\n",
    "    \n",
    "        x = Dense(4*4*256, use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "    \n",
    "        x = Reshape((4, 4, 256))(x)\n",
    "    \n",
    "        x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "    \n",
    "        x = Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "    \n",
    "        x = Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "    \n",
    "        output_image = Conv2DTranspose(3, (4, 4), strides=(1, 1), padding='same', use_bias=False, activation='sigmoid')(x)\n",
    "    \n",
    "        return Model(inputs=input_layer, outputs=output_image)\n",
    "        \n",
    "    def build_generator_vgg224(self, input_shape, output_shape):\n",
    "\n",
    "        input_layer = Input(shape=input_shape)\n",
    "        x = Flatten()(input_layer)\n",
    "\n",
    "        x = Dense(7*7*256, use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Reshape((7, 7, 256))(x)\n",
    "        x = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        x = Conv2DTranspose(16, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        output_image = Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n",
    "\n",
    "        return Model(inputs=input_layer, outputs=output_image)\n",
    "    \n",
    "    \n",
    "encoder = DCEncryptor(output_shape=(1, 32, 32, 4))"
   ],
   "id": "c19d25c4f9c6339f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T18:58:25.319309Z",
     "start_time": "2024-12-22T18:58:24.161192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.api.applications import ResNet152V2, VGG16, EfficientNetB7\n",
    "# from keras.api.applications.vgg16 import preprocess_input\n",
    "from keras.api.applications.resnet_v2 import preprocess_input\n",
    "import tensorflow as tf\n",
    "from keras.api.models import load_model\n",
    "\n",
    "\n",
    "def pad(tensor, original, target=600):\n",
    "    pad_height = (target - original) // 2\n",
    "    pad_width = (target - original) // 2\n",
    "    padded_tensor = tf.pad(tensor, [[pad_height, pad_height], [pad_width, pad_width], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "    # If the dimensions are odd, add an extra row/column to one side\n",
    "    if (600 - 224) % 2 != 0:\n",
    "        padded_tensor = tf.pad(padded_tensor, [[0, 1], [0, 1], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "    return padded_tensor[np.newaxis, ...]\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Assuming 'image' is your input tensor\n",
    "    resized_image = tf.image.resize(image, (32, 32))\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "class VGG16CloudModel:\n",
    "    name = \"vgg16\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = self.get_model()\n",
    "        self.input_shape = (224, 224, 3) \n",
    "        self.output_shape = (1,1000)\n",
    "\n",
    "    def fit(self, X_train, y_train, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def get_model(self):\n",
    "        # Load the pretrained VGG16 model with ImageNet weights\n",
    "        # model = load_model(\"/Users/eden.yavin/Projects/Tabular-Cloud-ML/store/models/cifar100_vgg.keras\") #\n",
    "        model = VGG16(weights='imagenet')\n",
    "        return model\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.preprocess(X)\n",
    "        predictions = self.model.predict(X, verbose=None)\n",
    "        return predictions\n",
    "\n",
    "    def preprocess(self, X):\n",
    "        \n",
    "        X = X.copy()\n",
    "        # X = (X * 10000).astype(np.uint8)\n",
    "\n",
    "        if any(s < 224 for s in X.shape[1:3]):\n",
    "            # Pad the input to make its size equal to 224\n",
    "            padded_X = tf.image.resize_with_crop_or_pad(X, 224, 224)\n",
    "\n",
    "            # Ensure the input is properly preprocessed for VGG16\n",
    "            X = preprocess_input(padded_X.numpy())\n",
    "        else:\n",
    "            # If no padding is needed, directly preprocess the input\n",
    "            X = preprocess_input(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    \n",
    "    \n",
    "cloud = VGG16CloudModel()\n"
   ],
   "id": "aa8eddbabe42f647",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:01:13.865399Z",
     "start_time": "2024-12-22T18:58:55.336747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "X_encrypted, X_test_encrypted = [], []\n",
    "X_embed, X_test_embed = [], []\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "        \n",
    "    for i, x in tqdm(X_sample.iterrows(), total=len(X_sample), leave=True, position=0):\n",
    "        \n",
    "        x_embed = embedding(x.values.reshape(1,-1))\n",
    "        X_embed.append(x_embed)\n",
    "        encrypted = encoder.encode(np.vstack(x_embed))\n",
    "    \n",
    "        X_encrypted.append(encrypted)\n",
    "        \n",
    "    for i,x in tqdm(X_test.iterrows(), total=len(X_test), leave=True, position=0):\n",
    "        x_embed = embedding(x.values.reshape(1,-1))\n",
    "        X_test_embed.append(x_embed)\n",
    "        encrypted = encoder.encode(np.vstack(x_embed))\n",
    "        X_test_encrypted.append(encrypted)"
   ],
   "id": "5778ef3e2aa3f76e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:06<00:00, 158.39it/s]\n",
      "100%|██████████| 2000/2000 [00:12<00:00, 163.28it/s]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:22:37.744536Z",
     "start_time": "2024-12-22T19:01:13.872742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.device('/GPU:0'):\n",
    "\n",
    "    predictions = [\n",
    "        cloud.predict(x)\n",
    "        for x in tqdm(X_encrypted, total=len(X_encrypted), leave=True, position=0)\n",
    "    ]\n",
    "    test_preds = [\n",
    "        cloud.predict(x)\n",
    "        for x in tqdm(X_test_encrypted, total=len(X_test_encrypted), leave=True, position=0)\n",
    "]"
   ],
   "id": "bce9b101d1accad8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]2024-12-22 21:01:14.019489: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "100%|██████████| 20000/20000 [19:14<00:00, 17.32it/s]\n",
      "100%|██████████| 2000/2000 [02:09<00:00, 15.47it/s]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:22:43.937611Z",
     "start_time": "2024-12-22T19:22:37.822991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Define the base models\n",
    "base_model1 = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "base_model2 = XGBClassifier(n_estimators=100, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Create the stacking classifier\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('xgb1', base_model1), ('xgb2', base_model2)],\n",
    "    final_estimator=meta_model,\n",
    "    # cv=5\n",
    ")"
   ],
   "id": "f3a41b5f74ebcc6a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:22:57.272686Z",
     "start_time": "2024-12-22T19:22:48.812087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_pred_embed, X_test_pred_embed = [], []\n",
    "for embed, pred in zip(X_embed, predictions):\n",
    "    X_pred_embed.append(np.hstack([embed, pred]))\n",
    "    \n",
    "for embed, pred in zip(X_test_embed, test_preds):\n",
    "    X_test_pred_embed.append(np.hstack([embed, pred]))"
   ],
   "id": "c1b8acfc072dfef0",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:23:32.631345Z",
     "start_time": "2024-12-22T19:23:32.611788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_pred_embed = np.vstack(X_pred_embed)\n",
    "X_test_pred_embed = np.vstack(X_test_pred_embed)"
   ],
   "id": "7092406c6ba0f344",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:24:41.819011Z",
     "start_time": "2024-12-22T19:24:30.081893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "# Fit the stacking model\n",
    "stacking_model.fit(X_pred_embed, y_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = stacking_model.predict(X_test_pred_embed)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Stacking Model Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Stacking Model F1 Score: {f1_score(y_test, y_pred):.4f}\")"
   ],
   "id": "1e27fc78e76aceaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model Accuracy: 0.9455\n",
      "Stacking Model F1 Score: 0.3978\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:39:38.450919Z",
     "start_time": "2024-12-22T19:39:36.717884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Create and train the first XGBoost model on X1\n",
    "model1 = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model1.fit(np.vstack(X_embed), y_sample)\n",
    "\n",
    "# Create and train the second XGBoost model on X2\n",
    "model2 = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model2.fit(np.vstack(predictions), y_sample)\n",
    "\n",
    "# Make predictions using both models (probability of class 1)\n",
    "pred1_train = model1.predict_proba(np.vstack(X_embed))[:, 1].reshape(-1, 1)\n",
    "pred2_train = model2.predict_proba(np.vstack(predictions))[:, 1].reshape(-1, 1)\n",
    "pred1_test = model1.predict_proba(np.vstack(X_test_embed))[:, 1].reshape(-1, 1)\n",
    "pred2_test = model2.predict_proba(np.vstack(test_preds))[:, 1].reshape(-1, 1)\n",
    "\n",
    "# Combine predictions for meta-model training\n",
    "X_meta_train = np.hstack((pred1_train, pred2_train))\n",
    "X_meta_test = np.hstack((pred1_test, pred2_test))\n",
    "\n",
    "# Create and train the meta-model (stacking)\n",
    "meta_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "meta_model.fit(X_meta_train, y_sample)\n",
    "\n",
    "# Make final predictions using the meta-model\n",
    "final_predictions = meta_model.predict(X_meta_test)\n",
    "final_proba = meta_model.predict_proba(X_meta_test)[:, 1]\n",
    "\n",
    "# Evaluate the stacked model\n",
    "accuracy = accuracy_score(y_test, final_predictions)"
   ],
   "id": "358378c4a9cace3f",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T19:45:05.312712Z",
     "start_time": "2024-12-22T19:45:05.308784Z"
    }
   },
   "cell_type": "code",
   "source": "accuracy, f1_score(y_test, final_predictions, average='weighted')",
   "id": "7205f6e2a4ff3582",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9385, 0.938381641511976)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9da945a163cc486e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
