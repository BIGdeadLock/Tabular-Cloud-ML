{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-16T11:22:16.214886Z",
     "start_time": "2024-12-16T11:21:51.408917Z"
    }
   },
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from keras.src import Sequential\n",
    "from keras.src.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.src.callbacks import EarlyStopping"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:22:16.228694Z",
     "start_time": "2024-12-16T11:22:16.225870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECT_PATH = os.getcwd()\n",
    "PROJECT_PATH = os.path.join(PROJECT_PATH, \"..\")\n",
    "MODELS_DIR = pathlib.Path(PROJECT_PATH) / \"store\" / \"models\"\n",
    "\n",
    "DATASET_DIR = pathlib.Path(PROJECT_PATH) / \"data\""
   ],
   "id": "982312657be336ff",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:22:16.293966Z",
     "start_time": "2024-12-16T11:22:16.240235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(DATASET_DIR / \"bank_marketing\"/ \"dataset.csv\")\n",
    "dataset"
   ],
   "id": "a240984fa1f517ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       age           job   marital  education default  balance housing loan  \\\n",
       "0       27    management    single  secondary      no       35      no   no   \n",
       "1       54   blue-collar   married    primary      no      466      no   no   \n",
       "2       43   blue-collar   married  secondary      no      105      no  yes   \n",
       "3       31    technician    single  secondary      no       19      no   no   \n",
       "4       27    technician    single  secondary      no      126     yes  yes   \n",
       "...    ...           ...       ...        ...     ...      ...     ...  ...   \n",
       "30902   51    technician   married   tertiary      no      825      no   no   \n",
       "30903   71       retired  divorced    primary      no     1729      no   no   \n",
       "30904   72       retired   married  secondary      no     5715      no   no   \n",
       "30905   57   blue-collar   married  secondary      no      668      no   no   \n",
       "30906   37  entrepreneur   married  secondary      no     2971      no   no   \n",
       "\n",
       "         contact  day_of_week month  duration  campaign  pdays  previous  \\\n",
       "0       cellular            4   jul       255         1     -1         0   \n",
       "1       cellular            4   jul       297         1     -1         0   \n",
       "2       cellular            4   jul       668         2     -1         0   \n",
       "3      telephone            4   jul        65         2     -1         0   \n",
       "4       cellular            4   jul       436         4     -1         0   \n",
       "...          ...          ...   ...       ...       ...    ...       ...   \n",
       "30902   cellular           17   nov       977         3     -1         0   \n",
       "30903   cellular           17   nov       456         2     -1         0   \n",
       "30904   cellular           17   nov      1127         5    184         3   \n",
       "30905  telephone           17   nov       508         4     -1         0   \n",
       "30906   cellular           17   nov       361         2    188        11   \n",
       "\n",
       "      poutcome    y  \n",
       "0          NaN   no  \n",
       "1          NaN   no  \n",
       "2          NaN   no  \n",
       "3          NaN   no  \n",
       "4          NaN   no  \n",
       "...        ...  ...  \n",
       "30902      NaN  yes  \n",
       "30903      NaN  yes  \n",
       "30904  success  yes  \n",
       "30905      NaN   no  \n",
       "30906    other   no  \n",
       "\n",
       "[30907 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>35</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>466</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>105</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>668</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>19</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>126</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>436</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30902</th>\n",
       "      <td>51</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>825</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30903</th>\n",
       "      <td>71</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1729</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30904</th>\n",
       "      <td>72</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>5715</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30905</th>\n",
       "      <td>57</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>668</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30906</th>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2971</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30907 rows × 17 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:22:16.515673Z",
     "start_time": "2024-12-16T11:22:16.498776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = dataset.iloc[:, :-1], dataset.iloc[:, -1]\n",
    "\n",
    "# Remove the bug in the dataset where the entire row has -9 values\n",
    "mask = ~(X == -9).all(axis=1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "y = y.replace({\"no\": 0, \"yes\": 1}).astype(int)"
   ],
   "id": "187e2a5342844a47",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r9/9n0wpy917zg1611cmsmqg0kr0000gn/T/ipykernel_82216/1292191429.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = y.replace({\"no\": 0, \"yes\": 1}).astype(int)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:22:16.563057Z",
     "start_time": "2024-12-16T11:22:16.538345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(X: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    The function will preprocess the data:\n",
    "    1. Categorical features will be label encoded (Boy->1, Girl ->2)\n",
    "    2. Numerical features will be scaled if the data is intended to be used for baseline. For cloud data set, no scaling will be preformed.\n",
    "\n",
    "    Return pd.Dataframe\n",
    "    \"\"\"\n",
    "    # Identify categorical and numeric columns\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "    # Initialize lists to store processed columns\n",
    "    processed_columns = []\n",
    "\n",
    "    # If there are categorical columns, apply one-hot encoding\n",
    "    if categorical_cols:\n",
    "        print(\"\\nEncoding categorical columns...\")\n",
    "        # onehot_encoder = OneHotEncoder(categories='auto', sparse=False)\n",
    "        # X_categorical = pd.DataFrame(onehot_encoder.fit_transform(X[categorical_cols]),\n",
    "        #                              columns=onehot_encoder.get_feature_names_out(categorical_cols))\n",
    "        label_encoder = LabelEncoder()\n",
    "        X_categorical = pd.DataFrame()\n",
    "        for col in categorical_cols:\n",
    "            X_categorical[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "        processed_columns.append(X_categorical)\n",
    "\n",
    "    # Apply standard scaling to the numeric columns\n",
    "    if numeric_cols:\n",
    "        print(\"\\nScaling numerical columns...\")\n",
    "        scaler = MinMaxScaler()\n",
    "        X_numeric = X[numeric_cols]\n",
    "        # X_numeric = pd.DataFrame(scaler.fit_transform(X[numeric_cols]), columns=numeric_cols, index=X.index)\n",
    "\n",
    "        processed_columns.append(X_numeric)\n",
    "\n",
    "    # Combine the processed columns\n",
    "    if processed_columns:\n",
    "        X_processed = pd.concat(processed_columns, axis=1)\n",
    "    else:\n",
    "        X_processed = X.copy()  # If there are no categorical or numeric columns, keep the original dataframe\n",
    "\n",
    "\n",
    "    return X_processed\n",
    "\n",
    "\n",
    "X = preprocess(X)"
   ],
   "id": "909539a4be92cf8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding categorical columns...\n",
      "\n",
      "Scaling numerical columns...\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:22:16.595631Z",
     "start_time": "2024-12-16T11:22:16.592634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_sample, y_sample = X.iloc[2000:3000], y.iloc[2000:3000]\n",
    "y_sample.value_counts()"
   ],
   "id": "20fd537bed251cc5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    919\n",
       "1     81\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:22:16.638813Z",
     "start_time": "2024-12-16T11:22:16.635824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test, y_test = X.iloc[:1000], y.iloc[:1000]\n",
    "y_test.value_counts()"
   ],
   "id": "d48d5a81179fad14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    940\n",
       "1     60\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:22:39.977454Z",
     "start_time": "2024-12-16T11:22:16.687965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from keras.src.utils import to_categorical\n",
    "\n",
    "\n",
    "class DNNEmbedding(nn.Module):\n",
    "\n",
    "    name = \"dnn_embedding\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DNNEmbedding, self).__init__()\n",
    "\n",
    "        X, y = kwargs.get(\"X\"), kwargs.get(\"y\")\n",
    "        num_classes = len(set(y))\n",
    "        y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=X.shape[1]//2, activation='tanh', name=\"embedding\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(units=num_classes, activation='softmax', name=\"output\"))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        early_stop = EarlyStopping(patience=2, monitor=\"loss\")\n",
    "\n",
    "        model.fit(X, y,validation_data=[X_test, to_categorical(y_test,2)], epochs=50, batch_size=8, callbacks=[early_stop])\n",
    "        self.model = model.layers[0]\n",
    "        self.output_shape = (1, X.shape[1]//2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if type(x) is pd.DataFrame:\n",
    "            x = x.to_numpy()\n",
    "\n",
    "        embedding = self.model(x)\n",
    "        return embedding\n",
    "\n",
    "\n",
    "embedding = DNNEmbedding(X=X_sample, y=y_sample)\n",
    "\n"
   ],
   "id": "d69d33283821949f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eden.yavin/Projects/Tabular-Cloud-ML/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 13:22:18.297333: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-12-16 13:22:18.297365: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2024-12-16 13:22:18.297373: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "2024-12-16 13:22:18.297791: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-16 13:22:18.297809: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-12-16 13:22:18.656642: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 15ms/step - accuracy: 0.5896 - loss: 0.7511 - val_accuracy: 0.6790 - val_loss: 0.6760\n",
      "Epoch 2/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 14ms/step - accuracy: 0.7623 - loss: 0.5310 - val_accuracy: 0.7340 - val_loss: 0.4654\n",
      "Epoch 3/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.8121 - loss: 0.4399 - val_accuracy: 0.9400 - val_loss: 0.3375\n",
      "Epoch 4/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 14ms/step - accuracy: 0.9092 - loss: 0.3528 - val_accuracy: 0.9400 - val_loss: 0.2731\n",
      "Epoch 5/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 17ms/step - accuracy: 0.9079 - loss: 0.3262 - val_accuracy: 0.9400 - val_loss: 0.2396\n",
      "Epoch 6/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.9168 - loss: 0.3029 - val_accuracy: 0.9400 - val_loss: 0.2232\n",
      "Epoch 7/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.9262 - loss: 0.2754 - val_accuracy: 0.9400 - val_loss: 0.2193\n",
      "Epoch 8/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 14ms/step - accuracy: 0.9196 - loss: 0.2771 - val_accuracy: 0.9400 - val_loss: 0.2126\n",
      "Epoch 9/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.9319 - loss: 0.2393 - val_accuracy: 0.9400 - val_loss: 0.2046\n",
      "Epoch 10/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.9171 - loss: 0.2576 - val_accuracy: 0.9400 - val_loss: 0.1987\n",
      "Epoch 11/50\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 17ms/step - accuracy: 0.9100 - loss: 0.2735 - val_accuracy: 0.9400 - val_loss: 0.1942\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:27:04.760520Z",
     "start_time": "2024-12-16T11:27:03.752601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.api.applications import ResNet152V2, VGG16, EfficientNetB7\n",
    "# from keras.api.applications.vgg16 import preprocess_input\n",
    "from keras.api.applications.resnet_v2 import preprocess_input\n",
    "import tensorflow as tf\n",
    "from keras.api.models import load_model\n",
    "\n",
    "\n",
    "def pad(tensor, original, target=600):\n",
    "    pad_height = (target - original) // 2\n",
    "    pad_width = (target - original) // 2\n",
    "    padded_tensor = tf.pad(tensor, [[pad_height, pad_height], [pad_width, pad_width], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "    # If the dimensions are odd, add an extra row/column to one side\n",
    "    if (600 - 224) % 2 != 0:\n",
    "        padded_tensor = tf.pad(padded_tensor, [[0, 1], [0, 1], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "    return padded_tensor[np.newaxis, ...]\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Assuming 'image' is your input tensor\n",
    "    resized_image = tf.image.resize(image, (32, 32))\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "class VGG16CloudModel:\n",
    "    name = \"vgg16\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = self.get_model()\n",
    "        self.input_shape = (224, 224, 3)\n",
    "        self.output_shape = (1,1000)\n",
    "\n",
    "    def fit(self, X_train, y_train, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def get_model(self):\n",
    "        # Load the pretrained VGG16 model with ImageNet weights\n",
    "        model = VGG16(weights='imagenet')\n",
    "        return model\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.preprocess(X)\n",
    "        predictions = self.model.predict(X, verbose=None)\n",
    "        return predictions\n",
    "\n",
    "    def preprocess(self, X):\n",
    "        \n",
    "        X = X.copy()\n",
    "        # X = (X * 10000).astype(np.uint8)\n",
    "\n",
    "        if any(s < 224 for s in X.shape[1:3]):\n",
    "            # Pad the input to make its size equal to 224\n",
    "            padded_X = tf.image.resize_with_crop_or_pad(X, 224, 224)\n",
    "\n",
    "            # Ensure the input is properly preprocessed for VGG16\n",
    "            X = preprocess_input(padded_X.numpy())\n",
    "        else:\n",
    "            # If no padding is needed, directly preprocess the input\n",
    "            X = preprocess_input(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    \n",
    "    \n",
    "cloud = VGG16CloudModel()\n"
   ],
   "id": "d010100e38c2c228",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:27:06.140057Z",
     "start_time": "2024-12-16T11:27:06.129859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from keras.src.layers import Input, Dense,  Flatten\n",
    "from keras.src.layers import BatchNormalization, Activation, Conv2DTranspose\n",
    "from keras.src.models import Model, Sequential\n",
    "from keras.src.layers import LeakyReLU, Reshape, Conv2D, UpSampling2D, ReLU\n",
    "\n",
    "class BaseEncryptor:\n",
    "\n",
    "    name: str\n",
    "\n",
    "    def __init__(self, input_shape=None, output_shape=None):\n",
    "        self.model = None\n",
    "        self.output_shape = output_shape\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build_generator(self, input_shape, output_shape):\n",
    "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
    "\n",
    "    def encode(self, inputs) -> np.array:\n",
    "        inputs = np.expand_dims(inputs, axis=0)\n",
    "        if self.model is None:\n",
    "            input_shape = inputs.shape[1:]\n",
    "            output_shape = self.output_shape or (1, inputs.shape[2])\n",
    "            self.model = self.build_generator(input_shape, output_shape)\n",
    "        return self.model(inputs).numpy()\n",
    "\n",
    "class DCEncryptor(BaseEncryptor):\n",
    "\n",
    "    name = \"dc\"\n",
    "        \n",
    "    def build_generator(self, input_shape, output_shape):\n",
    "\n",
    "          # Ziv's Model\n",
    "        G = Sequential()\n",
    "\n",
    "        G.add(Reshape(target_shape=[1, *input_shape[1:]], input_shape=input_shape))\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 1x1x4096\n",
    "        G.add(Conv2DTranspose(filters=64, kernel_size=4))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 0, Activations index: 1\n",
    "\n",
    "        # 4x4x64\n",
    "        G.add(Conv2D(filters=64, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 2, Activations index: 5\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 8x8x64\n",
    "        G.add(Conv2D(filters=32, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 8, Activations index: 9\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 16x16x32\n",
    "        G.add(Conv2D(filters=16, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 14, Activations index: 13\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 32x32x16\n",
    "        G.add(Conv2D(filters=8, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 20, Activations index: 17\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 64x64x8\n",
    "        G.add(Conv2D(filters=4, kernel_size=4, padding='same'))\n",
    "        G.add(BatchNormalization(momentum=0.7))\n",
    "        G.add(Activation('relu'))\n",
    "        # Weights index: 26, Activations index: 21\n",
    "        G.add(UpSampling2D())\n",
    "        # No weights or activations here\n",
    "\n",
    "        # 128x128x4\n",
    "        G.add(Conv2D(filters=3, kernel_size=4, padding='same'))\n",
    "        G.add(Activation('sigmoid'))\n",
    "        # Weights index: 32, Activations index: 25\n",
    "\n",
    "        return G\n",
    "    \n",
    "    \n",
    "encoder = DCEncryptor(output_shape=(1, *cloud.input_shape))"
   ],
   "id": "821dca637b470fff",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T14:27:26.420068Z",
     "start_time": "2024-12-16T14:19:27.819796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "X_encrypted, X_test_encrypted = [], []\n",
    "X_embed, X_test_embed = [], []\n",
    "for i, x in tqdm(X.iterrows(), total=len(X)):\n",
    "    \n",
    "    x_embed = embedding(x.values.reshape(1,-1))\n",
    "    X_embed.append(x_embed)\n",
    "    x_embed = np.vstack(x_embed)[np.newaxis, ...]\n",
    "    encrypted = encoder.encode(x_embed)\n",
    "\n",
    "    X_encrypted.append(encrypted)\n",
    "    \n",
    "# for i,x in X_test.iterrows():\n",
    "#     x_embed = embedding(x.values.reshape(1,-1))\n",
    "#     X_test_embed.append(x_embed)\n",
    "#     encrypted = encoder.encode(np.vstack(X_embed)[np.newaxis, ...])\n",
    "#     X_test_encrypted.append(encrypted)"
   ],
   "id": "a24845e75f0e88ae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30907/30907 [07:58<00:00, 64.58it/s]\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T14:28:11.868576Z",
     "start_time": "2024-12-16T14:28:11.822037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.models import Sequential\n",
    "\n",
    "\n",
    "from keras.src.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "student_model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),  # Output: (64,64,64)\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),  # Output: (32,32,128)\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),  # Output: (16,16,256)\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),  # Output: (8,8,256)\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),  # Output: (4,4,256)\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same')\n",
    "])\n",
    "\n",
    "# student_model = Sequential([\n",
    "#     Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Flatten(),\n",
    "#     Dense(512, activation='relu'),\n",
    "#     Dense(1000, activation='softmax')\n",
    "# ])"
   ],
   "id": "e03b36c74ce1c321",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eden.yavin/Projects/Tabular-Cloud-ML/venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T14:28:12.033622Z",
     "start_time": "2024-12-16T14:28:12.030334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from keras.src.losses import categorical_crossentropy as logloss, kl_divergence as KLD_Loss\n",
    "from keras.src.metrics.accuracy_metrics import categorical_accuracy\n",
    "NUM_CLASSES = 1000\n",
    "\n",
    "def distillation_loss(y_true, y_pred, temperature=3.5, lambd=0.5):\n",
    "    y_true, y_pred = tf.nn.softmax(y_true), tf.nn.softmax(y_pred)\n",
    "    # The teacher's model prediction vector is the y_true.\n",
    "    # To use KL-div loss we first need to soften the outputs\n",
    "    y_true_KD = tf.nn.softmax(y_true / temperature, axis=1)\n",
    "    y_pred_KD = tf.nn.softmax(y_pred / temperature, axis=1)\n",
    "                        \n",
    "    # # Classic cross-entropy (without temperature)\n",
    "    # CE_loss = logloss(y_true,y_pred)\n",
    "    \n",
    "    # KL-Divergence loss for softened output (with temperature)\n",
    "    KL_loss = temperature**2*KLD_Loss(y_true_KD,y_pred_KD)\n",
    "    return KL_loss\n",
    "    # return lambd*CE_loss + (1-lambd)*KL_loss\n"
   ],
   "id": "f52fbccbe1beb7bd",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T14:28:13.202284Z",
     "start_time": "2024-12-16T14:28:13.199715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def preprocess(X):\n",
    "#         \n",
    "#     X = X.copy()\n",
    "#     # X = (X * 10000).astype(np.uint8)\n",
    "#     \n",
    "#     if any(s < 224 for s in X.shape[1:3]):\n",
    "#         # Pad the input to make its size equal to 224\n",
    "#         padded_X = tf.image.resize_with_crop_or_pad(X, 224, 224)\n",
    "#     \n",
    "#         # Ensure the input is properly preprocessed for VGG16\n",
    "#         X = preprocess_input(padded_X.numpy())\n",
    "#     else:\n",
    "#         # If no padding is needed, directly preprocess the input\n",
    "#         X = preprocess_input(X)\n",
    "#     \n",
    "#     return X"
   ],
   "id": "e12751af14c634a5",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T14:28:13.874508Z",
     "start_time": "2024-12-16T14:28:13.698669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.optimizers import Adam\n",
    "from keras.src.layers import Lambda, Activation\n",
    "from keras.src.applications.vgg16 import preprocess_input as vgg_preprocess_input\n",
    "\n",
    "# teacher_model = cloud.model\n",
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "teacher_model = VGG16(weights=\"imagenet\", include_top=False, input_tensor=input_tensor)\n",
    "teacher_model.trainable = False\n",
    "optimizer = Adam()\n",
    "\n",
    "# Preprocess function (adjust as needed for your specific case)\n",
    "def preprocess(images):\n",
    "    return vgg_preprocess_input(images)\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    with tf.GradientTape() as tape:\n",
    "        teacher_preds = teacher_model(images)        \n",
    "        student_preds = student_model(images, training=True)\n",
    "        loss = distillation_loss(teacher_preds, student_preds)\n",
    "    \n",
    "    gradients = tape.gradient(loss, student_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, student_model.trainable_variables))\n",
    "    return loss\n"
   ],
   "id": "8ff2d6ab68f7c358",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T14:37:27.398296Z",
     "start_time": "2024-12-16T14:28:23.346431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "num_epochs = 5\n",
    "train_dataset = np.vstack(X_encrypted)\n",
    "batch_size = 32\n",
    "\n",
    "# Assuming X_encrypted is a numpy array, convert it to a tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_dataset)\n",
    "train_dataset = train_dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    progress_bar = tqdm(train_dataset, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        batch = preprocess(batch)\n",
    "        loss = train_step(batch)\n",
    "        epoch_loss.append(loss.numpy())\n",
    "        \n",
    "        # Update progress bar\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': f'{np.mean(epoch_loss):.4f}'})\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Average Loss: {np.mean(epoch_loss):.4f}\")"
   ],
   "id": "c642d5bbc1cb6e33",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 965/965 [02:24<00:00,  6.83it/s, loss=0.0301]2024-12-16 16:30:56.801687: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Epoch 1/5: 100%|██████████| 965/965 [02:24<00:00,  6.67it/s, loss=0.0301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 965/965 [02:21<00:00,  6.83it/s, loss=0.0300]2024-12-16 16:33:18.235535: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Epoch 2/5: 100%|██████████| 965/965 [02:21<00:00,  6.82it/s, loss=0.0300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 965/965 [02:23<00:00,  6.85it/s, loss=0.0300]2024-12-16 16:35:41.633943: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Epoch 3/5: 100%|██████████| 965/965 [02:23<00:00,  6.73it/s, loss=0.0300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  75%|███████▌  | 725/965 [01:45<00:35,  6.85it/s, loss=0.0300]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[120], line 28\u001B[0m\n\u001B[1;32m     26\u001B[0m batch \u001B[38;5;241m=\u001B[39m preprocess(batch)\n\u001B[1;32m     27\u001B[0m loss \u001B[38;5;241m=\u001B[39m train_step(batch)\n\u001B[0;32m---> 28\u001B[0m epoch_loss\u001B[38;5;241m.\u001B[39mappend(\u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# Update progress bar\u001B[39;00m\n\u001B[1;32m     32\u001B[0m progress_bar\u001B[38;5;241m.\u001B[39mset_postfix({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnp\u001B[38;5;241m.\u001B[39mmean(epoch_loss)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m})\n",
      "File \u001B[0;32m~/Projects/Tabular-Cloud-ML/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:407\u001B[0m, in \u001B[0;36m_EagerTensorBase.numpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    384\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001B[39;00m\n\u001B[1;32m    385\u001B[0m \n\u001B[1;32m    386\u001B[0m \u001B[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;124;03m    NumPy dtype.\u001B[39;00m\n\u001B[1;32m    405\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001B[39;00m\n\u001B[0;32m--> 407\u001B[0m maybe_arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    408\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m maybe_arr\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(maybe_arr, np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;28;01melse\u001B[39;00m maybe_arr\n",
      "File \u001B[0;32m~/Projects/Tabular-Cloud-ML/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:373\u001B[0m, in \u001B[0;36m_EagerTensorBase._numpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_numpy\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m npt\u001B[38;5;241m.\u001B[39mArrayLike:\n\u001B[1;32m    372\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 373\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    374\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    375\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T14:13:45.873250Z",
     "start_time": "2024-12-16T14:13:45.853551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for epoch in range(num_epochs):\n",
    "#     for images in tqdm.tqdm(train_dataset, total=len(train_dataset)):\n",
    "#         images = preprocess(images)\n",
    "#         loss = train_step(images)\n",
    "#     print(f\"Epoch {epoch + 1}, Loss: {loss.numpy()}\")"
   ],
   "id": "47cd9c8dabbc6b46",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (32,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[99], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch_loss\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mmean\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m~/Projects/Tabular-Cloud-ML/venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3464\u001B[0m, in \u001B[0;36mmean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m   3461\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3462\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m mean(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 3464\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_methods\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mean\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3465\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/Tabular-Cloud-ML/venv/lib/python3.10/site-packages/numpy/core/_methods.py:165\u001B[0m, in \u001B[0;36m_mean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_mean\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 165\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[43masanyarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m     is_float16_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    169\u001B[0m     rcount \u001B[38;5;241m=\u001B[39m _count_reduce_items(arr, axis, keepdims\u001B[38;5;241m=\u001B[39mkeepdims, where\u001B[38;5;241m=\u001B[39mwhere)\n",
      "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (32,) + inhomogeneous part."
     ]
    }
   ],
   "execution_count": 99
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
